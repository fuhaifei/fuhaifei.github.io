<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>博客建成</title>
    <url>/2021/07/01/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E6%88%90/</url>
    <content><![CDATA[<h3 id="为什么要搭建这个博客"><a href="#为什么要搭建这个博客" class="headerlink" title="为什么要搭建这个博客"></a>为什么要搭建这个博客</h3><ol>
<li>项目不会做，不知道干啥，就来搞点没用的</li>
<li>想把笔记放在网站上，起到保存和督促的作用</li>
</ol>
<h3 id="当前博客的计划"><a href="#当前博客的计划" class="headerlink" title="当前博客的计划"></a>当前博客的计划</h3><ol>
<li>每周末把这周的笔记整理发布到网站上</li>
<li>其他感想之类的废话，还有待思考</li>
</ol>
<p>总结：闲的没事干，整点歪门邪道</p>
]]></content>
      <categories>
        <category>日常扯淡</category>
      </categories>
  </entry>
  <entry>
    <title>DataLoaders和DataSets使用总结</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/DataLoaders%E5%92%8CDataSets%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="DataLoaders和DataSets使用总结"><a href="#DataLoaders和DataSets使用总结" class="headerlink" title="DataLoaders和DataSets使用总结"></a>DataLoaders和DataSets使用总结</h1><p>通过 <code>torch.utils.data.Dataset</code>类定义数据集，通过<code>torch.utils.data.DataLoader</code>与<code>Dataset</code>配合定义数据加载方式</p>
<p><code>torch.utils.data.Dataset</code>主要参数:</p>
<ol>
<li>dataset 指定构造的数据集，一般是数据+label的元组</li>
<li>shuffle 指定是否打乱</li>
<li>sampler 指定采样器，采取某种方式遍历数据（顺序，随机等）</li>
<li>collate_fn (callable, optional):将数据形成一个batch的tensor（在某些时候需要自定义）<span id="more"></span>
以加载minist数据集为例，基本的使用流程：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先加载数据集（pytorch现有的数据集） 返回的是DataSet对象</span></span><br><span class="line">mnist_train = torchvision.datasets.FashionMNIST(root=root, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">mnist_test = torchvision.datasets.FashionMNIST(root=root, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"><span class="comment"># 然后构造DataLoader对象 返回的是可迭代的DataLoader对象</span></span><br><span class="line">train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 通过for循环遍历进行训练</span></span><br><span class="line"><span class="keyword">for</span> batch_features,batch_labels <span class="keyword">in</span> train_iter:</span><br></pre></td></tr></table></figure>
<p>基本遍历原理</p>
<ul>
<li>通过sampler抽样index(默认为顺序抽样)，根据抽出的index从dataset中获取元素（getitem），调用自身的collate_fn方法，将原始数据转化为batch形式的tensor，返回。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dataloader遍历的next方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__next__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.num_workers == <span class="number">0</span>:  </span><br><span class="line">            indices = <span class="built_in">next</span>(self.sample_iter)  <span class="comment"># Sampler</span></span><br><span class="line">            batch = self.collate_fn([self.dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices]) <span class="comment"># Dataset</span></span><br><span class="line">            <span class="keyword">if</span> self.pin_memory:</span><br><span class="line">                batch = _utils.pin_memory.pin_memory_batch(batch)</span><br><span class="line">            <span class="keyword">return</span> batch</span><br><span class="line"><span class="comment"># dataset 以[] 形式访问的方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br></pre></td></tr></table></figure>
<h2 id="1-自定义数据集"><a href="#1-自定义数据集" class="headerlink" title="1. 自定义数据集"></a>1. 自定义数据集</h2><h4 id="1-1-继承dataset类"><a href="#1-1-继承dataset类" class="headerlink" title="1.1 继承dataset类"></a>1.1 继承dataset类</h4><p>需要重写<code>init(),len(),getitem()</code>方法，以word2vec中负采样数据集生成为例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 自定义数据读取类，可结合dataloader进行数据批量读取</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">torch.utils.data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, centers, contexts, negatives</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(centers) == <span class="built_in">len</span>(contexts) == <span class="built_in">len</span>(negatives)</span><br><span class="line">        self.centers = centers</span><br><span class="line">        self.contexts = contexts</span><br><span class="line">        self.negatives = negatives</span><br><span class="line">	<span class="comment"># 返回当前行数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> (self.centers[index], self.contexts[index], self.negatives[index])</span><br><span class="line">    <span class="comment"># 返回数据长度</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.centers)</span><br></pre></td></tr></table></figure>
<h4 id="1-2-定义collate-fn方法"><a href="#1-2-定义collate-fn方法" class="headerlink" title="1.2 定义collate_fn方法"></a>1.2 定义collate_fn方法</h4><p>默认的collate_fn方法，必须保证每个训练数据的长度相同，通过自定义collate_fn方法解决这一问题</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_collate_fn</span>(<span class="params">data</span>):</span></span><br><span class="line">	<span class="comment"># 保证所有数据一致的统一长度</span></span><br><span class="line">    max_len = <span class="number">500</span></span><br><span class="line">    center_words = []</span><br><span class="line">    context_negatives = []</span><br><span class="line">    masks = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> center, contexts, negatives <span class="keyword">in</span> data:</span><br><span class="line">        cur_len = <span class="built_in">len</span>(contexts) + <span class="built_in">len</span>(negatives)</span><br><span class="line">        center_words.append([center])</span><br><span class="line">        <span class="comment"># 对数据进行截断或者延长</span></span><br><span class="line">        <span class="keyword">if</span> cur_len &gt; max_len:</span><br><span class="line">        	context_negatives.append((contexts + negatives)[<span class="number">0</span>:max_len])</span><br><span class="line">        	labels.append([<span class="number">1</span>] * <span class="built_in">len</span>(contexts) + [<span class="number">0</span>] * (max_len - <span class="built_in">len</span>(contexts)))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        	context_negatives.append(contexts + negatives + [<span class="number">0</span>] * (max_len - cur_len))</span><br><span class="line">        	labels.append([<span class="number">1</span>] * <span class="built_in">len</span>(contexts) + [<span class="number">0</span>] * (max_len - <span class="built_in">len</span>(contexts)))</span><br><span class="line">    <span class="keyword">return</span>  torch.tensor(center_words), torch.tensor(context_negatives)</span><br><span class="line"><span class="comment"># 使用即可</span></span><br><span class="line">train_iter = Data.DataLoader(MyDataset(all_centers, all_contexts, all_negatives), collate_fn = batchify, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="2-自定义sampler"><a href="#2-自定义sampler" class="headerlink" title="2.自定义sampler"></a>2.自定义sampler</h2><p>待补充</p>
]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch Scatter和gather函数使用</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/Scatter%E5%92%8Cgather%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="Scatter函数"><a href="#Scatter函数" class="headerlink" title="Scatter函数"></a>Scatter函数</h3><blockquote>
<p>scatter_(<em>dim</em>, <em>index</em>, <em>src</em>, <em>reduce=None</em>) → Tensor</p>
<p>Writes all values from the tensor <code>src</code> into <code>self</code> at the indices specified in the <code>index</code> tensor. For each value in <code>src</code>, its output index is specified by its index in <code>src</code> for <code>dimension != dim</code> and by the corresponding value in <code>index</code> for <code>dimension = dim</code>.</p>
</blockquote>
<p>简单理解就是将 src 张量中的元素散落到 self 张量中，具体选择哪个元素，选择的元素散落到哪个位置由index张量决定，具体的映射规则为:</p>
<figure class="highlight plaintext"><figcaption><span>三维张量为例</span></figcaption><table><tr><td class="code"><pre><span class="line"># 其中 i,j,k 为index张量中元素坐标。</span><br><span class="line">self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0</span><br><span class="line">self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1</span><br><span class="line">self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><ul>
<li><strong>dim(int)</strong> 指index数组元素替代的坐标（dim = 0 替代src中的横坐标）</li>
<li><strong>index (LongTensor)</strong> 可以为空，最大与src张量形状相同</li>
<li><strong>src(Tensor or float)</strong> 源张量</li>
<li><strong>reduce</strong> 聚集函数(src替换元素与self中被替换元素执行的操作，默认是替代，可以进行add,multiply等操作)</li>
</ul>
<p>具体例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>src = torch.arange(<span class="number">1</span>, <span class="number">11</span>).reshape((<span class="number">2</span>, <span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>src</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">        [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.zeros(<span class="number">3</span>, <span class="number">5</span>, dtype=src.dtype).scatter_(<span class="number">0</span>, index, src)</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<p>以上例子中scatter函数执行的操作等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 遍历index，在dim = 0 时,替换i</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(index.shape[<span class="number">0</span>]):</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(index.shape[<span class="number">1</span>]):</span><br><span class="line">		self[index[i][j]][j] = src[i][j]</span><br></pre></td></tr></table></figure>
<h3 id="gather-函数"><a href="#gather-函数" class="headerlink" title="gather() 函数"></a>gather() 函数</h3><blockquote>
<p>Gathers values along an axis specified by dim.</p>
<p>沿着某条轴对元素进行聚集</p>
</blockquote>
<p>scatter的逆操作，挑选源张量的某些元素，放置到新张量中，具体映射规则与scatter类似：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out[i][j][k] = <span class="built_in">input</span>[index[i][j][k]][j][k]  <span class="comment"># if dim == 0</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][index[i][j][k]][k]  <span class="comment"># if dim == 1</span></span><br><span class="line">out[i][j][k] = <span class="built_in">input</span>[i][j][index[i][j][k]]  <span class="comment"># if dim == 2</span></span><br></pre></td></tr></table></figure>
<h4 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h4><ul>
<li><strong>input</strong> 输入张量</li>
<li><strong>dim</strong> 聚集的轴</li>
<li><strong>index</strong> 聚集的index张量</li>
</ul>
<p>具体例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(t, <span class="number">1</span>, torch.tensor([[<span class="number">0</span>, <span class="number">1</span>]]))</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure>
<p>以上例子中gather()函数等价于scatter()函数的操作:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 遍历index，在dim = 1 时,替换j</span><br><span class="line">for i in range(index.shape[0]):</span><br><span class="line">	for j in range(index.shape[1]):</span><br><span class="line">		result[i][j] = input[i][index[i][j]]</span><br></pre></td></tr></table></figure>
<h3 id="scatter-vs-gather"><a href="#scatter-vs-gather" class="headerlink" title="scatter vs gather"></a>scatter vs gather</h3><p>相同点:</p>
<ul>
<li>scatter 和 gather 函数都是根据index数组从 src/input 源张量中选取指定元素</li>
</ul>
<p>不同点：</p>
<ul>
<li>scatter选取元素放置到目标张量中，放置位置由<code>index[i][j]</code>决定</li>
<li>gather选取元素放置组成新的张量，选取位置由<code>index[i][j]</code>决定</li>
</ul>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><h4 id="1-使用scatter函数将向量转化为one-hot形式"><a href="#1-使用scatter函数将向量转化为one-hot形式" class="headerlink" title="1. 使用scatter函数将向量转化为one-hot形式"></a>1. 使用scatter函数将向量转化为one-hot形式</h4><p>以转化为<code>n x 10</code>的n个10维行one-hot向量为例子:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.tensor([<span class="number">9</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t.view(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">tensor([[<span class="number">9</span>],</span><br><span class="line">        [<span class="number">8</span>],</span><br><span class="line">        [<span class="number">9</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>],</span><br><span class="line">        [<span class="number">7</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>one_hot = torch.zeros(t.shape[<span class="number">0</span>],<span class="number">10</span>).scatter(<span class="number">1</span>,t.view(-<span class="number">1</span>,<span class="number">1</span>),<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ont_hot</span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure>
<p>使用argmax转化回去:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; one_hot.argmax(dim = 1,keepdim = True)</span><br><span class="line">tensor([[9],</span><br><span class="line">        [8],</span><br><span class="line">        [9],</span><br><span class="line">        [5],</span><br><span class="line">        [6],</span><br><span class="line">        [7]])</span><br></pre></td></tr></table></figure>
<h3 id="待补充"><a href="#待补充" class="headerlink" title="待补充"></a>待补充</h3>]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>model_selection模块进行交叉验证</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/model-selection%E6%A8%A1%E5%9D%97%E8%BF%9B%E8%A1%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<p>为了避免模型过拟合，通过添加<strong>验证集</strong>，模型训练完成后使用<strong>验证集</strong>验证模型的效果后，再对测试集进行测试。</p>
<h3 id="训练集和测试集划分"><a href="#训练集和测试集划分" class="headerlink" title="训练集和测试集划分"></a>训练集和测试集划分</h3><p>使用train_test_split函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载鸢尾花数据集</span></span><br><span class="line">&gt;&gt; x_data, y_data = datasets.load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 划分测试集和训练集</span></span><br><span class="line">&gt;&gt; x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = <span class="number">0.2</span>, random_state = <span class="number">42</span>)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(x_train.shape)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(x_test.shape)</span><br><span class="line">(<span class="number">120</span>, <span class="number">4</span>)</span><br><span class="line">(<span class="number">30</span>, <span class="number">4</span>)</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">&gt;&gt; clf = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">1</span>).fit(X_train, y_train)</span><br><span class="line">&gt;&gt; clf.score(X_test, y_test)</span><br><span class="line"><span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h3 id="cross-validation-交叉验证"><a href="#cross-validation-交叉验证" class="headerlink" title="cross validation 交叉验证"></a>cross validation 交叉验证</h3><p><img src="sklearn model_selection模块进行交叉验证/image-20210709165817836.png" alt="image-20210709165817836"></p>
<h4 id="cross-val-score函数进行模型交叉验证评价"><a href="#cross-val-score函数进行模型交叉验证评价" class="headerlink" title="cross_val_score函数进行模型交叉验证评价"></a>cross_val_score函数进行模型交叉验证评价</h4><p>简单使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">&gt;&gt; clf = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">1</span>, random_state=<span class="number">42</span>)</span><br><span class="line">&gt;&gt; scores = cross_val_score(clf, x_data, y_data, cv = <span class="number">5</span>)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(scores)</span><br><span class="line">[<span class="number">0.96666667</span> <span class="number">1.</span>         <span class="number">0.96666667</span> <span class="number">0.96666667</span> <span class="number">1.</span>        ]</span><br></pre></td></tr></table></figure>
<p>通过scoring参数，自定义评估函数，如果不显示指定，则调用estimator的默认score函数</p>
<p><img src="sklearn model_selection模块进行交叉验证/image-20210604090841624.png" alt="image-20210604090841624"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; scores = cross_val_score(clf, x_data, y_data, cv = <span class="number">5</span>, scoring = <span class="string">&#x27;f1_macro&#x27;</span>)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(scores)</span><br><span class="line">[<span class="number">0.96658312</span> <span class="number">1.</span>         <span class="number">0.96658312</span> <span class="number">0.96658312</span> <span class="number">1.</span>        ]</span><br></pre></td></tr></table></figure>
<p>cv参数不止可以传入k折的折数，还可以传入<strong>cross-validation generator or an iterable</strong>等</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 传入交叉验证生成器</span></span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> ShuffleSplit</span><br><span class="line">&gt;&gt; cv = ShuffleSplit(n_splits=<span class="number">5</span>, test_size=<span class="number">0.2</span>, random_state= <span class="number">42</span>)</span><br><span class="line">&gt;&gt; cross_val_score(clf, x_data, y_data, cv=cv)</span><br><span class="line">array([<span class="number">1.</span>        , <span class="number">1.</span>        , <span class="number">0.96666667</span>, <span class="number">0.93333333</span>, <span class="number">0.96666667</span>])</span><br><span class="line"><span class="comment"># 传入index生成迭代器（教程代码）</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">custom_cv_2folds</span>(<span class="params">X</span>):</span></span><br><span class="line"><span class="meta">... </span>    n = X.shape[<span class="number">0</span>]</span><br><span class="line"><span class="meta">... </span>    i = <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">while</span> i &lt;= <span class="number">2</span>:</span><br><span class="line"><span class="meta">... </span>        idx = np.arange(n * (i - <span class="number">1</span>) / <span class="number">2</span>, n * i / <span class="number">2</span>, dtype=<span class="built_in">int</span>)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> idx, idx</span><br><span class="line"><span class="meta">... </span>        i += <span class="number">1</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>custom_cv = custom_cv_2folds(X)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(clf, X, y, cv=custom_cv)</span><br><span class="line">array([<span class="number">1.</span>        , <span class="number">0.973</span>...])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>pytroch如何对梯度追踪张量进行inplace操作</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/pytorch%E5%A6%82%E4%BD%95%E5%AF%B9%E6%A2%AF%E5%BA%A6%E8%BF%BD%E8%B8%AA%E5%BC%A0%E9%87%8F%E8%BF%9B%E8%A1%8Cinplace%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="如何对梯度追踪张量进行inplace操作"><a href="#如何对梯度追踪张量进行inplace操作" class="headerlink" title="如何对梯度追踪张量进行inplace操作"></a>如何对梯度追踪张量进行inplace操作</h3><blockquote>
<p>别忘了梯度追踪张量必须为float</p>
<p>Only Tensors of floating point and complex dtype can require gradients</p>
</blockquote>
<h4 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h4><p>当对设置了requires_grad=True的张量进行原地操作时，pytorch会抛出运行错误：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt; X = torch.rand((3,4),requires_grad = True)</span><br><span class="line">&gt;&gt; X.fill_(0)</span><br><span class="line">RuntimeError: a leaf Variable that requires grad is being used in an in-place operation.</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>什么情况下会进行原地操作（当前遇到的）:</p>
<ul>
<li>模型参数初始化</li>
<li>自定义实现梯度下降法</li>
<li>避免梯度积累，每次训练进行梯度清零</li>
</ul>
<h4 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h4><ol>
<li><p>使用 .data 或 .detach() 方法，获得原张量的同内存但不进行梯度追踪的张量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="built_in">print</span>(X)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(X.data.requires_grad)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(X.detach().requires_grad)</span><br><span class="line">tensor([[<span class="number">0.2407</span>, <span class="number">0.3222</span>, <span class="number">0.4246</span>, <span class="number">0.3125</span>],</span><br><span class="line">        [<span class="number">0.1386</span>, <span class="number">0.7018</span>, <span class="number">0.1751</span>, <span class="number">0.0617</span>],</span><br><span class="line">        [<span class="number">0.3467</span>, <span class="number">0.5178</span>, <span class="number">0.2557</span>, <span class="number">0.9855</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>使用该不追踪梯度张量替代执行inplace操作</p>
<pre><code># 自定义实现梯度下降
net.weight.detach().sub_(net.weight.grad,alpha = lr)
net.bias.detach().sub_(net.bias.grad,alpha = lr)
</code></pre></li>
<li><p>.data 与 .detach()的区别在于</p>
<ul>
<li><p>.data 的inplace修改自动求导不监控，如果修改了梯度追踪节点的值，可能导致求导结果错误</p>
</li>
<li><p>.detach() 的inplace修改自动求导同样监控，如果修改了梯度追踪节点的值再进行求导，系统会报错</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<pre><code> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 正常使用</span><br><span class="line">&gt;&gt; X = torch.tensor([[5, 1, 9],[6, 5, 7]],requires_grad = True,dtype = torch.float)</span><br><span class="line">&gt;&gt; print(X)</span><br><span class="line">&gt;&gt; Y = X ** 2</span><br><span class="line">&gt;&gt; Y.sum().backward()</span><br><span class="line"># 梯队为2X</span><br><span class="line">&gt;&gt; print(X.grad)</span><br><span class="line">tensor([[5., 1., 9.],</span><br><span class="line">        [6., 5., 7.]], requires_grad=True)</span><br><span class="line">tensor([[10.,  2., 18.],</span><br><span class="line">        [12., 10., 14.]])</span><br></pre></td></tr></table></figure>

 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用data</span><br><span class="line">&gt;&gt; X = torch.tensor([[5, 1, 9],[6, 5, 7]],requires_grad = True,dtype = torch.float)</span><br><span class="line">&gt;&gt; print(X)</span><br><span class="line">&gt;&gt;  = X ** 2</span><br><span class="line">&gt;&gt; X.data *= 2</span><br><span class="line">&gt;&gt; Y.sum().backward()</span><br><span class="line">&gt;&gt; print(Y)</span><br><span class="line"># 梯队为(梯度相较于正常的放大了两倍)</span><br><span class="line">&gt;&gt; print(X.grad)</span><br><span class="line">tensor([[5., 1., 9.],</span><br><span class="line">        [6., 5., 7.]], requires_grad=True)</span><br><span class="line">tensor([[25.,  1., 81.],</span><br><span class="line">        [36., 25., 49.]], grad_fn=&lt;PowBackward0&gt;)</span><br><span class="line">tensor([[20.,  4., 36.],</span><br><span class="line">        [24., 20., 28.]])</span><br></pre></td></tr></table></figure>

 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用detach()</span><br><span class="line">X = torch.tensor([[5, 1, 9],[6, 5, 7]],requires_grad = True,dtype = torch.float)</span><br><span class="line">print(X)</span><br><span class="line">Y = X ** 2</span><br><span class="line">X.detach().add_(100)</span><br><span class="line">Y.sum().backward()</span><br><span class="line">print(Y)</span><br><span class="line"># 梯队为(梯度相较于正常的放大了两倍)</span><br><span class="line">print(X.grad)</span><br><span class="line">直接报错:</span><br><span class="line">RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [2, 3]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).</span><br></pre></td></tr></table></figure>
</code></pre><ul>
<li>detach() 与 detach_()的区别<ul>
<li>detach_()不仅获得未追踪梯度同内存tensor，还将当前节点设置为叶子节点（即求梯度是求到当前节点停止，不在向前继续计算，截断方向传播计算图）</li>
</ul>
</li>
</ul>
<ol>
<li><p>使用pytorch的init模块初始化模块参数</p>
<blockquote>
<p>torch.nn.init+初始化函数名</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 正态分布初始化</span></span><br><span class="line">net = nn.Linear(feature_num, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> net.parameters():</span><br><span class="line">    nn.init.normal_(param, mean=<span class="number">0</span>, std=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="自动求导相关属性"><a href="#自动求导相关属性" class="headerlink" title="自动求导相关属性"></a>自动求导相关属性</h3><ul>
<li><p><strong>requires_grad</strong> 是否进行梯度追踪</p>
<blockquote>
<p>Is <code>True</code> if gradients need to be computed for this Tensor, <code>False</code> otherwise.</p>
</blockquote>
</li>
<li><p><strong>grad</strong> 存储梯度的tensor数组，未进行反向传播计算时为None，多次计算梯度会进行累加</p>
<blockquote>
<p>This attribute is <code>None</code> by default and becomes a Tensor the first time a call to <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.backward"><code>backward()</code></a> computes gradients for <code>self</code>. The attribute will then contain the gradients computed and future calls to <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.backward"><code>backward()</code></a> will accumulate (add) gradients into it.</p>
</blockquote>
</li>
<li><p><strong>is_leaf</strong>  所有用户创建的梯度追踪结点为叶子节点,只有叶子节点的梯度值会被计算,可通过retrain_grad()获得非叶子节点的梯度</p>
<blockquote>
<p>All Tensors that have <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.requires_grad"><code>requires_grad</code></a> which is <code>False</code> will be leaf Tensors by convention.</p>
<p>For Tensors that have <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.requires_grad"><code>requires_grad</code></a> which is <code>True</code>, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so <code>grad_fn</code> is None.</p>
<p>Only leaf Tensors will have their <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.grad"><code>grad</code></a> populated during a call to <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.backward"><code>backward()</code></a>. To get <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.grad"><code>grad</code></a> populated for non-leaf Tensors, you can use <a href="https://pytorch.org/docs/stable/autograd.html?highlight=grad#torch.Tensor.retain_grad"><code>retain_grad()</code></a>.</p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch模型定义</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/pytorch%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89/</url>
    <content><![CDATA[<h2 id="pytorch模型定义的几种方式"><a href="#pytorch模型定义的几种方式" class="headerlink" title="pytorch模型定义的几种方式"></a>pytorch模型定义的几种方式</h2><p>主要包括 标准继承模式 和 使用常用容器 两种方式</p>
<h3 id="1-继承nn-Module实现模型"><a href="#1-继承nn-Module实现模型" class="headerlink" title="1. 继承nn.Module实现模型"></a>1. 继承nn.Module实现模型</h3><p>通过继承nn模块的Module基类，并实现初始化<strong>init</strong>()以及forward()方法，实现模型定义</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># 模型的初始化方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 首先调用父类构造方法</span></span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        <span class="comment"># 定义各层模型，层与层之间的权重</span></span><br><span class="line">        self.hidden = nn.Linear(<span class="number">128</span>, <span class="number">16</span>) <span class="comment"># 隐藏层</span></span><br><span class="line">        self.activate = nn.ReLU()</span><br><span class="line">        self.output = nn.Linear(<span class="number">16</span>, <span class="number">10</span>)  <span class="comment"># 输出层</span></span><br><span class="line">    <span class="comment"># 模型的计算方法  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.activate(self.hidden(x))</span><br><span class="line">        <span class="keyword">return</span> self.output(x)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>模型的使用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">test_input = torch.rand((256,128))</span><br><span class="line">net = Model()</span><br><span class="line">print(net(test_input))</span><br><span class="line">print(net)</span><br><span class="line">输出:</span><br><span class="line">tensor([[ 0.2073, -0.0732,  0.1259,  ...,  0.1715,  0.1540,  0.1089],</span><br><span class="line">        [ 0.2999, -0.0407,  0.1167,  ...,  0.1734,  0.2581,  0.0695],</span><br><span class="line">        [ 0.3761, -0.0145,  0.1217,  ...,  0.1910,  0.2665,  0.0340],</span><br><span class="line">        ...,</span><br><span class="line">        [ 0.3084, -0.1336,  0.1632,  ...,  0.2174, -0.0351,  0.1205],</span><br><span class="line">        [ 0.3323, -0.1693,  0.1411,  ...,  0.1700,  0.1171, -0.0442],</span><br><span class="line">        [ 0.3395,  0.0367, -0.0068,  ...,  0.2706,  0.2510,  0.0017]],</span><br><span class="line">       grad_fn=&lt;AddmmBackward&gt;)</span><br><span class="line">Model(</span><br><span class="line">  (hidden): Linear(in_features=128, out_features=16, bias=True)</span><br><span class="line">  (activate): ReLU()</span><br><span class="line">  (output): Linear(in_features=16, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="2-快速定义模型"><a href="#2-快速定义模型" class="headerlink" title="2. 快速定义模型"></a>2. 快速定义模型</h3><p>pytorch提供了一系列继承自nn.Module的实现类，类如Sequential等用来快速定义模型</p>
<h4 id="1-nn-Sequential"><a href="#1-nn-Sequential" class="headerlink" title="1. nn.Sequential"></a>1. nn.Sequential</h4><blockquote>
<p>A sequential container. Modules will be added to it in the order they are passed in the constructor. Alternatively, an ordered dict of modules can also be passed in.</p>
</blockquote>
<p>向Sequential中传入一系列的层/其他模型（Module），按照传入的顺序或者OrderedDict中的顺序进行前向传播计算，实现模型定义</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Example of using Sequential</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example of using Sequential with OrderedDict</span></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">1</span>,<span class="number">20</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU()),</span><br><span class="line">          (<span class="string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="number">20</span>,<span class="number">64</span>,<span class="number">5</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu2&#x27;</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line">输出:</span><br><span class="line">Sequential(</span><br><span class="line">  (conv1): Conv2d(<span class="number">1</span>, <span class="number">20</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu1): ReLU()</span><br><span class="line">  (conv2): Conv2d(<span class="number">20</span>, <span class="number">64</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu2): ReLU()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="2-nn-ModuleList"><a href="#2-nn-ModuleList" class="headerlink" title="2.nn.ModuleList"></a>2.nn.ModuleList</h4><blockquote>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html?highlight=modulelist#torch.nn.ModuleList"><code>ModuleList</code></a> can be indexed like a regular Python list, but modules it contains are properly registered, and will be visible by all <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module"><code>Module</code></a> methods.</p>
</blockquote>
<p>存储module的列表，支持列表的append，insert操作，并可通过坐标形式访问</p>
<ul>
<li>与sequence不同点，在于ModuList就是个List，不支持forward前向传播运算</li>
<li>与List不同点，在于ModuList中所有模型的参数均加入到了反向传播梯度计算监控中</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MyModule(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(MyModule, self).__init__()</span><br><span class="line">        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # ModuleList can act as an iterable, or be indexed using ints</span><br><span class="line">        for i, l in enumerate(self.linears):</span><br><span class="line">            x = self.linears[i // 2](x) + l(x)</span><br><span class="line">        return x</span><br><span class="line">net = MyModule()</span><br><span class="line">print(net)</span><br><span class="line">输出:</span><br><span class="line">MyModule(</span><br><span class="line">  (linears): ModuleList(</span><br><span class="line">    (0): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (1): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (2): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (3): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (4): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (5): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (6): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (7): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (8): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">    (9): Linear(in_features=10, out_features=10, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>与列表存储模型不同点比较</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MyModule1(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(MyModule1, self).__init__()</span><br><span class="line">        self.linearList = [nn.Linear(i,i) for i in range(1,3)]</span><br><span class="line">class MyModule2(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(MyModule2, self).__init__()</span><br><span class="line">        self.linearList = nn.ModuleList([nn.Linear(i,i) for i in range(1, 3)])</span><br><span class="line">net1 = MyModule1()</span><br><span class="line">net2 = MyModule2()</span><br><span class="line">print(&#x27;net1:&#x27;)</span><br><span class="line">for parameter in net1.parameters():</span><br><span class="line">    print(parameter)</span><br><span class="line">print(&#x27;net2:&#x27;)</span><br><span class="line">for parameter in net2.parameters():</span><br><span class="line">    print(parameter)</span><br><span class="line">输出:</span><br><span class="line">net1:</span><br><span class="line">net2:</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[0.9031]], requires_grad=True)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([0.8702], requires_grad=True)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ 0.4465, -0.2073],</span><br><span class="line">        [-0.3850, -0.6185]], requires_grad=True)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([-0.1432, -0.6002], requires_grad=True)</span><br><span class="line"></span><br><span class="line">#### 3. nn.MoudleDict</span><br><span class="line"></span><br><span class="line">类似于Modulist，只是存储形式为Dict</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>sklearn主要模块理解</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/sklearn%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>主要包括六个模块，其中四个模块为<strong>分类，回归，聚类，降维</strong>的算法模块，两个其他模型，模型选择评估模块和预处理模块。</p>
<img src="/2021/07/09/DL%E7%BC%96%E7%A8%8B/sklearn%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97%E7%90%86%E8%A7%A3/image-20210709164825577.png" class="" title="image-20210709164825577">
<span id="more"></span>
<h3 id="一个数据分析流程中涉及的sklearn模块"><a href="#一个数据分析流程中涉及的sklearn模块" class="headerlink" title="一个数据分析流程中涉及的sklearn模块"></a>一个数据分析流程中涉及的sklearn模块</h3><p>机器学习项目的一般流程为 <strong>数据集获取</strong>-》<strong>数据预处理</strong>-》<strong>训练模型</strong>-》<strong>评估模型</strong>-》<strong>应用模型</strong></p>
<ol>
<li><p>获取数据集，使用dataset模块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"><span class="comment"># 返回一个包含data和target的字典</span></span><br><span class="line">iris_data = iris.data</span><br><span class="line">iris_target = iris.target</span><br></pre></td></tr></table></figure>
<p>包含常用的数据集加载</p>
<img src="/2021/07/09/DL%E7%BC%96%E7%A8%8B/sklearn%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97%E7%90%86%E8%A7%A3/image-20210709164843880.png" class="" title="image-20210709164843880">
</li>
<li><p>数据预处理，使用sklearn的Preprocessing模块</p>
<p>包括常用的归一化、one_hot等处理方式</p>
<img src="/2021/07/09/DL%E7%BC%96%E7%A8%8B/sklearn%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97%E7%90%86%E8%A7%A3/image-20210709164855098.png" class="" title="image-20210709164855098">
</li>
<li><p>划分数据集，使用model_selection模块中的划分函数（不同的训练集测试集划分方式)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<img src="/2021/07/09/DL%E7%BC%96%E7%A8%8B/sklearn%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97%E7%90%86%E8%A7%A3/image-20210709164909443.png" class="" title="image-20210709164909443">
</li>
<li><p>模型选择，直接导入特定模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">clf = svm.SVC(gamma=<span class="number">0.001</span>, C=<span class="number">100.</span>)</span><br><span class="line"><span class="comment"># 训练模型fit</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(clf.get_params())</span><br><span class="line"><span class="comment"># 评价模型</span></span><br><span class="line"><span class="built_in">print</span>(clf.score(X_test,y_test))</span><br></pre></td></tr></table></figure>
</li>
<li><p>评价模型，使用metircs模块进行评价</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy_score(y_test, clf.predict(X_test))</span><br></pre></td></tr></table></figure>
<img src="/2021/07/09/DL%E7%BC%96%E7%A8%8B/sklearn%E4%B8%BB%E8%A6%81%E6%A8%A1%E5%9D%97%E7%90%86%E8%A7%A3/image-20210709164919754.png" class="" title="image-20210709164919754">
</li>
</ol>
]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>优化算法学习总结</title>
    <url>/2021/07/21/DL%E7%BC%96%E7%A8%8B/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="1-动量梯度下降"><a href="#1-动量梯度下降" class="headerlink" title="1. 动量梯度下降"></a>1. 动量梯度下降</h3><p>为了解决随机梯度梯度下降存在的震荡问题，通过添加动量，平滑动量变化。</p>
<h4 id="什么是指数加权平均"><a href="#什么是指数加权平均" class="headerlink" title="什么是指数加权平均"></a>什么是指数加权平均</h4><p>当前步的函数值不仅取决于当前的输入，还取决于之前的函数值，公式如下</p>
<script type="math/tex; mode=display">
v_t = \beta v_{t-1}+(1-\beta)\theta_t</script><p>通过不断带入展开，可得只包含 <script type="math/tex">\theta</script> 的表达式为</p>
<script type="math/tex; mode=display">
v_t = (1-\beta)\theta_t + (1-\beta)\beta\theta_{t-1} + (1-\beta)\beta^2\theta_{t-2}+....+(1-\beta)\beta^n\theta_{t-n}+\beta^nv_{t-n}</script><img src="/2021/07/21/DL%E7%BC%96%E7%A8%8B/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20210720092013215.png" class="" title="image-20210720092013215">
<p>由于 <script type="math/tex">(1-\frac{1}{n})^n</script> 在n趋向于无穷时等于 <script type="math/tex">e^{-1}</script>。当 <script type="math/tex">\beta</script> 趋向于1时，<script type="math/tex">\beta^{\frac{1}{1-\beta}} = (1-\frac{1}{n})^n</script> 同样等于 <script type="math/tex">e^{-1}</script>,如果将 <script type="math/tex">e^{-1}</script>看作一个可以忽略的数字，则展开式中含有阶数大于等于 <script type="math/tex">\theta^{\frac{1}{1-\theta}}</script> 的相可以忽略。</p>
<ul>
<li>当 <script type="math/tex">\beta = 0.98</script>​时，<script type="math/tex">\beta^{\frac{1}{1-\beta}} = \beta^{20}</script>​ ,所以所有系数包含<script type="math/tex">\beta^n</script>​ n&gt;=20的均省略，原式子等价于前20个<script type="math/tex">\theta</script>​的加权平均和，<strong>即当前梯度等于前20个梯度的加权平均和</strong><span id="more"></span>
</li>
</ul>
<h4 id="动量梯度下降公式"><a href="#动量梯度下降公式" class="headerlink" title="动量梯度下降公式"></a>动量梯度下降公式</h4><p>假设第 <script type="math/tex">t</script> 次训练的输入为 <script type="math/tex">x_t</script> ,学习率为<script type="math/tex">\eta_t</script>,计算得到梯度为 <script type="math/tex">g_t</script> ,并定义速度向量 <script type="math/tex">v_t</script>,初始化为0；动量系数为m</p>
<script type="math/tex; mode=display">
v_t = m * v_{t-1} + \eta * g_t \\
x_t = x_{t-1} - v_t</script><p>其中 <script type="math/tex">0<m<1</script>，当 <script type="math/tex">m=0</script> 时等价于随机梯度下降</p>
<p><strong>通过对历史梯度进行指数加权平均，实现了梯度的平滑变换，确保了相邻梯度方向的一致性，解决了梯度下降的震荡问题。</strong></p>
<h3 id="2-AdaGrad算法"><a href="#2-AdaGrad算法" class="headerlink" title="2. AdaGrad算法"></a>2. AdaGrad算法</h3><p>为解决不同方向梯度大小变化不同，导致学习率设置的问题，adagrad算法根据每个方向梯度大小，不断更新学习率</p>
<h4 id="AdaGrad公式"><a href="#AdaGrad公式" class="headerlink" title="AdaGrad公式"></a>AdaGrad公式</h4><p>首先定义向量 <script type="math/tex">s_t</script> ,初始化为0，每次迭代累加梯度的内积，递归公式为</p>
<script type="math/tex; mode=display">
s_t = s_{t-1} + g_i * g_i</script><p>更新目标参数是，使用  <script type="math/tex">s_t</script> 更新学习率大小,其中 <script type="math/tex">\epsilon</script> 为为保持数值稳定性添加的常数</p>
<script type="math/tex; mode=display">
x_t = x_{t-1} - \frac{\eta}{\sqrt{s_t+\epsilon}}*g_t</script><p><strong>AdaGrad算法能够根据梯度大小设置学习率，梯度越大，学习率越小，但是由于 $s_t$ 为累加形式，学习率随着训练会不断减小，到后期学习速率可能过慢</strong></p>
<h3 id="3-RMSprop算法"><a href="#3-RMSprop算法" class="headerlink" title="3. RMSprop算法"></a>3. RMSprop算法</h3><p>为了解决AdAGrad算法后期，学习率过小可能无法找到最优解的问题，在计算 $s_t$ 时引入加权平均</p>
<h4 id="RMSprop公式"><a href="#RMSprop公式" class="headerlink" title="RMSprop公式"></a>RMSprop公式</h4><p>引入加权平均后的 $s_t$ 计算公式如下，避免了学习率的不断减小</p>
<script type="math/tex; mode=display">
s_t = \theta s_{t-1} + (1-\theta)g_i * g_i</script><h3 id="4-AdaDelta算法"><a href="#4-AdaDelta算法" class="headerlink" title="4. AdaDelta算法"></a>4. AdaDelta算法</h3><p>舍弃了学习率这一参数，从另一个角度解决AdaGrad后期学习率变小，难以找到最优解的问题</p>
<h4 id="AdaDelta公式"><a href="#AdaDelta公式" class="headerlink" title="AdaDelta公式"></a>AdaDelta公式</h4><p>$s_t$递推公式与RMSprop一致</p>
<script type="math/tex; mode=display">
s_t = \theta s_{t-1} + (1-\theta)g_i * g_i</script><p>增加了状态 $\Delta x_t$,计算梯度  $g’_t$ </p>
<script type="math/tex; mode=display">
g'_t = \sqrt{\frac{\Delta x_{t-1} + \epsilon}{s_t + \epsilon}}*g_t</script><p>使用 $g’_t$  更新参数</p>
<script type="math/tex; mode=display">
x_t = x_{t-1} - g'_t</script><p>其中状态 $\Delta x_t$ 的递推公式为</p>
<script type="math/tex; mode=display">
\Delta x_t = \theta \Delta x_{t-1} + (1-\theta)g'_i * g'_i</script><p><strong>与RMSprop算法区别点在于学习率也通过指数加权平均递归计算</strong></p>
<h3 id="5-Adam算法"><a href="#5-Adam算法" class="headerlink" title="5. Adam算法"></a>5. Adam算法</h3><p>Adam算法结合了动量法和RMSprop法，对梯度和$s_t$ 均进行了指数加权平均</p>
<p>$s_t$递推公式($\theta_1$  建议为0.999）</p>
<script type="math/tex; mode=display">
s_t = \theta_1 s_{t-1} + (1-\theta_1)g_i * g_i</script><p>$v_t$ 递推公式($\theta_2$  建议为0.9）</p>
<script type="math/tex; mode=display">
v_t = \theta_2 * v_{t-1} + \theta_2 * g_t</script><p>由于 $s_t$ 和 $v_t$ 在递推初始化时初始化为0，根据递推公式中 $\theta_1$ 和 $\theta_2$  均为接近于1的数，导致在训练初期， $s_t$ 和 $v_t$ 取值与梯度关系不大，更加趋向于0，因此需要增加 <strong>误差修正(bias correction)</strong> 操作</p>
<script type="math/tex; mode=display">
s'_t = \frac{s_t}{1-\theta_1^t}\\
v'_t = \frac{v_t}{1-\theta_2^t}</script><p>使用修正后的两个参数计算新梯度</p>
<script type="math/tex; mode=display">
g'_t =\frac{\eta v'_t}{\sqrt{s'_t} + \epsilon}</script><p>更新参数公式为</p>
<script type="math/tex; mode=display">
x_t = x_{t-1} - g'_t</script><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><img src="/2021/07/21/DL%E7%BC%96%E7%A8%8B/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/image-20210720143613685.png" class="" title="image-20210720143613685">
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
  </entry>
  <entry>
    <title>sklearn数据预处理一般流程</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<blockquote>
<p>The <code>sklearn.preprocessing</code> package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.</p>
</blockquote>
<p>sklearn的preprocessing模块提供了一系列包括标准化、数据最大最小缩放处理、正则化、特征二值化和数据缺失值处理在内的数据预处理模块。</p>

<p>基本操作流程为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.创建预处理器 transform</span></span><br><span class="line">test_scaler = StandardScaler()</span><br><span class="line"><span class="comment"># 2. 调用fit函数 计算预处理所需要的相关数据(如StandardScaler会计算mean、var等)</span></span><br><span class="line">test_scaler.fit(<span class="built_in">input</span>)</span><br><span class="line"><span class="comment"># 3. 调用transform函数对数据进行预处理</span></span><br><span class="line">test_scaler.transform(<span class="built_in">input</span>)</span><br><span class="line"><span class="comment"># 或者直接合并fit和transform两部操作</span></span><br><span class="line">test_scaler.fit_transform(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="1-标准化"><a href="#1-标准化" class="headerlink" title="1. 标准化"></a>1. 标准化</h2><h3 id="使用StandardScaler（mean-1-std-0）"><a href="#使用StandardScaler（mean-1-std-0）" class="headerlink" title="使用StandardScaler（mean = 1,std = 0）"></a>使用StandardScaler（mean = 1,std = 0）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">&gt;&gt; <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">&gt;&gt; test_array = np.arange(<span class="number">0</span>,<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">       [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line">&gt;&gt; test_scaler = StandardScaler()</span><br><span class="line">&gt;&gt; test_scaler.fit(test_array)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_scaler.var_)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_scaler.mean_)</span><br><span class="line">&gt;&gt; test_scaler.transform(test_array, copy = <span class="literal">True</span>)</span><br><span class="line">[<span class="number">10.66666667</span> <span class="number">10.66666667</span> <span class="number">10.66666667</span> <span class="number">10.66666667</span>]</span><br><span class="line">[<span class="number">4.</span> <span class="number">5.</span> <span class="number">6.</span> <span class="number">7.</span>]</span><br><span class="line">array([[-<span class="number">1.22474487</span>, -<span class="number">1.22474487</span>, -<span class="number">1.22474487</span>, -<span class="number">1.22474487</span>],</span><br><span class="line">       [ <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ,  <span class="number">0.</span>        ],</span><br><span class="line">       [ <span class="number">1.22474487</span>,  <span class="number">1.22474487</span>,  <span class="number">1.22474487</span>,  <span class="number">1.22474487</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="使用MaxMinScaler进行区间缩放（默认0-1）"><a href="#使用MaxMinScaler进行区间缩放（默认0-1）" class="headerlink" title="使用MaxMinScaler进行区间缩放（默认0-1）"></a>使用MaxMinScaler进行区间缩放（默认0-1）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">&gt;&gt; test_array = np.random.uniform(low=-<span class="number">1</span>, high=<span class="number">16</span>, size=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_array)</span><br><span class="line">[[<span class="number">10.45968472</span>  <span class="number">6.52372993</span> <span class="number">12.08526458</span>]</span><br><span class="line"> [ <span class="number">9.94529398</span>  <span class="number">6.3849395</span>   <span class="number">6.22910917</span>]</span><br><span class="line"> [<span class="number">12.02516025</span> <span class="number">11.50269044</span>  <span class="number">6.380779</span>  ]</span><br><span class="line"> [<span class="number">14.67759022</span>  <span class="number">0.36908024</span>  <span class="number">1.13677392</span>]]</span><br><span class="line">[<span class="number">0.42262781</span> <span class="number">0.17963625</span> <span class="number">0.18267358</span>]</span><br><span class="line"><span class="comment"># 传入要缩放的区间</span></span><br><span class="line">&gt;&gt; test_scaler = MinMaxScaler((-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">&gt;&gt; test_scaler.fit(test_array)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_scaler.scale_)</span><br><span class="line">&gt;&gt; test_scaler.transform(test_array)</span><br><span class="line">array([[-<span class="number">0.78260417</span>,  <span class="number">0.1055982</span> ,  <span class="number">1.</span>        ],</span><br><span class="line">       [-<span class="number">1.</span>        ,  <span class="number">0.08066641</span>, -<span class="number">0.06976488</span>],</span><br><span class="line">       [-<span class="number">0.12099067</span>,  <span class="number">1.</span>        , -<span class="number">0.04205881</span>],</span><br><span class="line">       [ <span class="number">1.</span>        , -<span class="number">1.</span>        , -<span class="number">1.</span>        ]])</span><br></pre></td></tr></table></figure>
<h3 id="使用MaxAbsScaler稀疏数据标准化"><a href="#使用MaxAbsScaler稀疏数据标准化" class="headerlink" title="使用MaxAbsScaler稀疏数据标准化"></a>使用MaxAbsScaler稀疏数据标准化</h3><p>为了避免标准化过程中破坏稀疏数据的稀疏性质，使用MaxAbsScaler,根据样本数据除以最大绝对值，实现到[-1, 1]的映射</p>
<h3 id="使用RobustScaler带有离群值的数据标准化"><a href="#使用RobustScaler带有离群值的数据标准化" class="headerlink" title="使用RobustScaler带有离群值的数据标准化"></a>使用RobustScaler带有离群值的数据标准化</h3><h2 id="2-非线性转化"><a href="#2-非线性转化" class="headerlink" title="2.非线性转化"></a>2.非线性转化</h2><p>主要包括概率分布转化（Quantile transforms）和正态变换（Power transforms），用来将原特定分布的特征值映射到另一个特征分布。</p>
<h3 id="使用QuantileTransformer进行均匀分布映射转换"><a href="#使用QuantileTransformer进行均匀分布映射转换" class="headerlink" title="使用QuantileTransformer进行均匀分布映射转换"></a>使用QuantileTransformer进行均匀分布映射转换</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> QuantileTransformer</span><br><span class="line">&gt;&gt; data_x, data_y = load_iris(return_X_y=<span class="literal">True</span>)</span><br><span class="line">&gt;&gt; x_train, x_test, y_train, y_test = train_test_split(data_x, data_y,  test_size = <span class="number">0.2</span>, random_state = <span class="number">42</span>)</span><br><span class="line">&gt;&gt; quantileTransformer = QuantileTransformer()</span><br><span class="line">&gt;&gt; x_train_trans = quantileTransformer.fit_transform(x_train)</span><br><span class="line">&gt;&gt; x_test_trans = quantileTransformer.fit_transform(x_test)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(np.percentile(x_train[:, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">100</span>]))</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(np.percentile(x_train_trans[:, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>, <span class="number">100</span>]))</span><br><span class="line">[<span class="number">4.3</span>  <span class="number">5.1</span>  <span class="number">5.75</span> <span class="number">6.4</span>  <span class="number">7.7</span> ]</span><br><span class="line">[<span class="number">0.</span>         <span class="number">0.24789916</span> <span class="number">0.5</span>        <span class="number">0.7605042</span>  <span class="number">1.</span>        ]</span><br></pre></td></tr></table></figure>
<h3 id="使用PowerTransformer进行正态分布映射转换"><a href="#使用PowerTransformer进行正态分布映射转换" class="headerlink" title="使用PowerTransformer进行正态分布映射转换"></a>使用PowerTransformer进行正态分布映射转换</h3><p>使用Yeo-Johnson transform和 Box-Cox transform两种变换方式（暂时还不太懂，不列举代码）</p>
<h2 id="3-标准化（Normalization）"><a href="#3-标准化（Normalization）" class="headerlink" title="3.标准化（Normalization）"></a>3.标准化（<strong>Normalization</strong>）</h2><p>直接使用normalize函数，有三种归一化方式 <code>&#123;‘l1’, ‘l2’, ‘max’&#125;, default=’l2’</code> ，坑爹的是默认使用行向量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line">&gt;&gt; test_array = np.arange(<span class="number">3</span>, <span class="number">15</span>).reshape(<span class="number">2</span>, <span class="number">6</span>)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_array)</span><br><span class="line">&gt;&gt; result = preprocessing.normalize(test_array, norm = <span class="string">&#x27;l1&#x27;</span>, axis = <span class="number">0</span>)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(result)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(result.<span class="built_in">sum</span>(axis = <span class="number">0</span>))</span><br><span class="line">[[ <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>  <span class="number">7</span>  <span class="number">8</span>]</span><br><span class="line"> [ <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span> <span class="number">14</span>]]</span><br><span class="line">[[<span class="number">0.25</span>       <span class="number">0.28571429</span> <span class="number">0.3125</span>     <span class="number">0.33333333</span> <span class="number">0.35</span>       <span class="number">0.36363636</span>]</span><br><span class="line"> [<span class="number">0.75</span>       <span class="number">0.71428571</span> <span class="number">0.6875</span>     <span class="number">0.66666667</span> <span class="number">0.65</span>       <span class="number">0.63636364</span>]]</span><br><span class="line">[<span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br></pre></td></tr></table></figure>
<p>或者使用Normalizer类</p>
<h2 id="4-类型转化"><a href="#4-类型转化" class="headerlink" title="4.类型转化"></a>4.类型转化</h2><p>主要包括 onehot和数字顺序编码两种形式，主要涉及OneHotEncoder和OrdinalEncoder</p>
<h2 id="5-遇到继续整理。。。。"><a href="#5-遇到继续整理。。。。" class="headerlink" title="5. 遇到继续整理。。。。"></a>5. 遇到继续整理。。。。</h2><h2 id="自定义转化器"><a href="#自定义转化器" class="headerlink" title="自定义转化器"></a>自定义转化器</h2><h3 id="1-使用FunctionTransformer封装函数为转化器"><a href="#1-使用FunctionTransformer封装函数为转化器" class="headerlink" title="1.使用FunctionTransformer封装函数为转化器"></a>1.使用FunctionTransformer封装函数为转化器</h3><p>没想到怎么传入多个参数的函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line">&gt;&gt; <span class="function"><span class="keyword">def</span> <span class="title">my_power</span>(<span class="params">x, power = <span class="number">2</span></span>):</span></span><br><span class="line">    x = np.power(x, power);</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">&gt;&gt; my_transformer = FunctionTransformer(my_power)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(my_transformer)</span><br><span class="line">&gt;&gt; test_array = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(my_transformer.fit_transform(test_array))</span><br><span class="line">FunctionTransformer(func=&lt;function my_power at <span class="number">0x000001988F4543A0</span>&gt;)</span><br><span class="line">[ <span class="number">1</span>  <span class="number">4</span>  <span class="number">9</span> <span class="number">16</span>]</span><br></pre></td></tr></table></figure>
<h3 id="3-继承BaseEstimator-TransformerMixin（自动实现fit-transform）"><a href="#3-继承BaseEstimator-TransformerMixin（自动实现fit-transform）" class="headerlink" title="3. 继承BaseEstimator, TransformerMixin（自动实现fit_transform）"></a>3. 继承BaseEstimator, TransformerMixin（自动实现fit_transform）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line">rooms_ix, bedrooms_ix, population_ix, households_ix = <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span></span><br><span class="line"><span class="comment"># 通过原有属性增加一列属性（来自书籍-机器学习实战）</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CombineAttirbutesAdder</span>(<span class="params">BaseEstimator, TransformerMixin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, add_bedrooms_per_room = <span class="literal">True</span></span>):</span></span><br><span class="line">        self.add_bedrooms_per_room = add_bedrooms_per_room</span><br><span class="line">    <span class="comment"># 提取某些特征，例如归一化处理是求平均值和方差</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        rooms_per_house = X[:, rooms_ix] / X[:, households_ix]</span><br><span class="line">        pepoles_per_house = X[:, population_ix] / X[:, households_ix]</span><br><span class="line">        <span class="keyword">if</span> self.add_bedrooms_per_room:</span><br><span class="line">            bedrooms_per_house = X[:,bedrooms_ix] / X[:, households_ix]</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_house, bedrooms_per_house]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_house]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>sklearn Pipeline 组合多个预处理和预测模型</title>
    <url>/2021/07/09/DL%E7%BC%96%E7%A8%8B/%E7%BB%84%E5%90%88%E5%A4%9A%E4%B8%AA%E9%A2%84%E5%A4%84%E7%90%86%E5%92%8C%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<blockquote>
<p> Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator</p>
</blockquote>
<p>将一系列的数据预处理和模型封装在一起，固定处理数据的一系列步骤，调用一次fit和predict完成整个流程，并可使用grid search对pipeline内参数进行统一调试。</p>
<p>构成规则如下（前面处理数据，最后一步输入模型或者完全处理数据）：</p>
<ul>
<li>所有流水线中的estimator必须为transformer，除了最后一个</li>
<li>最后一个estimator可以是任何类型（trainsformer，classifier）</li>
</ul>
<p>主要函数：</p>
<ul>
<li>union为只包含transformer的pipeline</li>
</ul>

<span id="more"></span>
<h3 id="1-pipeline的基本使用"><a href="#1-pipeline的基本使用" class="headerlink" title="1. pipeline的基本使用"></a>1. pipeline的基本使用</h3><p>使用类似字典的元组链表初始化pipeline，或者使用make_pipeline()函数直接传入estimator列表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">&gt;&gt; estimators = [(<span class="string">&#x27;reduce_dim&#x27;</span>, PCA()), (<span class="string">&#x27;model&#x27;</span>, SVC())]</span><br><span class="line">&gt;&gt; test_pipeline = Pipeline(estimators)</span><br><span class="line">&gt;&gt; test_pipeline</span><br><span class="line">Pipeline(steps=[(<span class="string">&#x27;reduce_dim&#x27;</span>, PCA()), (<span class="string">&#x27;model&#x27;</span>, SVC())])</span><br></pre></td></tr></table></figure>
<p>可通过数组、字典以及step属性访问每个estimator</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="built_in">print</span>(test_pipeline[<span class="number">0</span>])</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_pipeline.steps)</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(test_pipeline[<span class="string">&#x27;reduce_dim&#x27;</span>])</span><br><span class="line">PCA()</span><br><span class="line">[(<span class="string">&#x27;reduce_dim&#x27;</span>, PCA()), (<span class="string">&#x27;model&#x27;</span>, SVC())]</span><br><span class="line">PCA()</span><br></pre></td></tr></table></figure>
<p>可使用数组的截断形式，获取子pipeline</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; <span class="built_in">print</span>(<span class="built_in">len</span>(test_pipeline))</span><br><span class="line">&gt;&gt; sub_pipeline = test_pipeline[<span class="number">1</span>:]</span><br><span class="line">&gt;&gt; <span class="built_in">print</span>(sub_pipeline)</span><br><span class="line"><span class="number">2</span></span><br><span class="line">Pipeline(steps=[(<span class="string">&#x27;model&#x27;</span>, SVC())])</span><br></pre></td></tr></table></figure>
<p>使用<code>&lt;estimator&gt;__&lt;parameter&gt;</code> 即pipeline中estimator名称+参数，设置访问pipeline中某一estimator的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt; test_pipeline.set_params(model__C = <span class="number">10</span>)</span><br><span class="line">&gt;&gt; test_pipeline.get_params()[<span class="string">&#x27;model__C&#x27;</span>]</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="comment"># 与GridSearchCV结合使用</span></span><br><span class="line">&gt;&gt; <span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">&gt;&gt; param_grid = <span class="built_in">dict</span>(reduce_dim__n_components=[<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>], clf__C=[<span class="number">0.1</span>, <span class="number">10</span>, <span class="number">100</span>])</span><br><span class="line">&gt;&gt; grid_search = GridSearchCV(test_pipeline, param_grid=param_grid)</span><br><span class="line">&gt;&gt; grid_search</span><br><span class="line">GridSearchCV(estimator=Pipeline(steps=[(<span class="string">&#x27;reduce_dim&#x27;</span>, PCA()),</span><br><span class="line">                                       (<span class="string">&#x27;model&#x27;</span>, SVC(C=<span class="number">10</span>))]),</span><br><span class="line">             param_grid=&#123;<span class="string">&#x27;clf__C&#x27;</span>: [<span class="number">0.1</span>, <span class="number">10</span>, <span class="number">100</span>],</span><br><span class="line">                         <span class="string">&#x27;reduce_dim__n_components&#x27;</span>: [<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]&#125;)</span><br></pre></td></tr></table></figure>
<h1 id="待补充。。"><a href="#待补充。。" class="headerlink" title="待补充。。"></a>待补充。。</h1>]]></content>
      <categories>
        <category>ML/DL编程总结</category>
      </categories>
      <tags>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title>lc2212.射箭比赛中的最大比赛</title>
    <url>/2022/03/27/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc2212.%E5%B0%84%E7%AE%AD%E6%AF%94%E8%B5%9B%E4%B8%AD%E7%9A%84%E6%9C%80%E5%A4%A7%E6%AF%94%E8%B5%9B/</url>
    <content><![CDATA[<h3 id="2212-射箭比赛中的最大得分"><a href="#2212-射箭比赛中的最大得分" class="headerlink" title="2212. 射箭比赛中的最大得分"></a><a href="https://leetcode-cn.com/problems/maximum-points-in-an-archery-competition/">2212. 射箭比赛中的最大得分</a></h3><p>打周赛遇到的一道非常典型的0-1背包问题，但是因为太久没写过背包问题，写了40分钟才写出来，再温习一遍。</p>
<h4 id="什么是0-1背包？"><a href="#什么是0-1背包？" class="headerlink" title="什么是0-1背包？"></a>什么是0-1背包？</h4><p>一共有N个物品，每个物品有对应的重量weight[i] 和价值value[i]，给定一个固定容量W的背包，问能够放入背包的最大价值是多少？非常经典又相对简单的动态规划问题，关键还是在于定义状态以及状态转移公式。</p>
<p>贪心的角度出发，假设我选取某个物品后，新的贪心目标变为 在剩余物品和空间的条件下，选取最大价值的物品，因此父问题到子问题的转化可以定义为：（按照从左到右一个一个选的思路）</p>
<ul>
<li><strong>父问题</strong>：是否选取第i个物品，使得总价值最大</li>
<li><strong>子问题</strong>：父问题 <strong>选 / 不选 </strong>第i个物品， 背包剩余 <strong>W-w[i] / W</strong>空间，如何在前i-1物品中合适选取使得子问题价值最大</li>
</ul>
<span id="more"></span>
<p>dp状态可以定义为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[i][j]: 将前i个物品装到容量为j的背包中的最大价值</span><br></pre></td></tr></table></figure>
<p>状态转移公式为:</p>
<ol>
<li><p>选取第i个物品</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[i][j] = v[i] + dp[i][j - w[i]]</span><br></pre></td></tr></table></figure>
</li>
<li><p>不选第i个物品（或者当前容量无法选取第i个物品）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[i][j] = dp[i - 1][j] </span><br></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li><p>最后公式为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dp[i][j] = max(v[i] + dp[i][j - w[i]], dp[i - 1][j])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>复杂度分析</strong>:</p>
<ol>
<li><strong>时间复杂度：</strong>自下而上（前i物品）计算状态，每个物品需要遍历所有的背包容量，<strong>时间复杂度为 O(NW)</strong>，即物品数量乘以背包容量</li>
<li><strong>空间复杂度：</strong> 类似时间复杂度分析，存储所有状态需要 O(NW)，若使用存储压缩，只需要一个长度等于背包容量的数组，但是若要存储解，则无法压缩，<strong>空间复杂度为 O(NW) 或者 O(W)</strong></li>
</ol>
<p><strong>模板伪代码</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># dp数组长度为w+1,多一个为了减少越界判断</span><br><span class="line">dp[0,1,2,3....,w] = 0</span><br><span class="line">for i in [0,1,2,3,4,5,6,7,8,9....n]:</span><br><span class="line">	for j in [w,w - 1,....1]:</span><br><span class="line">		# j &gt; w[i],反向遍历避免状态丢失（因为只用了一维数组存储状态）</span><br><span class="line">		dp[j] = max(dp[j], dp[j−w[i]]+v[i])</span><br></pre></td></tr></table></figure>
<h4 id="射箭问题"><a href="#射箭问题" class="headerlink" title="射箭问题"></a>射箭问题</h4><p>非常明显的0-1背包问题，箭支数量为”背包容量”，占领每个区域所需要的箭为”物品重量“，每个区域的分数为”价值”，转化为0-1背包问题套模板即可，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] maximumBobPoints(<span class="keyword">int</span> numArrows, <span class="keyword">int</span>[] aliceArrows) &#123;</span><br><span class="line">        <span class="comment">// dp状态数组</span></span><br><span class="line">        <span class="keyword">int</span>[] dpArray = <span class="keyword">new</span> <span class="keyword">int</span>[numArrows + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[][] solution = <span class="keyword">new</span> <span class="keyword">int</span>[aliceArrows.length][numArrows + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; aliceArrows.length;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = numArrows;j &gt; <span class="number">0</span>;j--)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j &gt; aliceArrows[i] &amp;&amp; i + dpArray[j - aliceArrows[i] - <span class="number">1</span>] &gt; dpArray[j])&#123;</span><br><span class="line">                    dpArray[j] = i + dpArray[j - aliceArrows[i] - <span class="number">1</span>];</span><br><span class="line">                    solution[i][j] = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//生成结果数组(比较重要的一部分代码)</span></span><br><span class="line">        <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[aliceArrows.length];</span><br><span class="line">        <span class="keyword">int</span> curArrows = numArrows;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = aliceArrows.length - <span class="number">1</span>;i &gt; <span class="number">0</span>;i--)&#123;</span><br><span class="line">            <span class="keyword">if</span>(solution[i][curArrows] == <span class="number">1</span>)&#123;</span><br><span class="line">                result[i] = aliceArrows[i] + <span class="number">1</span>;</span><br><span class="line">                curArrows -= aliceArrows[i] + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        result[<span class="number">0</span>] = curArrows;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>力扣刷题</category>
      </categories>
      <tags>
        <tag>0-1背包</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>死亡搁浅通关感想:一场关于‘连接’的快递之旅</title>
    <url>/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/</url>
    <content><![CDATA[<p>最开始从b站老戴的全流程视频里了解到了死亡搁浅这款游戏，听说这个游戏好看不好玩，原计划在b站云通关，但是看了几期视频后，发现游戏所营造的世界观和剧情深深的吸引了我，于是等到了Epic夏促打折入手，这几天终于通关了游戏，心里有一些小感受，写一点东西，算是对死亡搁浅体验的个人总结。</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/20210617193238_1.jpg" class="" title="20210617193238_1">
<span id="more"></span>
<h4 id="我玩到了什么"><a href="#我玩到了什么" class="headerlink" title="我玩到了什么"></a>我玩到了什么</h4><p>说实话网上说死亡搁浅更像电影，不像游戏有一定道理的，全流程体验下来，感觉主要的游戏方式主要就局限于<strong>送快递、打BT、抢劫米尔人</strong>这几种，修公路、建滑索算也勉强算是游戏内容一部分。</p>
<ul>
<li><strong>跑图送快递</strong>，从一个点到另一个点跑图，有车开车，没车硬跑，还要维持身体平衡，比较枯燥，但是小岛配的音乐真的有味道，和场景搭配起来恰到好处，一定程度解决了长距离跑图的枯燥</li>
<li><strong>干BT</strong>，说实话我感觉体验不是很好，虽然武器和怪物随着剧情发展种类都会不断增加，但是实际体验下来还是换汤不换药，基本就是站桩打枪，尤其是背着一堆货物，是真不想打BT</li>
<li><strong>抢劫米尔人</strong>，这部分类似于其他游戏里的暗杀，不能击杀只能靠近用绳索勒晕，或者后期用步枪什么的，体验多了就有点枯燥了，尤其是后面米尔人有枪之后，我基本能绕着走就绕着走（另外我修了三条路，全是靠米尔人的寄存桶资源，谢谢米尔人为美国做出的贡献）</li>
</ul>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/20210721223211_1.jpg" class="" title="20210721223211_1">
<h5 id="体验不好的点"><a href="#体验不好的点" class="headerlink" title="体验不好的点"></a>体验不好的点</h5><blockquote>
<p>你想想，你带着货箱，开着小摩托，吃着隐生虫唱着歌，突然被米尔人给劫了</p>
</blockquote>
<p>游戏难度我选的默认普通，基本不会遇到怪打不过重新加载存档点，或者遣返重生的情况，最多的情况就是被米尔人抢劫了，或者掉河里货丢了这两种情况，尤其是开着摩托，带着一堆货，突然遇到一堆米尔人，他们追我跑，结果开的太快冲进河里，车也没了，货也没了，真的我当时就想把游戏性卸载了，ZTMD难受。</p>
<p>我感觉我游戏体验不好部分主要就是</p>
<ul>
<li><strong>载具手感真差</strong>，拿手柄开摩托车、汽车是真的折磨，弯转不过来，前进后退真的迷，难道为了让我们修公路故意这么做的吗？</li>
<li><strong>传送点没啥用</strong>，后期用fragile的伞给我们整了个传送功能，但是不能带货的传送有啥用？反过来想如果能带货那就没意思了，总而言之传送功能没什么用处。</li>
<li><strong>战斗太单一了</strong>，从头到尾就是打BT，从手榴弹打狮子狗BT，到步枪打希格斯BT,最后的榴弹炮打鲸鱼BT，真的没什么区别，玩到后面真的审美疲劳。</li>
<li><strong>不时需要安慰的bb</strong>，有时候真的稍微摔一下bb就开始哭，这就是照顾孩子的心情吗？一次两次还好，次数多了真的着急</li>
<li><strong>剥洋葱式讲剧情</strong>，不能说是缺点，但是一上来就给你扔进入一个未知的世界，陌生的世界观，玩起来真的晕头转向，不知道自己在干啥，后面一点一点展开就好点了，确实提高了游戏的入门门槛。</li>
</ul>
<h5 id="印象深刻的战斗"><a href="#印象深刻的战斗" class="headerlink" title="印象深刻的战斗"></a>印象深刻的战斗</h5><p>第一个是游戏快接近结束时和希格斯的从现实到冥滩的三百回合大战，在前面的剧情里把希格斯塑造的太无敌，每次出来都是在主角的脸上跳舞，以至于在最后一场和希格斯的肉搏战里，看着把希格斯脸锤得变形是真的解气，就ntm叫希格斯啊！！！</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/Death_Stranding_2021_8_4_15_48_50.png" class="" title="Death_Stranding_2021_8_4_15_48_50">
<p>第二个是拔叔饰演的昂格尔剧情部分的越战冥滩，虽然进入以后还是老一套的打BT，但是场景中枪林弹雨、各种飞机火箭的轰鸣，战场的紧张，肾上腺素喷薄，真的让我感觉仿佛置身于战场之中，我真真切切的被场景所震撼了。</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/20210802145157_1.jpg" class="" title="20210802145157_1">
<h4 id="死亡搁浅讲了什么（剧透警告）"><a href="#死亡搁浅讲了什么（剧透警告）" class="headerlink" title="死亡搁浅讲了什么（剧透警告）"></a>死亡搁浅讲了什么（<strong>剧透警告</strong>）</h4><p>死亡搁浅的出现让人类世界支离破碎，人们虽然居住在一篇大陆，却只能困于自己小小的避难所之中，无法与其他人产生联系，在这样的背景下，主角sam肩负起了连接世界的重任，通过连接一个一个节点的网络，让人们重新连接在一起，随着连接的不断进行，主角渐渐发现的自己的身世和死亡搁浅的真相，那就是人类的第六次灭绝，而自己是解决这一切的关键，是选择破而后立还是负重前行？面对决定人类命运最终的抉择，主角做出了自己的选择。死亡搁浅故事内核在我看来还是<strong>美式个人英雄主义</strong>式的，一人carry全场后，了却世俗，隐于山林。</p>
<h5 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h5><p>游戏从到到尾都在连接开罗尔网络，但我觉得小岛所传达出的出的‘连接’不仅仅局限于物理意义上的连接，更重要的是末世下人与人心之间的连接，游戏不断地用一个一个支线故事调这一点。玛玛与洛克妮的合体，废品商与女朋友的重归于好等等，相比连接开罗尔网络，更重要的是连接破碎的人心。</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/20210803110221_1.jpg" class="" title="20210803110221_1">
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/20210802102701_1.jpg" class="" title="20210802102701_1">
<p>在连接世界的过程中，山姆原本冰冷的心也渐渐的与世界连接在一起，从最开始的密切接触恐惧症，到最后主动与亡人紧紧拥抱，主动接受芙拉吉尔隐生虫，山姆接受了世界，也融入了这个世界。</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/20210802144048_1.jpg" class="" title="20210802144048_1">
<p>在游戏机制上，小岛也设计了玩家与玩家之间的连接，玩家之间可以相互帮忙送货，一起搞基建，相互点赞。从剧情到游戏，真的让我感觉紧紧连接在一起。（经常骑别人的摩托车，丢了也不心疼）</p>
<h5 id="关于死亡"><a href="#关于死亡" class="headerlink" title="关于死亡"></a>关于死亡</h5><blockquote>
<p>世界上只有一种英雄主义,就是看清生活的真相之后依然热爱生活</p>
</blockquote>
<p>游戏的最后，小岛给我们抛出了一个问题，当你面临关于人类命运的选择，你会做出哪个选项？</p>
<ol>
<li><strong>破而后立</strong> 选择灭亡，毁灭是为了更好的重生</li>
<li><strong>负重前行</strong> 选择阻止死亡搁浅的发生，接受这一事实，继续生活</li>
</ol>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/Death_Stranding_2021_8_10_17_52_30.png" class="" title="Death Stranding 2021_8_10 17_52_30">
<p>然而小岛并没有给我们选择的权力，我拿着枪一顿射，发现根本打不死amile，试了好几次才发现只能拥抱amile组织死亡搁浅的发生，最后只能违背自己的愿望，继续活下去，其实我心里更喜欢选项1。或许正如罗曼罗兰所说的：世界上只有一种英雄主义,就是看清生活的真相之后依然热爱生活，负重前行也许是更好的选择。</p>
<h5 id="山姆离去"><a href="#山姆离去" class="headerlink" title="山姆离去"></a>山姆离去</h5><p>其实最后山姆拒绝芙拉吉尔，选择自己走了我是有点难受的，我觉得他就应该和芙拉吉尔在一起，我觉得小岛一直在用山姆对待隐生虫的态度象征两个人的关系，最开始在山洞相遇山姆拒绝芙拉吉尔的隐生虫，后面开始接受，再到主动给芙拉吉尔隐生虫，象征着两人的关系越来越亲密，最后在首都节点城，拒绝芙拉吉尔后，天空也出现了隐生虫，但是山姆放弃了，真的难以接受。</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/image-20210812103152564.png" class="" title="image-20210812103152564">
<p>至于山姆为什么要离去？我觉得首先山姆最牵挂的就是amile、bb以及芙拉吉尔，但是当他完成最终选择，他发现amile留在冥滩，永远回不来了，bb也死了，他所有的牵挂都离他而去。山姆发现自己牵挂的东西最后都不得善终，因此主动放弃了芙拉吉尔，选择自己一个人享受孤独。（忘记截图了，截一张老戴视频里的）</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/image-20210812104025400.png" class="" title="image-20210812104025400">
<h4 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h4><p>死亡搁浅以自己独特的世界观讲了一个好故事，值回票价，如果你没那么重视玩法，喜欢剧情导向的游戏，那么死亡搁浅准没错，最后像吐槽一下，什么时候美利坚能像游戏里塑造的那么正直高大，我觉得不太可能</p>
<img src="/2021/08/12/%E6%9D%82%E6%96%87/%E6%AD%BB%E4%BA%A1%E6%90%81%E6%B5%85/Death_Stranding_2021_8_10_19_49_58.png" class="" title="Death_Stranding_2021_8_10 19_49_58.png">
]]></content>
      <categories>
        <category>玩物丧志</category>
      </categories>
      <tags>
        <tag>玩后感</tag>
      </tags>
  </entry>
  <entry>
    <title>lc437.路径总和III</title>
    <url>/2021/09/30/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc437.%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8CIII/</url>
    <content><![CDATA[<h3 id="437-路径总和-III"><a href="#437-路径总和-III" class="headerlink" title="437. 路径总和 III"></a><a href="https://leetcode-cn.com/problems/path-sum-iii/">437. 路径总和 III</a></h3><p>前后一共做了三次，每次都想不出来使用前缀和的方法。</p>
<h4 id="思路1：DFS遍历"><a href="#思路1：DFS遍历" class="headerlink" title="思路1：DFS遍历"></a>思路1：DFS遍历</h4><p>先序遍历整个二叉树，遍历到某一结点后，以该节点为子树，查找当前子树中，是否存在一条从根节点出发的路径，满足路径和条件。</p>
<p><strong>复杂度分析</strong>：</p>
<ul>
<li>时间复杂度：与DFS遍历不同的点，在于每到达一个节点都需要重新遍历子树，寻找备选最优解，<strong>时间复杂度为O(N^2)</strong></li>
<li>空间复杂度：两次遍历不影响栈的深度，最大栈深度与DFS相同，<strong>空间复杂度为O(logN)</strong></li>
</ul>
<span id="more"></span>
<p><strong>代码实现：</strong></p>
<p>思路比较简单，实现也比较简单</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSolution</span><span class="params">(TreeNode curNode ,<span class="keyword">int</span> curSum, <span class="keyword">int</span> targetSum)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(curNode == <span class="keyword">null</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    curSum += curNode.val;</span><br><span class="line">    <span class="keyword">if</span>(curSum == targetSum)&#123;</span><br><span class="line">        result++;</span><br><span class="line">    &#125;</span><br><span class="line">    result += getSolution(curNode.left, curSum, targetSum) + getSolution(curNode.right, curSum, targetSum);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//简单的dfs</span></span><br><span class="line">    <span class="keyword">return</span> getSolution(root, <span class="number">0</span>, targetSum) + pathSum(root.left, targetSum) + pathSum(root.right, targetSum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="思路2：前缀和"><a href="#思路2：前缀和" class="headerlink" title="思路2：前缀和"></a>思路2：前缀和</h4><p>DFS计算路径和只能计算从根路径到当前节点的总和，但是满足目标解的路径不一定从根节点开始，我们可以将不从根节点开始的序列，转化成 两个从根出发序列的差，其中一个序列是另一个序列前缀。</p>
<p>如何实现这种存储，并且方便查询？深度遍历过程中将当前路径和存储到哈希表中，当遍历到某一个节点时，哈希表存储的是从根节点到当前节点的序列的<strong>所有前缀子序列的路径和</strong>,原问题转化为</p>
<script type="math/tex; mode=display">
sum_{seq\_i} = sum_{rootSeq_i} - sum_{preSeq_i}</script><p>在回退时，需要删除再是前缀的序列的前缀和（也就是当前序列）</p>
<p><strong>复杂度分析：</strong></p>
<ul>
<li>时间复杂度：与DFS一致，时间复杂度为树中的节点数目，<strong>时间复杂度为O(N)</strong></li>
<li>空间复杂度：哈希表的最大存储数量为O(logN)，<strong>空间复杂度为O(logN)</strong></li>
</ul>
<p><strong>代码实现：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//前缀和算法，包含当前节点</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">dfs</span><span class="params">(TreeNode curNode,<span class="keyword">int</span> curSum,<span class="keyword">int</span> targetSum,Map&lt;Integer, Integer&gt; preSumMap)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(curNode == <span class="keyword">null</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    curSum += curNode.val;</span><br><span class="line">    <span class="keyword">if</span>(preSumMap.containsKey(curSum - targetSum) &amp;&amp; preSumMap.get(curSum - targetSum) != <span class="number">0</span>)&#123;</span><br><span class="line">        result += preSumMap.get(curSum - targetSum);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将当前前缀和添加到hashmap中</span></span><br><span class="line">    <span class="keyword">int</span> times = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(preSumMap.containsKey(curSum))&#123;</span><br><span class="line">        times += preSumMap.get(curSum);</span><br><span class="line">    &#125;</span><br><span class="line">    preSumMap.put(curSum, times);</span><br><span class="line">    result += (dfs(curNode.left, curSum, targetSum, preSumMap) + dfs(curNode.right, curSum, targetSum, preSumMap));</span><br><span class="line">    <span class="comment">//回滚</span></span><br><span class="line">    preSumMap.put(curSum, times - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span> </span>&#123;</span><br><span class="line">    Map&lt;Integer, Integer&gt; preSumMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    preSumMap.put(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> dfs(root, <span class="number">0</span>, targetSum, preSumMap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><p>初始化应加入根节点的”假”前缀序列(序列和为0)</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">preSumMap.put(<span class="number">0</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>有序树中可能有负值节点，不能只记录前缀值的否出现，应记录出现次数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> times = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span>(preSumMap.containsKey(curSum))&#123;</span><br><span class="line">	times += preSumMap.get(curSum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>力扣刷题</category>
      </categories>
      <tags>
        <tag>树</tag>
        <tag>前缀思路</tag>
      </tags>
  </entry>
  <entry>
    <title>lc517.超级洗衣机</title>
    <url>/2021/09/30/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc517.%E8%B6%85%E7%BA%A7%E6%B4%97%E8%A1%A3%E6%9C%BA/</url>
    <content><![CDATA[<h3 id="517-超级洗衣机"><a href="#517-超级洗衣机" class="headerlink" title="517. 超级洗衣机"></a><a href="https://leetcode-cn.com/problems/super-washing-machines/">517. 超级洗衣机</a></h3><p>贪心的思路并不难，就是太难想到了</p>
<h4 id="思路1：邻居平分法（我自己的思路）"><a href="#思路1：邻居平分法（我自己的思路）" class="headerlink" title="思路1：邻居平分法（我自己的思路）"></a>思路1：邻居平分法（我自己的思路）</h4><p>类似于最优解的区域法，针对每个洗衣机，将整个数组划分为左边右边两个子区域，计算左右两个区域的衣服总和，并定会存在总数小于或者大于 平均*区域数量 的区域，如果当前洗衣机衣服多，就将多余的衣服分给缺衣服的区域（给了邻居）</p>
<ol>
<li>每遍历一次所有洗衣机等价于一次移动</li>
<li>最后一次遍历所有情况下划分的子区域，均满足 平均*区域数量 的性质</li>
</ol>
<p><strong>复杂度分析：</strong></p>
<ol>
<li>时间复杂度：每次平均都需要从头到尾遍历数组，共需要遍历结果次数的数组，<strong>时间复杂度为O(KN)</strong></li>
<li>空间复杂度：额外开辟了一个存储前缀和的数组，<strong>空间复杂度为O(N)</strong></li>
</ol>
<span id="more"></span>
<p><strong>代码实现：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findMinMoves</span><span class="params">(<span class="keyword">int</span>[] machines)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> average;</span><br><span class="line">        <span class="keyword">int</span> numOFMach = machines.length;</span><br><span class="line">        <span class="keyword">int</span>[] preSum = <span class="keyword">new</span> <span class="keyword">int</span>[numOFMach];</span><br><span class="line">        preSum[<span class="number">0</span>] = machines[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt; numOFMach;i++)&#123;</span><br><span class="line">            preSum[i] = preSum[i - <span class="number">1</span>] + machines[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//判断是否可分</span></span><br><span class="line">        <span class="keyword">if</span>(preSum[numOFMach - <span class="number">1</span>] % numOFMach != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        average = preSum[numOFMach - <span class="number">1</span>] / numOFMach;</span><br><span class="line">        <span class="keyword">boolean</span> flag;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            flag = <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; numOFMach;i++)&#123;</span><br><span class="line">                <span class="comment">//如果左边区域小，往左边区域移动</span></span><br><span class="line">                <span class="keyword">if</span>(machines[i] &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i != <span class="number">0</span> &amp;&amp; preSum[i] - machines[i] &lt; i * average)&#123;</span><br><span class="line">                        machines[i] -= <span class="number">1</span>;</span><br><span class="line">                        machines[i - <span class="number">1</span>] += <span class="number">1</span>;</span><br><span class="line">                        preSum[i - <span class="number">1</span>] += <span class="number">1</span>;</span><br><span class="line">                        flag = <span class="keyword">false</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(i != numOFMach - <span class="number">1</span> &amp;&amp; preSum[numOFMach - <span class="number">1</span>] - preSum[i] &lt; (numOFMach - i - <span class="number">1</span>) * average)&#123;</span><br><span class="line">                        machines[i] -= <span class="number">1</span>;</span><br><span class="line">                        machines[i + <span class="number">1</span>] += <span class="number">1</span>;</span><br><span class="line">                        preSum[i] -= <span class="number">1</span>;</span><br><span class="line">                        flag = <span class="keyword">false</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//没有平均操作就返回</span></span><br><span class="line">            <span class="keyword">if</span>(flag)&#123;</span><br><span class="line">                <span class="keyword">return</span> result;</span><br><span class="line">            &#125;</span><br><span class="line">            result++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>可惜差两个测试用例，超时</p>
<img src="/2021/09/30/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc517.%E8%B6%85%E7%BA%A7%E6%B4%97%E8%A1%A3%E6%9C%BA/image-20210930181801433.png" class="" title="image-20210930181801433">
</li>
</ul>
<h4 id="思路2：官方题解"><a href="#思路2：官方题解" class="headerlink" title="思路2：官方题解"></a>思路2：官方题解</h4><p>基于区域的最优，主要是三个点</p>
<ol>
<li><p>如果将数组划分为前后两个区域，如果是一个多衣服，一个少衣服，要达到平均状态最少也要将</p>
<p>多衣服的区域多的衣服，转移到少衣服区域，也就是 <strong>最少的次数至少也是多衣服区域多出来的衣服</strong></p>
</li>
<li><p>单个区域内要达到平均，最多衣服的洗衣机，要转移成平均，意味着 <strong>最少的次数至少是最多衣服数量洗衣机转移的衣服数量</strong></p>
</li>
<li><p>这种转移可以并行进行，也就得到了最终的贪心策略-<strong>寻找多最多的区域或者某个洗衣机</strong></p>
</li>
</ol>
<p><strong>复杂度分析：</strong></p>
<ol>
<li>时间复杂度：只需要遍历一次数组计算上面两个状态，<strong>时间复杂度为O(N)</strong></li>
<li>空间复杂度：不需要额外空间，<strong>空间复杂度为O(1)</strong></li>
</ol>
<p><strong>代码实现：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findMinMoves</span><span class="params">(<span class="keyword">int</span>[] machines)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//首先求和计算平均值</span></span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> average;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; machines.length;i++)&#123;</span><br><span class="line">        sum += machines[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(sum % machines.length != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//计算平均数，并用sum作为前i个元素所需要移入或移出的个数</span></span><br><span class="line">    average = sum / machines.length;</span><br><span class="line">    sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> tempNeed;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; machines.length;i++)&#123;</span><br><span class="line">        tempNeed = machines[i] - average;</span><br><span class="line">        sum += tempNeed;</span><br><span class="line">        result = Math.max(Math.abs(sum),Math.max(tempNeed, result));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>力扣刷题</category>
      </categories>
      <tags>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title>lc59.两数相除</title>
    <url>/2021/10/17/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc59.%E4%B8%A4%E6%95%B0%E7%9B%B8%E9%99%A4/</url>
    <content><![CDATA[<h3 id="29-两数相除"><a href="#29-两数相除" class="headerlink" title="29. 两数相除"></a><a href="https://leetcode-cn.com/problems/divide-two-integers/">29. 两数相除</a></h3><p>难点在于处理不能用long解决溢出问题</p>
<h4 id="思路1：“二进制”减法-没有满足越界要求"><a href="#思路1：“二进制”减法-没有满足越界要求" class="headerlink" title="思路1：“二进制”减法(没有满足越界要求)"></a>思路1：“二进制”减法(没有满足越界要求)</h4><p>不能用除法，最简单的思路就是被除数(dividend)不断地减除数(divisor)，直到减到剩余余数，相减的次数就是结果。该方法的问题就是时间复杂度太高，</p>
<ul>
<li>二进制优化，首先找到最大的n使得 $divisor <em> 2^n &lt; dividend$，每次减去 $ divisor </em> 2^n， divisor <em> 2^{n-1} ，divisor </em> 2^{n-2}  ……$,直到减到 $ divisor $</li>
<li>实际上就是将原来的逐个减去，变为二进制减去（找商的二进制表示），由于任何数都能由二进制表示，所以该方法必定有解</li>
<li>我的实现方法<strong>越界无法规避</strong>，只能用Long</li>
</ul>
<p><strong>复杂度分析：</strong></p>
<p>没有分析的必要，由于只有32位整数，二进制一共只需要移动32次，时间复杂度与空间复杂度均为O(1)</p>
<p><strong>代码实现：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">divide</span><span class="params">(<span class="keyword">int</span> dividend, <span class="keyword">int</span> divisor)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> result  = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">boolean</span> isNegative = (dividend &lt; <span class="number">0</span> &amp; divisor &gt; <span class="number">0</span>) || (dividend &gt; <span class="number">0</span> &amp; divisor &lt; <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">long</span> temp = <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//首先绝对值求解</span></span><br><span class="line">    <span class="keyword">long</span> denominator = (<span class="keyword">long</span>)Math.abs((<span class="keyword">long</span>)dividend);</span><br><span class="line">    <span class="keyword">long</span> numerator = (<span class="keyword">long</span>)Math.abs((<span class="keyword">long</span>)divisor);</span><br><span class="line">    <span class="comment">//首先找到最大元素</span></span><br><span class="line">    <span class="keyword">while</span>(numerator &lt;&lt; <span class="number">1</span> &lt;= denominator)&#123;</span><br><span class="line">        temp = temp &lt;&lt; <span class="number">1</span>;</span><br><span class="line">        numerator = numerator &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(numerator &gt;= Math.abs((<span class="keyword">long</span>)divisor))&#123;</span><br><span class="line">        <span class="keyword">if</span>(denominator &gt;= numerator)&#123;</span><br><span class="line">            denominator -= numerator;</span><br><span class="line">            <span class="keyword">if</span>(isNegative)</span><br><span class="line">                result -= temp;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                result += temp;</span><br><span class="line">        &#125;</span><br><span class="line">        numerator = numerator &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        temp = temp &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(result &gt; Integer.MAX_VALUE)&#123;</span><br><span class="line">        result = Integer.MAX_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">int</span>)result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="思路2：条件约束-二分查找（答案的方法看得我头疼）"><a href="#思路2：条件约束-二分查找（答案的方法看得我头疼）" class="headerlink" title="思路2：条件约束+二分查找（答案的方法看得我头疼）"></a>思路2：条件约束+二分查找（答案的方法看得我头疼）</h4>]]></content>
      <categories>
        <category>力扣刷题</category>
      </categories>
      <tags>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title>lc798.得分最高的最小轮调</title>
    <url>/2022/03/13/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc798.%E5%BE%97%E5%88%86%E6%9C%80%E9%AB%98%E7%9A%84%E6%9C%80%E5%B0%8F%E8%BD%AE%E8%B0%83/</url>
    <content><![CDATA[<h2 id="798-得分最高的最小轮调"><a href="#798-得分最高的最小轮调" class="headerlink" title="798.得分最高的最小轮调"></a><a href="https://leetcode-cn.com/problems/smallest-rotation-with-highest-score/">798.得分最高的最小轮调</a></h2><p>第一次写一点思路都没有，扣了半天最终放弃，直奔题解，发现题目主要有两个难点</p>
<ol>
<li>从轮调位置角度考虑转换到每个元素位置考虑<ul>
<li>我的思路一直局限在从选k出发，如何计算出每个k位置的分数？怎么找到一种贪心或者动态规状态传递的方式</li>
<li>没有从元素的角度出发，某个元素满足小于等于index时，k一定在某个范围内，所有元素决定的k的范围交集次数最多的就是最优解（表达不出来这种思维的转变）</li>
</ul>
</li>
<li>如何记录最大交集次数？<ul>
<li>看完一半题解就想到创建一个数组，每计算出一个k的范围，就将范围内记录全部加一</li>
<li>题解提供的差分数组思路”针不错”</li>
</ul>
</li>
</ol>
<span id="more"></span>
<p>如何<strong>计算k的范围</strong>，以index=i处元素为例分情况讨论（基本思路：轮调等价于数组开头一部分元素拼接到数组末尾或者末尾一部分元素拼接到数组开头）</p>
<ol>
<li><p>$i &lt; nums[i]$ 即元素值大于索引，必须增大元素索引才能满足条件</p>
<ul>
<li>左边至少增加 $nums[i] - i$ ，也就意味着 轮调位置k必须在当前元素后面，且k<strong>后边元素个数</strong>必须大于等于当前元素左边至少要增加的元素,可得公式为 $ nums.length - k &gt;= nums[i] - i$ ，得到k的范围为<script type="math/tex; mode=display">
k \in [i+ 1, nums.length - nums[i] +i]</script></li>
</ul>
</li>
<li><p>$i &gt;= nums[i]$ 即索引值大于等于元素值，由于已经满足条件，可以如条件继续在左边增加元素（k在当前位置右边），或者从左边删掉一部分元素（k在当前位置左边）</p>
<ul>
<li><p>左边增加元素个数任意（k在当前位置右边），即k大于i时始终成立</p>
<script type="math/tex; mode=display">
k \in [i + 1, nums.length - 1]</script></li>
<li><p>左边删除一定数量元素，即最多$ i - nums[i]$，</p>
<script type="math/tex; mode=display">
k \in [0, i - nums[i]]</script></li>
</ul>
</li>
</ol>
<ul>
<li>最终第二种情况k范围为<script type="math/tex; mode=display">
k \in [0, i - nums[i]] \cup [i + 1, nums.length - 1]</script></li>
</ul>
<p>差分数组理解：</p>
<ol>
<li>差分数组元素定义为：<strong>differ[i] = nums[i] - nums[i - 1]</strong>，实际代表原数组的与前一个位置元素的差（可以理解为每个元素的参考都是前一个元素）</li>
<li>若要将原数组中<strong>某个区间内元素统一加某个值</strong>，在开始加 $differ[start] + number$，在结束后一个位置减  $differ[end + 1] - number$ </li>
</ol>
<p>如何更新差分数组：</p>
<ol>
<li><p>只需要执行两种操作，<strong>区间的左边界 + 1，区间的右边界右边-1</strong></p>
</li>
<li><p>两种情况的differ数组更新情况</p>
<ol>
<li>$i &lt; nums[i]$ <ul>
<li>differ[i + 1] + 1，differ[nums.length-nums[i] + i + 1] - 1</li>
</ul>
</li>
<li><p>$i &gt;= nums[i]$ </p>
<ul>
<li>differ[i + 1] + 1,右边界越界，不需要记录</li>
<li>differ[0] + 1, differ[i - nums[i] + 1] - 1</li>
</ul>
</li>
<li><p>$ (nums.length + i - nums[i]) % nums.length$ 可以等价与两个右边界情况</p>
</li>
</ol>
</li>
</ol>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">bestRotation</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] differ = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span> tempLow;</span><br><span class="line">        <span class="keyword">int</span> tempHigh;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nums.length;i++)&#123;</span><br><span class="line">            tempLow = i + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// 精髓</span></span><br><span class="line">            tempHigh = (nums.length + i - nums[i]) % nums.length;</span><br><span class="line">            differ[tempLow]++;</span><br><span class="line">            differ[tempHigh + <span class="number">1</span>]--;</span><br><span class="line">            <span class="comment">//左右双开区间</span></span><br><span class="line">            <span class="keyword">if</span>(nums[i] &lt;= i)&#123;</span><br><span class="line">                differ[<span class="number">0</span>]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt; differ.length;i++)&#123;</span><br><span class="line">            differ[i] += differ[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> score = differ[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt; differ.length;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(differ[i] &gt; score)&#123;</span><br><span class="line">                result = i;</span><br><span class="line">                score = differ[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>力扣刷题</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>lc869.重新排序得到2的幂</title>
    <url>/2021/11/21/%E5%8A%9B%E6%89%A3%E5%88%B7%E9%A2%98/lc869.%E9%87%8D%E6%96%B0%E6%8E%92%E5%BA%8F%E5%BE%97%E5%88%B02%E7%9A%84%E5%B9%82/</url>
    <content><![CDATA[<h3 id="869-重新排序得到-2-的幂"><a href="#869-重新排序得到-2-的幂" class="headerlink" title="869.重新排序得到 2 的幂"></a><a href="https://leetcode-cn.com/problems/reordered-power-of-2/">869.重新排序得到 2 的幂</a></h3><p>关键点是意识到2的幂次是有限</p>
<h3 id="解法1-暴力回溯法"><a href="#解法1-暴力回溯法" class="headerlink" title="解法1-暴力回溯法"></a>解法1-暴力回溯法</h3><p>看到重排序就想到回溯法中的排列树问题，按照排列树的标准模板求解即可,注意排除出现前导零的情况,与</p>
<p><strong>复杂度分析：</strong></p>
<ul>
<li>时间复杂度：由于第i层共有N- i个选择，<strong>时间复杂度为O(N!)</strong></li>
<li>空间复杂度：递归深度为数字的长度，<strong>空间复杂度为O(N)</strong></li>
</ul>
<p><strong>代码：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">backTrace</span><span class="params">(<span class="keyword">int</span> depth, <span class="keyword">int</span> nLength, Long curNumber, <span class="keyword">int</span>[] visited, <span class="keyword">int</span>[] digits)</span></span>&#123;</span><br><span class="line">        <span class="comment">//所有情况选取完毕</span></span><br><span class="line">        <span class="keyword">if</span>(depth == nLength)&#123;</span><br><span class="line">            <span class="keyword">return</span> isTwoPower(curNumber);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nLength;i++)&#123;</span><br><span class="line">            <span class="comment">//未选用过当前位置数字,前导数字不能为0</span></span><br><span class="line">            <span class="keyword">if</span>(visited[i] == <span class="number">0</span> &amp;&amp; (depth != <span class="number">0</span> || digits[i] != <span class="number">0</span>))&#123;</span><br><span class="line">                visited[i] = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span>(backTrace(depth + <span class="number">1</span>, nLength, curNumber * <span class="number">10</span> + digits[i] , visited, digits))</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                visited[i] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h3 id="解法2-预先计算存储法"><a href="#解法2-预先计算存储法" class="headerlink" title="解法2-预先计算存储法"></a>解法2-预先计算存储法</h3><p>在数字的取值范围内，一共有$2^0, 2^1,……2^{29}$ 一共30个可能取到的2的幂次，事先计算所有2幂次数字各个位置的0~9 数字出现的次数，按照顺序生成字符串存储到Map中，对于目标数字，按照相同计算步骤生成字符串，查看Map中是否含有相同字符串即可。</p>
<p>不想写了贴个官方题解充个数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    Set&lt;String&gt; powerOf2Digits = <span class="keyword">new</span> HashSet&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">reorderedPowerOf2</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="keyword">return</span> powerOf2Digits.contains(countDigits(n));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">1</span>; n &lt;= <span class="number">1e9</span>; n &lt;&lt;= <span class="number">1</span>) &#123;</span><br><span class="line">            powerOf2Digits.add(countDigits(n));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">countDigits</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">char</span>[] cnt = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="number">10</span>];</span><br><span class="line">        <span class="keyword">while</span> (n &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            ++cnt[n % <span class="number">10</span>];</span><br><span class="line">            n /= <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> String(cnt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">作者：LeetCode-Solution</span><br><span class="line">链接：https:<span class="comment">//leetcode-cn.com/problems/reordered-power-of-2/solution/zhong-xin-pai-xu-de-dao-2-de-mi-by-leetc-4fvs/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>力扣刷题</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>前缀（字典）树总结</title>
    <url>/2021/11/21/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E5%89%8D%E7%BC%80%EF%BC%88%E5%AD%97%E5%85%B8%EF%BC%89%E6%A0%91%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="什么是前缀树（Trie）"><a href="#什么是前缀树（Trie）" class="headerlink" title="什么是前缀树（Trie）"></a>什么是前缀树（Trie）</h3><blockquote>
<p>In <a href="https://en.wikipedia.org/wiki/Computer_science">computer science</a>, a <strong>trie</strong>, also called <strong>digital tree</strong> or <strong>prefix tree</strong>, is a type of <a href="https://en.wikipedia.org/wiki/Search_tree">search tree</a>, a <a href="https://en.wikipedia.org/wiki/Tree_(data_structure">tree</a>) <a href="https://en.wikipedia.org/wiki/Data_structure">data structure</a> used for locating specific keys from within a set. These keys are most often <a href="https://en.wikipedia.org/wiki/String_(computer_science">strings</a>), with links between nodes defined not by the entire key, but by individual <a href="https://en.wikipedia.org/wiki/Character_(computing">characters</a>). - wikepidea</p>
</blockquote>
<p>前缀树（又叫做字典树）是一种特殊类型的<strong>多叉树</strong>，每条边代表一个一个字母，每个节点代表一个字符串（前缀），该字符串由从根节点到当前节点路径字母组成，由于节点间的父子关系，父节点字符串就相当于子节点字符串的前缀，因此称为<strong>前缀树</strong>。</p>
<p>需要特殊注意的是前缀树的根节点由于没有父节点，代表<strong>空字符串</strong></p>

<span id="more"></span>
<h4 id="前缀树结构"><a href="#前缀树结构" class="headerlink" title="前缀树结构"></a>前缀树结构</h4><p>假设给定字符串中只有<strong>小写字母</strong>，则每个节点可能有26种类型边指向孩子节点，数据结构定义如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrieTreeNode</span></span>&#123;</span><br><span class="line">    # 长度为<span class="number">26</span>的子节点数组</span><br><span class="line">    TrieTreeNode[] children;</span><br><span class="line">    # 当前节点是否为一个单词（还能够存储以当前前缀为前缀的单词数量）</span><br><span class="line">    <span class="keyword">boolean</span> isWord;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重点在于孩子节点数组的定义，其他属性可以根据具体问题设计</p>
<h4 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h4><ul>
<li><p>insert  向前缀树中插入一个单词</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inert</span><span class="params">(String word)</span></span>&#123;</span><br><span class="line">    <span class="comment">// 临时的初始节点</span></span><br><span class="line">    TrieTreeNode curNode = root;</span><br><span class="line">    <span class="comment">//将word转换成从根节点到(非)叶子节点的一条路</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; word.length();i++)&#123;</span><br><span class="line">        <span class="comment">//如果不存在当前前缀，添加</span></span><br><span class="line">        <span class="keyword">if</span>(curNode.children[word.charAt(i) - <span class="string">&#x27;a&#x27;</span>] == <span class="keyword">null</span>)&#123;</span><br><span class="line">            curNode.children[word.charAt(i) - <span class="string">&#x27;a&#x27;</span>]； = <span class="keyword">new</span> TrieTreeNode();</span><br><span class="line">        &#125;</span><br><span class="line">        curNode = curNode.children[word.charAt(i) - <span class="string">&#x27;a&#x27;</span>]；</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//标示当前词语</span></span><br><span class="line">    curNode.isWord = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>search 在前缀树中查找一个单词或者前缀</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">search</span><span class="params">(String word)</span></span>&#123;</span><br><span class="line">    <span class="comment">//从根节点搜索</span></span><br><span class="line">    TrieTreeNode curNode = root;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; word.length();i++)&#123;</span><br><span class="line">        <span class="comment">//不包含当前字母</span></span><br><span class="line">        <span class="keyword">if</span>(curNode.children[word.charAt(i)] == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        curNode = curNode.children[word.charAt(i)];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//如果是前缀,可以直接返回</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">//如果是找单词，需要查看节点标识符</span></span><br><span class="line">    <span class="keyword">return</span> curNode.isWord;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="几个典型例题"><a href="#几个典型例题" class="headerlink" title="几个典型例题"></a>几个典型例题</h4><ol>
<li>lc:<a href="https://leetcode-cn.com/problems/design-add-and-search-words-data-structure/">211. 添加与搜索单词 - 数据结构设计</a><ul>
<li>前缀树结构练习题</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>前缀树（Trie）</tag>
      </tags>
  </entry>
  <entry>
    <title>并查集整理</title>
    <url>/2021/07/04/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E5%B9%B6%E6%9F%A5%E9%9B%86%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h4 id="什么是并查集"><a href="#什么是并查集" class="headerlink" title="什么是并查集"></a>什么是并查集</h4><blockquote>
<p>并查集是一种树型的数据结构，用于处理一些不相交集合的合并及查询问题。</p>
<p>并查集的思想是用一个数组表示了整片森林（parent），树的根节点唯一标识了一个集合，我们只要找到了某个元素的的树根，就能确定它在哪个集合里。</p>
<p>百度百科</p>
</blockquote>
<p>并查集包括两种操作：</p>
<ol>
<li>find(x) 查询元素所属的集合</li>
<li>union(x, y) 合并两个不相关的集合</li>
</ol>
<p>我理解的并查集，就是对于一系列元素，不同元素组成不同的集合（使用树的形式描述集合），多个集合共同构成并查集（森林），提供集合与集合的合并（两棵的合并）和 查找元素所属的集合（在哪棵树）<br><span id="more"></span></p>
<h4 id="如何实现并查集"><a href="#如何实现并查集" class="headerlink" title="如何实现并查集"></a>如何实现并查集</h4><p>并查集中只关注元素属于哪个集合，集合之间的合并操作，以树形式表示集合，每个元素只需要知道自己所属树的根节点就能知道自己属于哪个集合(属于哪个树)，集合合并也可转化为树的合并，因此可使用类似于完全二叉树的数组存储方式实现并查集。</p>
<p>存储结构实现：</p>
<ul>
<li><p>使用father数组，存储元素的父节点(不直接存储根节点的原因在于，合并操作无法保证该性质)</p>
</li>
<li><p>每个元素初始化父节点为本身，表示并查集初始每个元素自成一个集合</p>
<p><code>int father[elements];</code></p>
</li>
</ul>
<p>操作实现：</p>
<ol>
<li><p>find(x) 查询元素所属集合</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 不断的向上查询父节点，直到找到当前集合的根</span><br><span class="line">int find(x)&#123;</span><br><span class="line">	root = x;</span><br><span class="line">	while(father[root] != root)&#123;</span><br><span class="line">		parent = father[root];</span><br><span class="line">	&#125;</span><br><span class="line">	return root;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>union 合并集合操作</p>
<ul>
<li>找到两个集合的根节点，将其中一个根节点父节点设置为另一集合根节点</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int uninon(x,y)&#123;</span><br><span class="line">	int root_x = find(x)</span><br><span class="line">	int root_y = find(y)</span><br><span class="line">	// 以x插入到y为例</span><br><span class="line">	parent[root_x] = root_y</span><br><span class="line">    return root_y</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li><p>java实现</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DisjointSetUnion</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] parent;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DisjointSetUnion</span><span class="params">(<span class="keyword">int</span> nums)</span></span>&#123;</span><br><span class="line">        parent = <span class="keyword">new</span> <span class="keyword">int</span>[nums];</span><br><span class="line">        <span class="comment">//初始化</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; nums;i++)&#123;</span><br><span class="line">            parent[i] = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(parent[x] != x)&#123;</span><br><span class="line">            x = parent[x];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> parent_x = find(x);</span><br><span class="line">        <span class="keyword">int</span> parent_y = find(y);</span><br><span class="line">        parent[parent_x] = parent_y;</span><br><span class="line">        <span class="keyword">return</span> parent_y;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="并查集优化"><a href="#并查集优化" class="headerlink" title="并查集优化"></a>并查集优化</h4><h5 id="1-路径压缩降低查找集合标示的复杂度"><a href="#1-路径压缩降低查找集合标示的复杂度" class="headerlink" title="1.路径压缩降低查找集合标示的复杂度"></a>1.路径压缩降低查找集合标示的复杂度</h5><p>在find的过程中，直接将当前的根节点接到所在集合的根节点</p>
<ul>
<li>该方法只有在查询的过程中才会优化，且只优化树的一条路径</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">find</span><span class="params">(x)</span></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(father[x] == x)&#123;</span><br><span class="line">		<span class="keyword">return</span> x;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">//同样的找父根节点，增加了赋值操作</span></span><br><span class="line">		father[x] = find(father[x]);</span><br><span class="line">        <span class="keyword">return</span> father[x];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//一行简写法</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x == father[x] ? x : (father[x] = find(fa[x]));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-按秩合并的方式"><a href="#2-按秩合并的方式" class="headerlink" title="2.按秩合并的方式"></a>2.按秩合并的方式</h5><p>出发点是把简单的树往复杂的树上合并，以减少合并增加的平均树深度，定义节点的秩为以当前节点为根子树的深度，开辟秩数组，每个节点对应一个秩。</p>
<p>初始化方法修改为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//所有的秩均初始化为1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">	father = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">	rank = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; n;i++)&#123;</span><br><span class="line">		father[i] = i;</span><br><span class="line">		rank[i] = i;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>合并方法修改为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = find(i), y = find(j);    <span class="comment">//先找到两个根节点</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (rank[x] &lt;= rank[y])</span><br><span class="line">        fa[x] = y;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        fa[y] = x;</span><br><span class="line">    <span class="comment">//深度相同时，根节点深度+1,深度不同，插入子树不影响深度</span></span><br><span class="line">    <span class="keyword">if</span> (rank[x] == rank[y] &amp;&amp; x != y)</span><br><span class="line">        rank[y]++;                   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="并查集应用"><a href="#并查集应用" class="headerlink" title="并查集应用"></a>并查集应用</h4><ol>
<li><p>洛谷p1551 亲戚问题</p>
 <img src="/2021/07/04/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E5%B9%B6%E6%9F%A5%E9%9B%86%E6%95%B4%E7%90%86/image-20210509112121807.png" class="">
<ul>
<li><p>简答的并查集思路，求是否具有亲戚关系，即判断两元素是否在一个集合中</p>
</li>
<li><p>java代码实现:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span>[] parent;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(parent[x] != x)&#123;</span><br><span class="line">            x = parent[x];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> parent_x = find(x);</span><br><span class="line">        <span class="keyword">int</span> parent_y = find(y);</span><br><span class="line">        parent[parent_x] = parent_y;</span><br><span class="line">        <span class="keyword">return</span> parent_y;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> n,m,p;</span><br><span class="line">        n = scanner.nextInt();</span><br><span class="line">        m = scanner.nextInt();</span><br><span class="line">        p = scanner.nextInt();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//初始化并查集</span></span><br><span class="line">        parent = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; parent.length;i++)&#123;</span><br><span class="line">            parent[i] = i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//读取关系合并并查集</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; m;i++)&#123;</span><br><span class="line">            union(scanner.nextInt() - <span class="number">1</span>,scanner.nextInt() - <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//判断两个集合是否在同一个集合中</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; p;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(find(scanner.nextInt() - <span class="number">1</span>) == find(scanner.nextInt() - <span class="number">1</span>))&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;Yes&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;No&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>岛屿数量问题(LC <a href="https://leetcode-cn.com/problems/number-of-islands/">200. 岛屿数量</a>)</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="comment">//并查集方法</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">DisjointUnion</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count;</span><br><span class="line">        <span class="keyword">int</span>[] parents;</span><br><span class="line">        <span class="keyword">int</span>[] rank;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">DisjointUnion</span><span class="params">(<span class="keyword">char</span>[][] grid)</span></span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.count = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">this</span>.parents = <span class="keyword">new</span> <span class="keyword">int</span>[grid.length * grid[<span class="number">0</span>].length];</span><br><span class="line">            <span class="keyword">this</span>.parents = <span class="keyword">new</span> <span class="keyword">int</span>[grid.length * grid[<span class="number">0</span>].length];</span><br><span class="line">            <span class="keyword">this</span>.rank = <span class="keyword">new</span> <span class="keyword">int</span>[grid.length * grid[<span class="number">0</span>].length];</span><br><span class="line">            <span class="comment">//初始化集合，每个元素1自成一个集合</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; grid.length;i++)&#123;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; grid[<span class="number">0</span>].length;j++)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(grid[i][j] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                        <span class="keyword">this</span>.count++;</span><br><span class="line">                        <span class="comment">//集合标识为自己</span></span><br><span class="line">                        parents[i * grid[<span class="number">0</span>].length + j] = i * grid[<span class="number">0</span>].length + j;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">this</span>.rank[i * grid[<span class="number">0</span>].length + j] = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(x != parents[x])&#123;</span><br><span class="line">                parents[x] = find(parents[x]);</span><br><span class="line">                x = parents[x];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> x;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">            <span class="keyword">int</span> parentX = find(x);</span><br><span class="line">            <span class="keyword">int</span> parentY = find(y);</span><br><span class="line">            <span class="comment">//是否为不同的集合</span></span><br><span class="line">            <span class="keyword">if</span>(parentX != parentY)&#123;</span><br><span class="line">                <span class="keyword">this</span>.count--;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//添加秩的合并操作</span></span><br><span class="line">                <span class="keyword">if</span>(rank[parentX] &lt;= rank[parentY])&#123;</span><br><span class="line">                    parents[parentX] = parentY;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    parents[parentY] = parentX;</span><br><span class="line">                    <span class="keyword">if</span>(rank[parentX] == parentY)&#123;</span><br><span class="line">                        rank[parentY]++;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>.count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numIslands</span><span class="params">(<span class="keyword">char</span>[][] grid)</span> </span>&#123;</span><br><span class="line">        DisjointUnion disjointUnion = <span class="keyword">new</span> DisjointUnion(grid);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; grid.length;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; grid[<span class="number">0</span>].length;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(grid[i][j] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(i - <span class="number">1</span> &gt;= <span class="number">0</span> &amp;&amp; grid[i - <span class="number">1</span>][j] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                        disjointUnion.union(i * grid[<span class="number">0</span>].length + j, (i - <span class="number">1</span>) * grid[<span class="number">0</span>].length + j);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span>(j - <span class="number">1</span> &gt;= <span class="number">0</span> &amp;&amp; grid[i][j - <span class="number">1</span>] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                        disjointUnion.union(i * grid[<span class="number">0</span>].length + j, i * grid[<span class="number">0</span>].length + j - <span class="number">1</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span>(i + <span class="number">1</span> &lt; grid.length &amp;&amp; grid[i + <span class="number">1</span>][j] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                        disjointUnion.union(i * grid[<span class="number">0</span>].length + j, (i +<span class="number">1</span>) * grid[<span class="number">0</span>].length + j);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span>(j + <span class="number">1</span> &lt; grid[<span class="number">0</span>].length &amp;&amp; grid[i][j + <span class="number">1</span>] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                        disjointUnion.union(i * grid[<span class="number">0</span>].length + j, i * grid[<span class="number">0</span>].length + j + <span class="number">1</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> disjointUnion.getCount();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>并查集</tag>
      </tags>
  </entry>
  <entry>
    <title>快速幂整理</title>
    <url>/2021/07/09/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E5%BF%AB%E9%80%9F%E5%B9%82%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h3 id="1-什么是快速幂"><a href="#1-什么是快速幂" class="headerlink" title="1 什么是快速幂"></a>1 什么是快速幂</h3><p>在求幂次操作时，一般采用逐个相乘的方式，求多少阶幂次，就需要进行多少次乘法，乘法的时间复杂度为<strong>O(N)</strong>，通过引入”备忘录“和二分思想，将乘法次数从 <script type="math/tex">N</script> 降低到 <script type="math/tex">log_2N</script></p>
<h4 id="主要思想："><a href="#主要思想：" class="headerlink" title="主要思想："></a>主要思想：</h4><ol>
<li>求 N幂次问题 转化为 求两个 N/2幂次的乘积</li>
<li>两个相同的 N/2幂次子问题，只需要求解一次<span id="more"></span>
<h4 id="1-1-递归伪代码："><a href="#1-1-递归伪代码：" class="headerlink" title="1.1 递归伪代码："></a>1.1 递归伪代码：</h4></li>
</ol>
<ul>
<li>递归实现较为简洁，但是会存在递归栈占用，递归树深度为<script type="math/tex">logN</script></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getPow</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> e)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(e == <span class="number">0</span>)&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//计算子问题</span></span><br><span class="line">    <span class="keyword">int</span> temp = getPow(x, e / <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">int</span> result = temp * temp;</span><br><span class="line">    <span class="keyword">if</span>(e % <span class="number">2</span> != <span class="number">0</span>)&#123;</span><br><span class="line">        result *= x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-2-迭代伪代码："><a href="#1-2-迭代伪代码：" class="headerlink" title="1.2 迭代伪代码："></a>1.2 <strong>迭代伪代码</strong>：</h4><p>观察递归代码，可以得到递归过程类似于将指数e转化为二进制的过程</p>
<ul>
<li>在底数转化二进制的某位为1时，对应递归子问题为奇数时乘以底数，</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if(e % 2 != 0)&#123;</span><br><span class="line">    result *= x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在递归返回时，每向上返回一层 该位置乘的底数，都要平方一次</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> result = temp * temp;</span><br></pre></td></tr></table></figure>
<p>根据以上分析可得递归代码为</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getPow</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> e)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> result = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">while</span>(e &gt; <span class="number">0</span>)&#123;</span><br><span class="line">		<span class="keyword">if</span>(e % <span class="number">2</span> != <span class="number">0</span>)&#123;</span><br><span class="line">			result *= x;</span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">//阶数向右移动</span></span><br><span class="line">        x *= x;</span><br><span class="line">        <span class="comment">//等价于从底向上递归</span></span><br><span class="line">		e &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-3-添加了避免越界的模板"><a href="#1-3-添加了避免越界的模板" class="headerlink" title="1.3 添加了避免越界的模板"></a>1.3 添加了避免越界的模板</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getPow</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> e)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> result = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">while</span>(e &gt; <span class="number">0</span>)&#123;</span><br><span class="line">		<span class="keyword">if</span>(e % <span class="number">2</span> != <span class="number">0</span>)&#123;</span><br><span class="line">			result = result * x mod number;</span><br><span class="line">		&#125;</span><br><span class="line">        <span class="comment">//阶数向右移动</span></span><br><span class="line">        x = x * x mod number;</span><br><span class="line">        <span class="comment">//等价于从底向上递归</span></span><br><span class="line">		e &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-4-快速幂扩展"><a href="#1-4-快速幂扩展" class="headerlink" title="1.4 快速幂扩展"></a>1.4 快速幂扩展</h4><p>快速幂思路不止可以应用在整数乘积上，同样可扩展到类似的矩阵乘积</p>
<h3 id="2-典型例题"><a href="#2-典型例题" class="headerlink" title="2 典型例题"></a>2 典型例题</h3><h4 id="2-1-洛谷-P3390-【模板】矩阵快速幂"><a href="#2-1-洛谷-P3390-【模板】矩阵快速幂" class="headerlink" title="2.1 洛谷 P3390 【模板】矩阵快速幂"></a>2.1 洛谷 P3390 【模板】<a href="https://www.luogu.com.cn/problem/solution/P3390">矩阵快速幂</a></h4><p>难点在于避免越界和矩阵乘法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">  <span class="keyword">static</span> <span class="keyword">int</span> MOD_NUMBER = <span class="number">100000007</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span>[][] matMul(<span class="keyword">long</span>[][] mat1, <span class="keyword">long</span>[][] mat2)&#123;</span><br><span class="line">      <span class="keyword">if</span>(mat1 == <span class="keyword">null</span>)&#123;</span><br><span class="line">          <span class="keyword">return</span> mat2;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//乘积结果存储在result中</span></span><br><span class="line">      <span class="keyword">long</span>[][] result = <span class="keyword">new</span> <span class="keyword">long</span>[mat1.length][mat1.length];</span><br><span class="line">      <span class="keyword">long</span> temp;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; mat1.length;i++)&#123;</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; mat1.length;j++)&#123;</span><br><span class="line">              temp = <span class="number">0</span>;</span><br><span class="line">              <span class="comment">//第i行与第j列相乘</span></span><br><span class="line">              <span class="keyword">for</span>(<span class="keyword">int</span> m = <span class="number">0</span>; m &lt; mat1.length;m++)&#123;</span><br><span class="line">                  <span class="comment">//避免越界的关键点</span></span><br><span class="line">                  temp  = (temp + mat1[i][m] * mat2[m][j] % MOD_NUMBER) % MOD_NUMBER;</span><br><span class="line">              &#125;</span><br><span class="line">              result[i][j] = temp;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">      <span class="keyword">int</span> n = scanner.nextInt();</span><br><span class="line">      Long k = scanner.nextLong();</span><br><span class="line">      <span class="keyword">long</span>[][] aimMatrix = <span class="keyword">new</span> <span class="keyword">long</span>[n][n];</span><br><span class="line">      <span class="comment">//读取matrix数组</span></span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; n;i++)&#123;</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; n;j++)&#123;</span><br><span class="line">              aimMatrix[i][j] = scanner.nextLong();</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">long</span>[][] result = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">while</span>(k &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (k % <span class="number">2</span> != <span class="number">0</span>) &#123;</span><br><span class="line">              result = matMul(result, aimMatrix);</span><br><span class="line">          &#125;</span><br><span class="line">          k &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">          aimMatrix = matMul(aimMatrix, aimMatrix);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//输出结果集合,省略</span></span><br><span class="line">System.....</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<img src="/2021/07/09/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E5%BF%AB%E9%80%9F%E5%B9%82%E6%95%B4%E7%90%86/image-20210706154401051.png" class="" title="image-20210706154401051">
<h4 id="2-2-力扣-1922-统计好数字的数目"><a href="#2-2-力扣-1922-统计好数字的数目" class="headerlink" title="2.2 力扣 1922. 统计好数字的数目"></a>2.2 力扣 <a href="https://leetcode-cn.com/problems/count-good-numbers/">1922. 统计好数字的数目</a></h4><p>难点在于将题目转化为求幂形式，<strong>通过归纳得到数组位数每增加两位，好数字数目*20</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">countGoodNumbers</span><span class="params">(<span class="keyword">long</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//设置初始化值</span></span><br><span class="line">        <span class="keyword">long</span> result = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(n % <span class="number">2</span> == <span class="number">1</span>)&#123;</span><br><span class="line">            result = <span class="number">5</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        n = n / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">long</span> a = <span class="number">20</span>;</span><br><span class="line">        <span class="comment">//快速幂模板</span></span><br><span class="line">        <span class="keyword">while</span>(n &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(n % <span class="number">2</span> == <span class="number">1</span>)&#123;</span><br><span class="line">                result = result * a % <span class="number">1000000007</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//右移一位</span></span><br><span class="line">            n &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">            a = a * a % <span class="number">1000000007</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>)result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2021/07/09/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E5%BF%AB%E9%80%9F%E5%B9%82%E6%95%B4%E7%90%86/image-20210706155441634.png" class="" title="image-20210706155441634">]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>快速幂</tag>
      </tags>
  </entry>
  <entry>
    <title>树状DP整理</title>
    <url>/2021/07/21/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%A0%91%E7%8A%B6DP%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h3 id="什么是树状DP"><a href="#什么是树状DP" class="headerlink" title="什么是树状DP"></a>什么是树状DP</h3><p>建立在 ”树“ 这一数据结构上的DP问题，难度介于线性dp和图dp之间，当前节点的状态可能取决于父亲节点或者孩子节点，即存在两种状态转移方向，树可能包括二叉树和多叉树。</p>
<p>难点还是如何找到状态转移方程</p>
<h4 id="主要题目类型"><a href="#主要题目类型" class="headerlink" title="主要题目类型"></a>主要题目类型</h4><ol>
<li><p>最大独立子集合问题</p>
<p>给一无向图，找出一个点集，使得任意两点之间都没有连边，这个点集就是独立集。而点最多的独立集，就是最大独立集，针对不问题，选取点的条件可能发生变化，但总体还是在限定条件下，选择最优的点集</p>
</li>
<li><p>最小点覆盖</p>
</li>
<li><p>最小支配集</p>
<span id="more"></span>
</li>
</ol>
<h3 id="典型例题"><a href="#典型例题" class="headerlink" title="典型例题"></a>典型例题</h3><h4 id="1-最大独立子集合问题-洛谷P1352-没有上司的舞会"><a href="#1-最大独立子集合问题-洛谷P1352-没有上司的舞会" class="headerlink" title="1. 最大独立子集合问题-洛谷P1352 没有上司的舞会"></a>1. 最大独立子集合问题-洛谷P1352 <a href="https://www.luogu.com.cn/problem/P1352">没有上司的舞会</a></h4><p>每个节点均有两个状态，当前节点参加和当前节点不参加的最优解，状态转移公式如下</p>
<script type="math/tex; mode=display">
dp_{in}[parent] = dp_{out}[child_1] + dp_{out}[child_1]+...+dp_{out}[child_n]</script><ul>
<li>如果选取父节点，孩子节点不能选取</li>
</ul>
<script type="math/tex; mode=display">
dp_{out}[parent] = max(dp_{out}[child_1],dp_{in}[child_1]) + ...+max(dp_{out}[child_n],dp_{in}[child_n])</script><ul>
<li>如果不选取父节点，子节点可选可不不选，本题选择两者较大</li>
</ul>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span></span>&#123;</span><br><span class="line">        List&lt;TreeNode&gt; children;</span><br><span class="line">        <span class="keyword">int</span> happiness;</span><br><span class="line">        TreeNode(<span class="keyword">int</span> happiness)&#123;</span><br><span class="line">            <span class="keyword">this</span>.children = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">this</span>.happiness = happiness;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] dfs(TreeNode cur)&#123;</span><br><span class="line">        <span class="comment">//选择当前节点与不选择当前节点两种解</span></span><br><span class="line">        <span class="keyword">int</span>[] totalHappiness = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>];</span><br><span class="line">        totalHappiness[<span class="number">0</span>] = cur.happiness;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] childHappiness;</span><br><span class="line">        <span class="keyword">for</span>(TreeNode child:cur.children)&#123;</span><br><span class="line">            childHappiness = dfs(child);</span><br><span class="line">            <span class="comment">//父亲选了，孩子不能选</span></span><br><span class="line">            totalHappiness[<span class="number">0</span>] += childHappiness[<span class="number">1</span>];</span><br><span class="line">            <span class="comment">//父亲没选，孩子可选可不选</span></span><br><span class="line">            totalHappiness[<span class="number">1</span>] += Math.max(childHappiness[<span class="number">0</span>],childHappiness[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> totalHappiness;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="comment">//建立二叉树的过程省略</span></span><br><span class="line">        <span class="comment">//....</span></span><br><span class="line">        <span class="comment">//dfs遍历</span></span><br><span class="line">        <span class="keyword">int</span>[] result = dfs(root);</span><br><span class="line">        System.out.println(Math.max(result[<span class="number">0</span>], result[<span class="number">1</span>]));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2021/07/21/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%A0%91%E7%8A%B6DP%E6%95%B4%E7%90%86/image-20210721144347304.png" class="" title="image-20210721144347304">
<h4 id="2-洛谷P2015-二叉苹果树"><a href="#2-洛谷P2015-二叉苹果树" class="headerlink" title="2. 洛谷P2015 二叉苹果树"></a>2. 洛谷P2015 <a href="https://www.luogu.com.cn/problem/P2015">二叉苹果树</a></h4><p>假设求节点 <script type="math/tex">i</script> 保留 <script type="math/tex">j</script> 条边的最优情况，其状态转移公式如下</p>
<script type="math/tex; mode=display">
dp[i][j] = max(dp[i][j], dp[u][i - k - 1] + dp[v][k] + weight[i][v])</script><p>其中 <script type="math/tex">v</script> 为当前节点的某个子节点，<script type="math/tex">weight[i][v]</script> 为连接子节点的遍历的权重，需要遍历所有子节点以及所有保留边情况，计算得到当前节点的所有候选状态。</p>
<p><strong>难理解的几个点</strong></p>
<ol>
<li><p>为什么状态转移是 <script type="math/tex">dp[u][i - k - 1] + dp[v][k] + weight[i][v]</script></p>
<ul>
<li>我们通常理解的二叉树或者多叉树的子问题划分，一定是将保留的边分配给所有的子节点，看每个子节点最最优情况，最后求和为当前节点最优情况，以二叉树为例子，即 <script type="math/tex">dp[left][i - k - 1] + dp[right][k] + weight[left][v] + + weight[right][v]</script></li>
<li>该状态转移公式，并不从所有的子节点出发，而是将保留的边分配给当前已遍历的子节点，即默认未遍历子树中的边全部删除情况，每遍历到一个新的孩子节点，重新考虑当前子节点分配边的情况</li>
<li>形象的例子就是，分苹果给张三、李四、王五，第一种思路是直接把三个人叫过来，看如何分成三份；另一种是先把张三叫过来，记录下来 把苹果从 0-全部 给他的情况，再叫李四，看给张三后，剩下不同苹果的基础上，给李四 0-全部 的最优情况。最后把王五拉过来，看给张三李四分完剩下，给他分怎么最优。</li>
</ul>
<p>即一种是直接考虑所有的节点之间分配，另一种是分成 已遍历 + 未遍历，未遍历节点不断地加入已遍历集合。<strong>第二种思路适用范围更广</strong>，如果问题变为多叉或者不定叉树，第一种思路代码无法实现</p>
</li>
<li><p>遍历部分的实现，<strong>为什么要倒序DP</strong>，即保留边数从大到小</p>
<ul>
<li>第一层遍历，遍历当前节点保留不同边的情况，最大边数 <script type="math/tex">j</script> 取<strong>已遍历子节点子树中边的个数和</strong>与<strong>要求保留边个数</strong>的较小值，<strong>倒序DP</strong></li>
<li>第二层遍历，遍历当前新节点的所有保留边数情况，最大边数 <script type="math/tex">k</script> 取 <strong><script type="math/tex">j-1</script></strong> 与 <strong>当前子节点子树边数</strong>的较小值，<strong>顺序无所谓</strong></li>
</ul>
<p>划分为子问题后，需要与原数组的前部元素求和，所以求大时会用到小，如果正序，前部修改导致后部计算使用的新计算的状态</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j = Math.min(childEdges[curNode], m);j &gt;= <span class="number">1</span>;j--)&#123;</span><br><span class="line">    <span class="comment">//k为当前子节点中保留边的个数</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> k = Math.min(j - <span class="number">1</span>, childEdges[i]);k &gt;= <span class="number">0</span>;k--)&#123;</span><br><span class="line">        dpArray[curNode][j] = Math.max(dpArray[curNode][j], dpArray[curNode][j - k - <span class="number">1</span>] + dpArray[i][k] + adjustMatrix[curNode][i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><p>基于dfs+邻接矩阵实现</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> curNode, <span class="keyword">int</span>[][] adjustMatrix,<span class="keyword">int</span>[][] dpArray,<span class="keyword">int</span>[] childEdges, <span class="keyword">int</span>[] visited, <span class="keyword">int</span> m)</span></span>&#123;</span><br><span class="line">        visited[curNode] = <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//首先dfs子树，求子问题解并获得子结点个数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; adjustMatrix.length;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(adjustMatrix[curNode][i] != -<span class="number">1</span> &amp;&amp; visited[i] != <span class="number">1</span>)&#123;</span><br><span class="line">                visited[i] = <span class="number">1</span>;</span><br><span class="line">                dfs(i, adjustMatrix, dpArray, childEdges, visited, m);</span><br><span class="line">                <span class="comment">//已遍历子树边数和</span></span><br><span class="line">                childEdges[curNode] += childEdges[i] + <span class="number">1</span>;</span><br><span class="line">                <span class="comment">//遍历当前节点保留不同数量树枝的解</span></span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> j = Math.min(childEdges[curNode], m);j &gt;= <span class="number">1</span>;j--)&#123;</span><br><span class="line">                    <span class="comment">//k为当前子节点中保留边的个数</span></span><br><span class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> k = Math.min(j - <span class="number">1</span>, childEdges[i]);k &gt;= <span class="number">0</span>;k--)&#123;</span><br><span class="line">                        dpArray[curNode][j] = Math.max(dpArray[curNode][j], dpArray[curNode][j - k - <span class="number">1</span>] + dpArray[i][k] + adjustMatrix[curNode][i]);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="comment">// 节点和边的数量</span></span><br><span class="line">        <span class="keyword">int</span> m,n;</span><br><span class="line">        <span class="keyword">int</span>[][] adjustMatrix;</span><br><span class="line">        m = scanner.nextInt();</span><br><span class="line">        n = scanner.nextInt();</span><br><span class="line">        adjustMatrix = <span class="keyword">new</span> <span class="keyword">int</span>[m][m];</span><br><span class="line">        <span class="comment">//初始化矩阵</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; m;j++)&#123;</span><br><span class="line">                adjustMatrix[i][j] = -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//读取边</span></span><br><span class="line">        <span class="keyword">int</span> tempNode1;</span><br><span class="line">        <span class="keyword">int</span> tempNode2;</span><br><span class="line">        <span class="keyword">int</span> tempWeight;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; m - <span class="number">1</span>;i++)&#123;</span><br><span class="line">            tempNode1 = scanner.nextInt() - <span class="number">1</span>;</span><br><span class="line">            tempNode2 = scanner.nextInt() - <span class="number">1</span>;</span><br><span class="line">            tempWeight = scanner.nextInt();</span><br><span class="line">            adjustMatrix[tempNode1][tempNode2] = tempWeight;</span><br><span class="line">            adjustMatrix[tempNode2][tempNode1] = tempWeight;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//dfs动态规划</span></span><br><span class="line">        <span class="keyword">int</span>[] visited = <span class="keyword">new</span> <span class="keyword">int</span>[m];</span><br><span class="line">        <span class="keyword">int</span>[] childEdges = <span class="keyword">new</span> <span class="keyword">int</span>[m];</span><br><span class="line">        <span class="keyword">int</span>[][] dpArray = <span class="keyword">new</span> <span class="keyword">int</span>[m][n + <span class="number">1</span>];</span><br><span class="line">        dfs(<span class="number">0</span>, adjustMatrix, dpArray, childEdges, visited, n);</span><br><span class="line">        System.out.println(dpArray[<span class="number">0</span>][n]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2021/07/21/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%A0%91%E7%8A%B6DP%E6%95%B4%E7%90%86/image-20210719171204593.png" class="" title="image-20210719171204593">
]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>树状DP</tag>
      </tags>
  </entry>
  <entry>
    <title>树状数组整理</title>
    <url>/2022/04/10/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h2 id="树状数组（Binary-indexed-tree）"><a href="#树状数组（Binary-indexed-tree）" class="headerlink" title="树状数组（Binary indexed tree）"></a>树状数组（Binary indexed tree）</h2><blockquote>
<p>A <strong>Fenwick tree</strong> or <strong>binary indexed tree</strong> is a data structure that can efficiently update elements and calculate <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix sums</a> in a table of numbers.</p>
<p>来自Wikipedia</p>
</blockquote>
<p>树状数组是一种求解前缀和问题的简单数据结构，能够在<strong>O(logn)</strong>的时间复杂度内解决区间求和问题，主要支持两种操作</p>
<ol>
<li><strong>单点修改</strong></li>
<li><strong>区间操作</strong></li>
</ol>
<h3 id="主要思路"><a href="#主要思路" class="headerlink" title="主要思路"></a>主要思路</h3><p>类比<strong>任何数</strong>均可以拆分为<strong>有限个不同2的幂次</strong>的求和，原论文作者认为<strong>一串序列</strong>的求和同样可以拆分为<strong>有限个不同长度为2的幂次的序列</strong>的和。在数字的拆分中，其二进制表示中1的个数即为不同2的幂次，例如 “10”，“12”</p>
<script type="math/tex; mode=display">
10 -> 1010 = 1000 + 0010\\
14 -> 1110 = 1000 + 0100 + 0010</script><span id="more"></span>
<p>自然想到一个问题：如何快速的找到<strong>任意数的不同二次幂的组合</strong>？引出了<strong>lowbit思路</strong>:</p>
<ol>
<li><p>通过<strong>原码与补码求逻辑与运算</strong>，求得目标数字的<strong>最右边的一个1</strong></p>
<script type="math/tex; mode=display">
lowbit(x) = (x)\&(-x)</script></li>
<li><p>原数字减去lowbit，获得少了一位1的数字</p>
<script type="math/tex; mode=display">
x_i = x_{i-1} - lowbit(x_{i-1})</script></li>
<li><p>重复操作，直到 $x_i = 0$ </p>
</li>
</ol>
<p>重复此过程每一步计算得到的 $lowbit(x_i)$ 即为原数字的不同2的幂次拆分，以14为例:</p>
<script type="math/tex; mode=display">
lowbit(14) = 0010 \\
\downarrow \\
lowbit(14 - 0010 = 12) = 0100\\
\downarrow \\
lowbit(12 - 0100 = 8) = 1000 \\
\downarrow \\
lowbit(0 - 1000 = 0) = 0000</script><h4 id="如何将对应拆分思路迁移到前缀和？"><a href="#如何将对应拆分思路迁移到前缀和？" class="headerlink" title="如何将对应拆分思路迁移到前缀和？"></a>如何将对应拆分思路迁移到前缀和？</h4><p>不妨用 $C[i]$ 表示 目标数组$f[1]…f[i]$的前缀和，通过$lowerbit$操作，我们可以快速找到<strong>任意区间长度</strong> 对应的<strong>二次幂区间长度的组合</strong>。</p>
<p>问题是我们如何设计存储方式，提前存储这些二次幂区间长度的区间和？观察14转化为组合的过程，对应到区间表达形式为:</p>
<script type="math/tex; mode=display">
(0,14] = (12, 14] + (8, 12] + (0, 8] \\
\updownarrow \\
(0,14] = (14 - lowbit(14), 14] + (12 - lowbit(12), 12] + (8 - lowbit(8), 8] \\
\updownarrow \\
(0,1110] = (1100, 1110] + (1000, 1100] + (0000, 1000]\\</script><p>可以得到每个区间右边界可以由上个区间右边界减去lobit得到，而区间的长度等于当前区间右边界的lowbit（<strong>拆分区间的递推关系</strong>），自然可以想到，将区间$(i - lowbit(i),i]$的和存储到 <strong>index = i</strong>的位置</p>
<ul>
<li>因此定义$tree$数组，对于<strong>任意$tree[i]$，其存储范围为 $(i-lowbit(i),i]$区间的和</strong>，如下：</li>
</ul>
<script type="math/tex; mode=display">
tree[i] = \sum^i_{j=i-lowbit(i) + 1}f[j]</script><p>任意前缀和 $C[i]$计算，按照上述拆分过程，可以转化为不断的减去最右边一的过程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int index = i;index &gt; 0;index -= lowbit(index)):</span><br><span class="line">	//index -= lowbit(index) 就是类似于14拆分过程中的找所有2次幂过程</span><br><span class="line">	C[i] += tree[index]</span><br></pre></td></tr></table></figure>
<h4 id="如何支持单点修改"><a href="#如何支持单点修改" class="headerlink" title="如何支持单点修改"></a>如何支持单点修改</h4><p>若修改 $f[i]$，需要修改所有包含$f[i]$ 的 $tree[index]$, 我们要找到所有包含当前元素的区间，假设 $tree[idx]$ 包含 $f[i]$，则 $i$一定满足:</p>
<script type="math/tex; mode=display">
idx - lowbit(idx) < i <= idx</script><p>来自博客<a href="http://duanple.blog.163.com/blog/static/7097176720081131113145832/"><strong>Binary indexed tree-树状数组</strong> </a>的形象解释</p>
<img src="/2022/04/10/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E6%95%B4%E7%90%86/image-20220405190706777.png" class="" title="image-20220405190706777">
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><h4 id="lowbit-函数"><a href="#lowbit-函数" class="headerlink" title="lowbit()函数"></a>lowbit()函数</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lowbit</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> x &amp; -x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="求前缀和"><a href="#求前缀和" class="headerlink" title="求前缀和"></a>求前缀和</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//预先处理好的子区间和数组</span></span><br><span class="line"><span class="keyword">int</span> tree[maxIndex]</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">query</span><span class="params">(<span class="keyword">int</span> index)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span>(;index &gt; <span class="number">0</span>;index++)&#123;</span><br><span class="line">		result += tree[index];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="更新方法"><a href="#更新方法" class="headerlink" title="更新方法"></a>更新方法</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//预先处理好的子区间和数组</span></span><br><span class="line"><span class="keyword">int</span> tree[maxIndex]</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(<span class="keyword">int</span> index, <span class="keyword">int</span> val)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> pos = index; pos &lt; maxIndex; pos += lowbit(pos))</span><br><span class="line">        <span class="comment">//以加法为例</span></span><br><span class="line">        tree[pos] += x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="初始化树状数组"><a href="#初始化树状数组" class="headerlink" title="初始化树状数组"></a>初始化树状数组</h4><p>wekipedia上的一个从数组[1,2,3,4,5]构建树状数组的过程：</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/BITDemo.gif/220px-BITDemo.gif" alt="BITDemo.gif"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> tree[maxIndex]</span><br><span class="line"><span class="comment">//待求和数组</span></span><br><span class="line"><span class="keyword">int</span> aim[maxIndex]</span><br><span class="line"><span class="comment">//1.调用update方法（复杂度O(nlogn)）</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt; maxIndex;i++)&#123;</span><br><span class="line">    update(i, aim[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2.前缀和法(tree[i] = preSum[i] - preSum[i - lowbit(i)])</span></span><br><span class="line"><span class="comment">// 	复杂度O(n)</span></span><br><span class="line"><span class="keyword">int</span> preSum[maxIndex];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt; maxIndex;i++)&#123;</span><br><span class="line">    preSum[i] = preSum[i - <span class="number">1</span>] + aim[i];</span><br><span class="line">    tree[i] = preSum[i] - preSum[i - lowbit(i)];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="模板题目"><a href="#模板题目" class="headerlink" title="模板题目"></a>模板题目</h3><ol>
<li><a href="https://www.luogu.com.cn/problem/P3374">luogu P3374 :树状数组1</a><ul>
<li>使用scanner做输入会出现三个测试用例TLE<strong>（坑爹）</strong></li>
</ul>
</li>
<li><a href="https://www.luogu.com.cn/problem/P3368">luogu P3368 :树状数组2</a><ul>
<li>通过<strong>差分</strong>的思路，将树状数组支持的操作变为<ul>
<li><strong>单点修改-&gt;区间修改</strong></li>
<li><strong>区间查询-&gt;单点查询</strong></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://www.luogu.com.cn/problem/P2880">luogu P2880 ：牛飞盘比赛</a><ul>
<li>树状数组维护值从 <strong>区间和</strong> 变为 <strong>区间内最值</strong></li>
<li>update操作变为最大值更新，查询操作递归完成</li>
</ul>
</li>
</ol>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ol>
<li><a href="https://zh.wikipedia.org/wiki/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84">wikipidia：树状数组</a></li>
<li><a href="http://duanple.blog.163.com/blog/static/7097176720081131113145832/">博客：Binary indexed tree-树状数组</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/93795692">博客：算法学习笔记(2) : 树状数组</a></li>
<li><a href="https://www.luogu.com.cn/training/3079">树状数组模板题</a></li>
</ol>
]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>树状数组</tag>
      </tags>
  </entry>
  <entry>
    <title>Dockerfile理解使用</title>
    <url>/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>docker file 包含一系列命令行，docker通过该文件组织生成镜像，一个docker file文件主要包括四部分：</p>
<ol>
<li>基础镜像信息</li>
<li>维护者信息</li>
<li>镜像操作指令</li>
<li>容器启动时执行指令</li>
</ol>
<p>以一个dockerfile为例：<br><img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/image-20210618162710697.png" class="" title="image-20210618162710697.png"></p>
<blockquote>
<p>Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大</p>
</blockquote>
<span id="more"></span>
<h3 id="基本的命令内容"><a href="#基本的命令内容" class="headerlink" title="基本的命令内容"></a>基本的命令内容</h3><ol>
<li><p>FORM：指定基础镜像，必须为第一个命令</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line">   　　<span class="comment"># 格式：</span></span><br><span class="line"><span class="keyword">FROM</span> &lt;image&gt;</span><br><span class="line"><span class="keyword">FROM</span> &lt;image&gt;:&lt;tag&gt;</span><br><span class="line"><span class="keyword">FROM</span> &lt;image&gt;@&lt;digest&gt;</span><br><span class="line">   　　<span class="comment"># 例如：</span></span><br><span class="line">   　　<span class="keyword">FROM</span> node:alpine</span><br></pre></td></tr></table></figure>
<p>同一个镜像可能有不同大小版本，不同的tag表示基于不同的base image（以python3.9.6 镜像为例）</p>
<ol>
<li><p><strong>完整版</strong> </p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/image-20210727160609885.png" class="" title="image-20210727160609885">
</li>
<li><p><strong>alpine</strong>  基于<strong>alpine linux</strong>的docker镜像，特点就是容量小，适合作为基础镜像</p>
<ul>
<li>缺少<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/GNU_C_Library">GNU C Library</a> (glibc)</li>
<li>缺少的软件过多，<a href="https://pythonspeed.com/articles/alpine-docker-python/">构建时间长</a></li>
</ul>
<blockquote>
<p>Alpine 是众多 Linux 发行版中的一员，和 CentOS、Ubuntu、Archlinux之类一样，只是一个发行版的名字，号称小巧安全，有自己的包管理工具 apk</p>
</blockquote>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/image-20210727160550212.png" class="" title="image-20210727160550212">
</li>
<li><p><strong>Debian Buster</strong> 基于<strong>Debian linux</strong>的docker镜像</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/image-20210727160529738.png" class="" title="image-20210727160529738">
</li>
<li><p><strong>slim</strong> 即瘦身版本，删去了部分通用包支持</p>
<ul>
<li>python:slim-buster是大多数Python用例的良好基础镜像</li>
</ul>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/image-20210727160805454.png" class="" title="image-20210727160805454">
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Dockerfile%E7%90%86%E8%A7%A3%E4%BD%BF%E7%94%A8/image-20210727160814190.png" class="" title="image-20210727160814190">
</li>
</ol>
</li>
<li><p>RUN: 构建镜像是执行的命令(支持两种执行方式)</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># shell执行</span></span><br><span class="line"><span class="comment"># 格式：</span></span><br><span class="line">    <span class="keyword">RUN</span><span class="bash"> &lt;<span class="built_in">command</span>&gt;</span></span><br><span class="line"><span class="comment"># exec执行</span></span><br><span class="line"><span class="comment"># 格式：</span></span><br><span class="line">    <span class="keyword">RUN</span><span class="bash"> [<span class="string">&quot;command&quot;</span>, <span class="string">&quot;param1&quot;</span>, <span class="string">&quot;param2&quot;</span>]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ADD/COPY:将本地文件添加到docker镜像中</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="bash"> &lt;src&gt; &lt;dest&gt;</span></span><br><span class="line"><span class="comment"># 例如：</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> . /data</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>WORKDIR:切换工作目录,即容器启动后的pwd，当前目录</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 格式：</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> path</span></span><br><span class="line"><span class="comment"># 例如：</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> . /data</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>CMD： 在容器启动后执行相关命令</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 格式：</span></span><br><span class="line">    <span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;executable&quot;</span>,<span class="string">&quot;param1&quot;</span>,<span class="string">&quot;param2&quot;</span>] </span></span><br><span class="line">    <span class="keyword">CMD</span><span class="bash"> <span class="built_in">command</span> param1 param2 </span></span><br></pre></td></tr></table></figure>
<ul>
<li>如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。</li>
</ul>
<p>参数名和参数值相连，分别为列表中的两个不同项，以gunicorn为例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gunicorn MainWebApp:app -c gunicorn.conf.py -t 100</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;gunicorn&quot;</span>, <span class="string">&quot;MainWebApp:app&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;gunicorn.conf.py&quot;</span>, <span class="string">&quot;&quot;</span>-t<span class="string">&quot;, &quot;</span>100<span class="string">&quot;]</span></span></span><br></pre></td></tr></table></figure>
<p>列表中的参数和命令一定要使用双引号</p>
</li>
</ol>
]]></content>
      <categories>
        <category>框架/技术学习</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker基础概念</title>
    <url>/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>主要包括三个基本核心概念：</p>
<ul>
<li><strong>镜像（image)</strong>：相当于一个静态的文件系统，类似于未安装的windows ios文件，相当于是一个未挂载的root文件系统</li>
<li><strong>容器（container)</strong>：容器是镜像运行时的实体，可以启动、创建、停止以及删除。容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间</li>
<li><strong>仓库（Repository）</strong>：镜像中心，类似于maven的依赖包中心，用来保存镜像，最常使用的公共仓库是官方的Docker Hub</li>
</ul>
<p>基本架构（cs架构）:</p>
<blockquote>
<p>守护进程（daemon）是生存期长的一种进程，没有控制终端。它们常常在系统引导装入时启动，仅在系统关闭时才终止</p>
</blockquote>
<ul>
<li><strong>Docker 客户端(Client)</strong>:与docker host中的守护进程进行通信，通过命令执行实际的操作（cs架构中的c）</li>
<li><strong>Docker 主机(Host)</strong>:运行容器，存储镜像的机器</li>
<li><strong>Docker Registry</strong>：一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。</li>
</ul>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210727162745322.png" class="" title="image-20210727162745322">
<span id="more"></span>
<p>从hello-word可以得到docker执行的基本流程</p>
<ol>
<li>client 连接 hosts 的daemon进程</li>
<li>daemon进程查看本地镜像，如果不存在，向远程Registry获取镜像</li>
<li>daemon进程为镜像启动容器</li>
<li>daemon进程将信息发送给client</li>
</ol>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210727162755137.png" class="" title="image-20210727162755137">
<h3 id="几个基本概念"><a href="#几个基本概念" class="headerlink" title="几个基本概念"></a>几个基本概念</h3><h4 id="1-容器与虚拟机的区别"><a href="#1-容器与虚拟机的区别" class="headerlink" title="1. 容器与虚拟机的区别"></a>1. 容器与虚拟机的区别</h4><p><strong>虚拟机</strong>，相当于一套真的操作系统，在os层上增加了一层hypervisor，用来虚拟化硬件，每个虚拟机以层虚拟化的硬件为基础，建立自己的OS层（GuestOa），应用层.</p>
<p><strong>容器</strong>，更偏向于一个进程隔离空间，空间内包含特定进程执行所需要的环境（镜像），容器之间互不干扰，但是共同调用底层的os接口，由daemon进程统一管理</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210727162804622.png" class="" title="image-20210727162804622">
<h4 id="2-Dockerfile相关总结"><a href="#2-Dockerfile相关总结" class="headerlink" title="2. Dockerfile相关总结"></a>2. Dockerfile相关总结</h4><h2 id="Docker基本使用（以某个项目部署为例）"><a href="#Docker基本使用（以某个项目部署为例）" class="headerlink" title="Docker基本使用（以某个项目部署为例）"></a>Docker基本使用（以某个项目部署为例）</h2><ol>
<li><p>在项目中添加Dockerfile(该文件用来提供构建镜像文件的必要信息)</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210727162814042.png" class="" title="image-20210727162814042">
</li>
<li><p>docker builder 构建镜像文件</p>
<ul>
<li>首先拉取基础docker镜像，之后将应用程序复制到docker容器中，根据应用程序依赖信息加载相关依赖，加载完成后执行初始run命令</li>
<li>-t 指明生成镜像文件的tag</li>
<li>. 指明dockerfile位置</li>
</ul>
</li>
<li><p>docker run 指定并绑定端口后运行项目</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210727162829498.png" class="" title="image-20210727162829498">
</li>
</ol>
<h3 id="docker基础镜像构建（搭建基础机器学习-深度学习环境）"><a href="#docker基础镜像构建（搭建基础机器学习-深度学习环境）" class="headerlink" title="docker基础镜像构建（搭建基础机器学习+深度学习环境）"></a>docker基础镜像构建（搭建基础机器学习+深度学习环境）</h3><blockquote>
<p>To stop a container, use <code>CTRL-c</code>. This key sequence sends <code>SIGKILL</code> to the container. If <code>--sig-proxy</code> is true (the default),<code>CTRL-c</code> sends a <code>SIGINT</code> to the container. If the container was run with <code>-i</code> and <code>-t</code>, you can detach from a container and leave it running using the <code>CTRL-p CTRL-q</code> key sequence.</p>
</blockquote>
<ol>
<li><p>使用ubuntu作为基础镜像,安装anaconda</p>
<ul>
<li><p>docker cp 复制文件到镜像中</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210726103848754.png" class="" title="image-20210726103848754">
</li>
<li><p>docker attach 切换到前台</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210726104207802.png" class="" title="image-20210726104207802">
</li>
<li><p><code>sh Anaconda3-2021.05-Linux-x86_64.sh</code> 执行安装脚本</p>
</li>
</ul>
</li>
<li><p>退出容器，将当前容器导出为镜像 docker commit</p>
<img src="/2021/07/27/%E6%9D%82%E9%A1%B9%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/Docker%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/image-20210726105455898.png" class="" title="image-20210726105455898">
</li>
<li><p>推送远程仓库（镜像名称中的用户名一定要与远程仓库用户名一致，否则报错）</p>
</li>
</ol>
]]></content>
      <categories>
        <category>框架/技术学习</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>读论文1-resNet</title>
    <url>/2022/03/13/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%871-resNet/</url>
    <content><![CDATA[<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><blockquote>
<p>论文地址 ：<a href="http://cn.arxiv.org/pdf/1512.03385.pdf">Deep Residual Learning for Image Recognition</a></p>
</blockquote>
<p>针对深度神经网络难以训练的问题，ResNet提出了一种特殊的网络结构-残差，有效的解决了深度网络的退化问题，降低了深度网络学习难度</p>
<h3 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h3><ol>
<li><p>摘要 abstract</p>
<p>按照<strong>问题-&gt;解决方案-&gt;实验效果</strong>的逻辑，首先提出问题：“深度神经网络难以训练”，引出解决方案-residual net，最后列举在不同数据上的卓越效果（ImageNet，COCO，CIFAR），证明解决方案的有效性</p>
</li>
<li><p>介绍 intro</p>
<p>与摘要的逻辑相同，逻辑非常严密（ps:太丝滑了）</p>
<ol>
<li>为什么要用深度网络？ 因为深度网络有助于捕捉特征，提升任务效果</li>
<li>增加网络深度又会出现<strong>两个主要问题</strong>：一是梯度爆炸/消失，二是深度网络的退化问题</li>
<li>梯度爆炸可以通过 <strong>normalized initialization and intermediate normalization layers</strong> 解决</li>
<li>网络退化如何解决？引出了本文的残差机制-residual</li>
<li>最后又展示了一轮不同数据上的实验效果</li>
</ol>
</li>
</ol>
<span id="more"></span>
<ol>
<li><p>相关工作 related work</p>
<p>没细看。。</p>
</li>
<li><p>算法描述 Deep Residual Learning</p>
<p><strong>残差机制-&gt;网络架构设计-&gt;网络实现</strong></p>
<ol>
<li><p>提出了深度网络之所以会出现退化,是因为 <strong>难以学习直接映射</strong>（只是形式上的理解，没有给出公式证明），很自然引出了残差机制的设计</p>
<blockquote>
<p>might have difficulties in approximating identity mappings by multiple nonlinear layers.</p>
</blockquote>
</li>
<li><p>为了方便对比残差机制是否真的有效，设计了<strong>Plain Networks</strong>和<strong>Residual Networks</strong>两种架构</p>
</li>
</ol>
</li>
<li><p>实验 Experiments</p>
<p>列举了从 ImageNet 到CIFAR10再到PASCAL and MS COCO三个数据集上不同任务的实验效果</p>
<ol>
<li><p>首先对比在ImageNet数据集上34层Plain network和18层效果，证明深层网络确实出现了退化现象，并且排除了是梯度消失造成的可能</p>
<blockquote>
<p> We conjecture that the deep plain nets may have <strong>exponentially low convergence rates</strong>, which impact the reducing of the training error</p>
</blockquote>
</li>
<li><p>然后对比34层和18层Residual Networks效果,证明残差确实能够解决深层网络退化问题,并且能够在训练初期加速网络收敛速度</p>
<blockquote>
<p>This indicates that the <strong>degradation problem is well addressed</strong> in this setting and we manage to obtain accuracy gains from increased depth</p>
</blockquote>
</li>
<li><p>继续对比了 <strong>直接映射 和 投影映射</strong> 两种不同残差计算方式，是否影响残差发挥作用，得到结论：单纯的直接映射残差机制即可解决退化问题，投影映射效果优于直接映射，但是计算量增加较大</p>
</li>
<li><p>之后提出了一种<strong>Deeper Bottleneck Architectures</strong>，在ImageNet上探索残差机制在更深层网络上的效果</p>
<img src="/2022/03/13/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%871-resNet/image-20220309093015669.png" class="" title="image-20220309093015669">
</li>
<li><p>在小数据集CIFAR-10上验证：<strong>当学习任务足够简单，并不需要过深网络时，深度网络中的残差映射会近似于直接映射</strong>（加了残差块的深层网络 <strong>等价于</strong> 浅层网络+多个直接映射层）</p>
<blockquote>
<p>the residual functions might be generally closer to zero than the non-residual functions.</p>
</blockquote>
</li>
<li><p>最后秀了一波在目标检测任务上的优秀成果</p>
</li>
</ol>
</li>
<li><p>总结 summarize</p>
<p>因为CVPR的页数限制没有总结（？）</p>
</li>
</ol>
<h3 id="残差机制-residual"><a href="#残差机制-residual" class="headerlink" title="残差机制-residual"></a>残差机制-residual</h3><img src="/2022/03/13/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%871-resNet/image-20220309093814713.png" class="" title="image-20220309093814713">
<p>文章中分别提出了两种残差映射公式，其中第一种为 “Identity Mapping”，直接映射公式如下</p>
<script type="math/tex; mode=display">
y=F(x,\{W_i\}) +x  \tag{1}</script><p>其中 <script type="math/tex">F(x,\{W_i\})</script> 代表残差块内从X到残差的映射（如图2为中间带ReLU激活函数的两个权重层）,直接映射要求输入输出的唯独相同，可以直接叠加</p>
<p>第二种为 “linear projection”，将输入投影到与输出相同维度，方便叠加</p>
<script type="math/tex; mode=display">
y=F(x,\{W_i\}) +W_s x  \tag{2}</script><ul>
<li>论文中已通过实验证明， “Identity Mapping”即可解决深度网络的退化问题</li>
<li>虽然 “linear projection”效果略优于 “Identity Mapping”，但投影操作增加了计算量</li>
</ul>
<h3 id="网络结构设计"><a href="#网络结构设计" class="headerlink" title="网络结构设计"></a>网络结构设计</h3><p>两个基本设计原则</p>
<ol>
<li>当特征图大小缩小一半（<script type="math/tex">224*224->112*112</script>），通道数翻一倍（<script type="math/tex">64->128</script>）</li>
<li>当特征图大小不变时，通道数保持不变</li>
</ol>
<p>网络组成结构如图</p>
<ul>
<li>每个中括号内为一个残差块，每一个例如$conv2_x，conv3_x$ 的卷积层包含多个残差块</li>
<li>跨越不同卷积层时特征图缩小一般，通道数扩大一倍</li>
<li>例如18层网络的结构为<ol>
<li>首先通过 <script type="math/tex">7*7</script> 输出通道为64的卷积层+ <script type="math/tex">3*3</script>的最大池化层</li>
<li>进入第<script type="math/tex">conv2\_x</script>卷积层，包括两个残差块，每个残差块内包含两个<script type="math/tex">3*3*64</script> 的卷积层</li>
<li>进入第<script type="math/tex">conv2\_x</script>卷积层，同样包括两个残差块，由于第一个残差块输入为<script type="math/tex">56*56</script> 输出为<script type="math/tex">28*28</script> 需要使用投影残差计算，其余无差异，其中投影残差作者对比了两种不同的选择<ul>
<li>通过padding升维度，避免投影计算（A)</li>
<li>1*1卷积核，类似于全连接层(B）</li>
</ul>
</li>
</ol>
</li>
</ul>
<img src="/2022/03/13/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%871-resNet/image-20220309150217483.png" class="" title="image-20220309150217483">
<p><strong>Deeper Bottleneck Architectures</strong></p>
<p>针对ImageNet设计深层网络时，为了降低计算复杂度，设计了一种Bottleneck block</p>
<ul>
<li>与普通残差块不同在于 包含三个卷积层: <script type="math/tex">1*1 + 3*3 + 1*1</script>,其中 <script type="math/tex">1*1</script> 负责升维和降维</li>
<li>上图中34层和50层，虽然增加了16层，但是使用Bottleneck block的50层网络计算量增加不大</li>
</ul>
<img src="/2022/03/13/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%871-resNet/image-20220309152918557.png" class="" title="image-20220309152918557">
<p><strong>训练超参数</strong></p>
<ol>
<li>使用SGD，256 mini-batch，迭代训练<script type="math/tex">6*10^4</script> 次</li>
<li>初始学习率为0.1，每当错误率达到稳定，学习率缩小10倍</li>
<li>weight decay:0.0001,momentum:0.9,不使用dropout</li>
<li>每个卷积层之后，激活层之前，添加BN层</li>
</ol>
<h3 id="Pytorch-代码实现"><a href="#Pytorch-代码实现" class="headerlink" title="Pytorch 代码实现"></a>Pytorch 代码实现</h3><p>基础残差块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    expansion: <span class="built_in">int</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self,</span></span></span><br><span class="line"><span class="params"><span class="function">        inplanes: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        planes: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        stride: <span class="built_in">int</span> = <span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        downsample: <span class="type">Optional</span>[nn.Module] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        groups: <span class="built_in">int</span> = <span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        base_width: <span class="built_in">int</span> = <span class="number">64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        dilation: <span class="built_in">int</span> = <span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        norm_layer: <span class="type">Optional</span>[<span class="type">Callable</span>[..., nn.Module]] = <span class="literal">None</span></span></span></span><br><span class="line"><span class="params"><span class="function">    </span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> groups != <span class="number">1</span> <span class="keyword">or</span> base_width != <span class="number">64</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;BasicBlock only supports groups=1 and base_width=64&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> dilation &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;Dilation &gt; 1 not supported in BasicBlock&quot;</span>)</span><br><span class="line">        <span class="comment"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        <span class="comment"># 第一个卷积层传入 输入通道，输出通道，步长</span></span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        <span class="comment"># 卷积层后+batchnorm层</span></span><br><span class="line">        self.bn1 = norm_layer(planes)</span><br><span class="line">        <span class="comment"># relu激活函数</span></span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = norm_layer(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">		<span class="comment"># 若输入与输出不相同，使用投影映射，也就是残差公式2</span></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line">		<span class="comment"># 残差计算+ReLU激活函数</span></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>投影残差函数初始化(就是简单的$1*1$卷积核加batchnorm）:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">    downsample = nn.Sequential(</span><br><span class="line">        conv1x1(self.inplanes, planes * block.expansion, stride),</span><br><span class="line">        norm_layer(planes * block.expansion),</span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Bottleneck块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">       identity = x</span><br><span class="line">       <span class="comment"># 1*1</span></span><br><span class="line">       out = self.conv1(x)</span><br><span class="line">       out = self.bn1(out)</span><br><span class="line">       out = self.relu(out)</span><br><span class="line">	<span class="comment"># 3*3</span></span><br><span class="line">       out = self.conv2(out)</span><br><span class="line">       out = self.bn2(out)</span><br><span class="line">       out = self.relu(out)</span><br><span class="line">	<span class="comment"># 1*1</span></span><br><span class="line">       out = self.conv3(out)</span><br><span class="line">       out = self.bn3(out)</span><br><span class="line">       </span><br><span class="line">       <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">           identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">       out += identity</span><br><span class="line">       out = self.relu(out)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>resnet网络结构</p>
<img src="/2022/03/13/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%871-resNet/image-20220309154506166.png" class="" title="image-20220309154506166">]]></content>
      <categories>
        <category>读论文</category>
      </categories>
      <tags>
        <tag>resNet</tag>
      </tags>
  </entry>
  <entry>
    <title>读论文2-transformer</title>
    <url>/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/</url>
    <content><![CDATA[<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><blockquote>
<p>论文地址：<a href="https://arxiv.org/pdf/1706.03762v5.pdf">Attention Is All You Need</a></p>
</blockquote>
<p>本文提出一个区别于传统RNN、CNN的基于attention机制的网络架构-transformer，在具备RNN捕捉序列特征能力的基础上，实现了并行计算，降低了计算成本（看论文名字就知道作者对论文内容非常自信）</p>
<h3 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h3><p>总结下来发现这篇论文没讲故事，就是单纯的讲自己的工作，非常的简洁</p>
<ol>
<li><p>摘要 abstract</p>
<p>从问题提出-&gt;解决方案-&gt;效果，三句话介绍NMT-&gt;encoder-decoder-&gt;transformer模型，剩余的句子全在列举是实验效果，<strong>非常简洁</strong></p>
</li>
<li><p>介绍 intro</p>
<p>还是围绕着 rnn、encoder-decoder、attention这三个主要内容</p>
<ul>
<li>首先介绍rnn在LM和NMT中广泛应用，取得了SOTA成果，但是其还是存在无法并行计算的问题（介绍了为什么）</li>
<li>然后介绍了attention机制能够跨距离建模依赖，但是目前研究大部分还是与rnn结合在一起</li>
<li>最后引出了本文完全基于attention机制的transformer模型</li>
</ul>
</li>
<li><p>背景 background</p>
<ul>
<li>列举了其他为了降低计算量的研究（convS2S, ByteNet）,但是降低效果不如transformer（证明自己工作的价值）</li>
<li>通过列举参考文献，证明 self-attention，decoder-encoder两种设计的有效性（证明自己解决方案的科学性）</li>
</ul>
</li>
</ol>
<span id="more"></span>
<ol>
<li><p>模型架构</p>
<ul>
<li>先是一段话+一张模型总图，整体介绍模型，然后每个层进行拆解，讲解内部机制</li>
<li><strong>总分结构</strong></li>
</ul>
</li>
<li><p>why attention</p>
<p>对比attention，rnn，cnn三种机制的计算的时间复杂度，证明attention机制真的有助于降低计算量</p>
</li>
<li><p>训练 traning</p>
<p>介绍了训练参数等</p>
</li>
<li><p>实验 Results</p>
<p>列举了在NMT以及English Constituency Parsing两个任务上的实验效果</p>
<ul>
<li>WMT 2014 English-to-German，WMT 2014 English-to-French实现了SOTA</li>
<li>为了证明transformer的在其它任务上的可泛化性，做了该实验，除了RNNG这个模型，transformer效果优于之前的所有模型</li>
</ul>
</li>
<li><p>结论 conclusion</p>
<p>总说自己提出了一个完全基于attention的模型，并再提了实验结果，最后说自己要把transformer推广到其他任务上（efficiently handle large inputs and outputssuch as images, audio and video）</p>
</li>
</ol>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>整体架构图如下，标准的encoder-decoder架构，encoder和decoder均为多个相同层的堆叠，其中encoder6层、decoder6层，共12层。</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/image-20220314104109242.png" class="" title="image-20220314104109242">
<p>其他机制不再赘述，之前的<a href="https://fuhaifei.github.io/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/">博客</a>总结过，简单总结一下几个新理解</p>
<h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/image-20220314104956244.png" class="" title="image-20220314104956244">
<p><strong>为什么要Scale？</strong></p>
<blockquote>
<p>We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients[4]. To counteract this effect, we scale the dot products by $\frac{1}{\sqrt d_k}$</p>
</blockquote>
<p>在计算注意力分数时，QK向量相乘后，要除以输入向量维度的平方根，此论文中给出的解释，当输入维度 $d_k$ 较大时，QK向量会变得相对较大，导致softmax函数落在图像两边（如下图），导致梯度过小（梯度消失），通过除以$\sqrt d_k$ 避免此问题的出现</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/image-20220314105426864.png" class="" title="image-20220314105426864">
<p><strong>encoder-decoder attention 的输入是什么</strong></p>
<blockquote>
<p>the queries come from the previous decoder layer,and the memory keys and values come from the output of the encoder.</p>
</blockquote>
<p>query来自于decoder上一层的多头注意力机制输出，value和key来自于encoder的输出</p>
<p><strong>多头注意力机制为什么有用？</strong></p>
<p>类似于卷积神经网络中的通道的作用，不同的通道代表不同特征空间</p>
<h4 id="embedding"><a href="#embedding" class="headerlink" title="embedding"></a>embedding</h4><p><strong>为什么embedding层在+pos encoding前要乘以 $\sqrt d_k$?</strong></p>
<p>随着输入维度的增加，嵌入向量的每个位置的数字会变小（总和接近于一），而pos encoding的大小不变，为了保持嵌入向量和pos encoding的相对大小关系保持不变，乘以 $\sqrt d_k$。</p>
<h3 id="why-self-attention"><a href="#why-self-attention" class="headerlink" title="why self-attention?"></a>why self-attention?</h3><p>原文中通过对比自注意力机制、卷积层、循环神经网络的计算复杂度、顺序计算量(是否可并行计算)、最大序列特征捕捉计算次数三个指标，证明自注意力机制在计算量上的优势</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/image-20220314145009609.png" class="" title="image-20220314145009609">
<p>Complexity per Layer</p>
<ol>
<li>self-Attenion的主要计算量在 Q和V相乘，两个均为 $n<em>d$维度矩阵，相乘复杂度为 $O(n^2</em>d)$</li>
<li>rnn每个时间步是一个输入为d,输出为d的全连接网络，整个seq的计算量为$O(n*d^2)$</li>
<li>卷积层与rnn类似，假设一维卷积核大小为k，每个元素近似在卷积核中卷积k次，整个seq的计算量为$O(k<em>n</em>d^2)$</li>
<li>可见当n &lt; d时，self-Attention的复杂度小于RNN</li>
</ol>
<p>其他理解比较简单</p>
<h3 id="实验参数"><a href="#实验参数" class="headerlink" title="实验参数"></a>实验参数</h3><p><strong>词嵌入</strong></p>
<ol>
<li>WMT 2014 English-German 使用 <strong>byte pair encoding</strong> 做词典，共37000 个token</li>
<li>WMT 2014 English-French 使用 32000 <strong>word-piece vocabulary</strong></li>
</ol>
<p><strong>optimizer</strong></p>
<p>使用Adam作为模型优化器</p>
<ol>
<li><p>三个参数 $\beta_1=0.9,\beta_2=0.98,\epsilon=10^{-9}$</p>
</li>
<li><p>学习率如下，当训练步数小于warmup步数时，取 $step_num*warmup_steps^{-1.5}$,其中warmup取4000步</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/image-20220314150054771.png" class="" title="image-20220314150054771">
</li>
</ol>
<p><strong>dropout</strong></p>
<ol>
<li>每个子层在残差相加之前，增加dropout</li>
<li>pos encoding+embedding后增加dropout</li>
<li>base模型的dropout概率为 $P_{drop} = 0.1$</li>
</ol>
<p><strong>label smoothing</strong></p>
<p>训练时增加了标签平滑，参数值为 $\epsilon_{ls} = 0.1$ </p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%872-transformer/image-20220314150919745.png" class="" title="image-20220314150919745">]]></content>
      <categories>
        <category>读论文</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>读论文3-BERT</title>
    <url>/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%873-BERT/</url>
    <content><![CDATA[<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><blockquote>
<p>论文地址:<a href="https://arxiv.org/abs/1810.04805v2">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
</blockquote>
<p>提出了一个基于transformer的预训练模型，引领了在大规模数据上预训练深度模型，在下游任务上微调的风潮，其主要贡献在两点</p>
<ol>
<li>引领了预训练模型的风潮</li>
<li>特殊的训练机制，实现了”真”双向语言模型</li>
</ol>
<h3 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h3><p>明显该论文的工作是基于ELMo和GPT改进，内容组织也是围绕着 前人工作+自己改进+实验效果展开的</p>
<ol>
<li><p>摘要 Abstract</p>
<p>提了一下 GPT和ELMo,强调BERT是区别于两者的基于transformer的“真”双向模型，并列举实验效果</p>
</li>
<li><p>介绍 Intro</p>
<p>主要是围绕着直接解决的问题以及相对于前人解决方案的优越性进行阐述</p>
<ol>
<li>首先强调 sentence-level 和 token-level 两种不同类型任务，需要聚焦于不同level的模型</li>
<li>又介绍了目前两种主要的预训练应用手段，一是特征提取，用预训练模型做特征提取，输入到下游任务模型；二是微调，预训练模型在下游任务数据上继续训练，微调参数</li>
<li>然后列举GPT和ELMo主流预训练模型存在的问题： 局限于语言模型的特性，无法实现真”双向”</li>
<li>引出了自己通过MLM+“next sentence prediction”,实现真双向，同时解决sentence level和token level两个问题</li>
</ol>
<p><strong>自己提出问题，自己解决问题，自圆其说</strong></p>
</li>
</ol>
<span id="more"></span>
<ol>
<li><p>相关工作 Related Word</p>
<p>从三个方面介绍了预训练相关工作情况，主要还是为了增加自己工作的可信度</p>
</li>
<li><p>bert</p>
<ul>
<li>模型架构</li>
<li>输入</li>
<li>预训练的两个target</li>
</ul>
<p>没细讲模型结构，主要强调思路，把有些难懂的细节放在了附录</p>
</li>
<li><p>实验 Experiments</p>
<p>列举了包括GLUE、SQuAD、SWAG四个任务上的微调的效果，验证了bert模型在token-level、sentence-level不同类型任务上的有效性</p>
</li>
<li><p>对比试验 Ablation Studies</p>
<ol>
<li><p>通过控制变量实验验证MLM和NSP对于提升模型特征抽取能力是有效的</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%873-BERT/image-20220319143433975.png" class="" title="image-20220319143433975">
</li>
<li><p>不同模型深度对于模型效果的影响</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%873-BERT/image-20220319143540227.png" class="" title="image-20220319143540227">
</li>
<li><p>bert用于特征抽取时，下游任务的效果（CoNLL-2003 命名实体识别任务的实验）</p>
</li>
</ol>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%873-BERT/image-20220319143621944.png" class="" title="image-20220319143621944">
</li>
<li><p>结论</p>
<blockquote>
<p>Our major contribution is further generalizing these findings to deep bidirectional architectures, allowing the same pre-trained model to successfully tackle a broad set of NLP tasks</p>
</blockquote>
</li>
</ol>
<p>​        简单强调了一下自己的主要贡献，即探索了深度双向架构预训练模型在解决一系列NLP任务中的作用。</p>
<h3 id="MLM-amp-NSP"><a href="#MLM-amp-NSP" class="headerlink" title="MLM &amp; NSP"></a>MLM &amp; NSP</h3><p>bert通过设计MLM和NSP这两个预训练目标，使得bert既能解决token-level，又能解决sentence-level的一系列NLP任务。</p>
<h4 id="Masked-LM"><a href="#Masked-LM" class="headerlink" title="Masked LM"></a>Masked LM</h4><p>由于语言模型本身约束，为了避免当前词看到未来词，只能训练单向语言模型，或者将两个方向的单向模型拼接在一起近似双向，bert在与训练过程中，将一部分词替换掉，训练模型预测被替换的词</p>
<ol>
<li><p>替换掉序列中 15%的 WordPiece token(还得保证替换之后，预训练预料和finetuning语料分布差距不会过大)</p>
<ul>
<li>其中 80% 替换为 [mask]</li>
</ul>
</li>
</ol>
<ul>
<li><p>10% 替换为词表中的任意一个词</p>
<ul>
<li>10% 保持原词不变</li>
</ul>
<p>在附录中的对比实验中，通过语言模型和NER两个任务效果对比，确定了8:1:1的比率设置</p>
</li>
</ul>
<ol>
<li><p>使用替换位置的最后一层隐藏状态，预测原词</p>
<blockquote>
<p>will be used to predict the original token with cross entropy loss.</p>
</blockquote>
</li>
</ol>
<p>通过Mask LM任务，bert具备了双向特征提取能力（bidirectional）</p>
<h4 id="NSP"><a href="#NSP" class="headerlink" title="NSP"></a>NSP</h4><p>为了使得BERT能够具备建模sentence level的任务（例如 QA,自然语言推断），预训练过程中增加 Next Sentence Prediction任务</p>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%873-BERT/image-20220320190738243.png" class="" title="image-20220320190738243">
<ol>
<li>输入两个句子：A和B，其中 50% 训练数据 B为A的next（labeled as IsNext），50%训练数据 A和B随机抽取组合(labeled as NotNext），两句子拼接，中间使用特殊字符 [SEP]分隔</li>
<li>两个句子的<strong>token长度和小于512</strong></li>
<li>使用 <strong>[CLS]</strong> token最后一层输出做概率预测</li>
</ol>
<blockquote>
<p>The training loss is the sum of the mean masked LM likelihood and the mean next sentence prediction likelihood.</p>
</blockquote>
<p>在预训练过程中，两个任务并行训练，训练损失为 <strong>平均mask概率 + 平均NSP概率</strong> 损失</p>
<h3 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h3><p>BERT预训练输入词向量包括三个不同Embeddings求和，三种Embeddings层均在训练中得到</p>
<ol>
<li>Token Embeddings 词嵌入，首先经过WordPieces模型分词后，在预训练模型中训练词嵌入</li>
<li>Segment Embeddings 段嵌入，与NSP任务相关，区分两个句子中的token，在预训练模型中训练得到</li>
<li>Position Embeddings 位置嵌入，也采用了 训练得到，<strong>未使用transformer中的正弦周期函数</strong></li>
</ol>
<img src="/2022/03/20/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%873-BERT/image-20220320192229816.png" class="" title="image-20220320192229816">
<h3 id="模型训练参数"><a href="#模型训练参数" class="headerlink" title="模型训练参数"></a>模型训练参数</h3><ol>
<li><strong>batch size=256</strong>, 每个batch的<strong>seq_length最长为512</strong>，训练了 <strong>40 epochs</strong>,大约1000000步</li>
<li>Adam优化器，lr= $1e^{-4}$ ,$\beta_1=0.9$, $\beta_2 = 0.999$ , weight decay $0.01$ ,dropout = 0.1</li>
<li>学习率随着训练epoch线性下降</li>
<li>使用 gelu实现替代了transformer中的relu函数</li>
</ol>
<p><strong>特殊的训练trick</strong></p>
<p>由于训练数据token长度分布大部分长度为128，为了加快收敛速度，在与训练过程中分为两阶段</p>
<ol>
<li>首先使用 <strong>128作为每个batch的seq_length</strong> 训练90%的step</li>
<li>再使用 <strong>seq_length=256</strong> 训练10%的step，用来学习position embedding（没太理解这么做的原因）</li>
</ol>
]]></content>
      <categories>
        <category>读论文</category>
      </categories>
      <tags>
        <tag>bert</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML-1.学什么</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-1.%E5%AD%A6%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<h3 id="学什么"><a href="#学什么" class="headerlink" title="学什么"></a>学什么</h3><iframe src="//player.bilibili.com/player.html?aid=675507034&bvid=BV13U4y1N7Uo&cid=409501228&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>主要是从机器学习的工作流出发，每个阶段主要的工作和工业界流行的技术和概念</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-1.%E5%AD%A6%E4%BB%80%E4%B9%88/image-20220224095954652.png" class="" title="image-20220224095954652">
<p>主要包括四个学习模块：</p>
<ol>
<li><strong>数据</strong> 数据获取、存储、清洗</li>
<li><strong>模型</strong> 训练、迁移、多模态</li>
<li><strong>部署</strong></li>
<li><strong>监控</strong> 可视化</li>
</ol>
<h3 id="学习计划"><a href="#学习计划" class="headerlink" title="学习计划"></a>学习计划</h3><p>基本学习计划：</p>
<ol>
<li>数据模块<ul>
<li>一天一个视频，慢慢学</li>
</ul>
</li>
<li>模型模块<ul>
<li>机器学习、深度学习模块部分，快速过一遍</li>
<li>模型验证，调优部分慢慢学，基础较差</li>
</ul>
</li>
<li>部署 + 监控部分<ul>
<li>慢慢学</li>
</ul>
</li>
</ol>
<p>大概一共30多个视频，三周内学完（无意外的情况下），<strong>deadline 3-15</strong></p>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML-5.偏差与方差</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/</url>
    <content><![CDATA[<h2 id="Bias-amp-Variance"><a href="#Bias-amp-Variance" class="headerlink" title="Bias &amp; Variance"></a>Bias &amp; Variance</h2><p><strong>bias(偏差)</strong>：模型对于样本的拟合程度，模型输出结果与样本真实结果之间的差距，通过增加模型复杂程度，增加训练轮数，可以实现bias的降低，但可能会出现过拟合问题（high variance）</p>
<p><strong>variance(方差)</strong>：模型预测结果的稳定性，通过简化模型，可以实现variance的降低 计算公式为 $E[(\hat y - E(\hat y)) ^ 2]$</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/image-20220301152126220.png" class="" title="image-20220301152126220">
<span id="more"></span>
<h3 id="公式角度分析Bias-与-Variance"><a href="#公式角度分析Bias-与-Variance" class="headerlink" title="公式角度分析Bias 与 Variance"></a>公式角度分析Bias 与 Variance</h3><ul>
<li><p>以MSE误差为例，计算bias和variance</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/image-20220301153351002.png" class="" title="image-20220301153351002">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/image-20220301153447334.png" class="" title="image-20220301153447334">
<ul>
<li><p>在样本上求误差均值，首先将f展开为    <script type="math/tex">y = f +\epsilon</script> </p>
</li>
<li><p>再在平方项内添加一个 y_hat期望 <script type="math/tex">E[\hat y]</script></p>
</li>
<li><p>由于 随机误差 $\epsilon$ 均值为0，方差为 $\sigma ^ 2$</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/image-20220301154214532.png" class="" title="image-20220301154214532">
</li>
<li><p>最终得到 Bias + Variance +  $\sigma ^ 2$ 的形式</p>
</li>
</ul>
</li>
</ul>
<h3 id="偏差与方差之间的关系"><a href="#偏差与方差之间的关系" class="headerlink" title="偏差与方差之间的关系"></a>偏差与方差之间的关系</h3><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/image-20220301154635423.png" class="" title="image-20220301154635423">
<h3 id="如何降低偏差和方差"><a href="#如何降低偏差和方差" class="headerlink" title="如何降低偏差和方差"></a>如何降低偏差和方差</h3><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML-5.%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE/image-20220301155342109.png" class="" title="image-20220301155342109">
<ul>
<li><strong>集成学习</strong>可以同时降低两个误差</li>
</ul>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_2.数据获取</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_2.%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96/</url>
    <content><![CDATA[<h2 id="机器学习-数据"><a href="#机器学习-数据" class="headerlink" title="机器学习-数据"></a>机器学习-数据</h2><p>当使用机器学习技术解决实际问题时，最先要考虑模型输入数据问题，如何获取数据，对数据进行标注、清理以及变换等，以满足模型的输入要求。</p>
<h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><p>主要有两个获取手段</p>
<ol>
<li>寻找已有的数据集（MNIST ImageNet等等）<ul>
<li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">维基百科数据集总结</a></li>
<li><a href="https://paperswithcode.com/datasets">paperwithcode datasets</a> 论文中常见的数据集</li>
<li><a href="https://www.kaggle.com/datasets">Kaggle Datasets</a> 用户上传数据集</li>
<li><a href="https://datasetsearch.research.google.com/">Google Dataset search</a> 数据集搜索引擎，聚合数据集网站内容</li>
<li><a href="https://huggingface.co/datasets">Hugging Face 数据集</a> 聚焦于文本数据</li>
</ul>
</li>
<li>根据任务，收集，形成自己的数据集</li>
<li>生成数据</li>
</ol>
<span id="more"></span>
<p>三种不同的数据集类型</p>
<ol>
<li>学术数据集<ul>
<li>定义清晰，但是局限于某个小问题</li>
</ul>
</li>
<li>竞赛数据集<ul>
<li>接近于真实的机器学习应用</li>
</ul>
</li>
<li>原始数据<ul>
<li>需要消耗大量的精力预处理</li>
</ul>
</li>
</ol>
<p>当收集到的数据来源不同，我们需要对数据进行集成（integrate）</p>
<ul>
<li><p>类似于数据库中不同表的join，寻找合并key，处理重复项、冲突以及确实</p>

</li>
</ul>
<p>当找不到可用的数据，或者收集到的数据量过小时，可通过<strong>人造(synthetic)数据</strong>增加数据量</p>
<ol>
<li>使用GANs  生成数据</li>
<li>数据增强（augmentation） <ul>
<li>图像反转、拉伸等</li>
<li>文本的反复翻译，改变语序</li>
</ul>
</li>
</ol>
<p><strong>总结</strong></p>

<h3 id="网页数据抓取（Scraping）"><a href="#网页数据抓取（Scraping）" class="headerlink" title="网页数据抓取（Scraping）"></a>网页数据抓取（Scraping）</h3><p> 网页数据抓取是获取数据的有效手段，包括ImageNet在内的很多数据集通过这种方式获取生成，其优缺点包括</p>
<ol>
<li>数据较为原始，包含的无关信息较多</li>
<li>数据量大</li>
</ol>

<p>常用的网页抓取工具</p>
<ol>
<li><p>linux的curl命令（通常会被反爬虫屏蔽）</p>
</li>
<li><p>使用模拟浏览器</p>
</li>
<li>不断更换ip，防止短时间大量相同ip访问导致的屏蔽</li>
</ol>
<h3 id="数据标注"><a href="#数据标注" class="headerlink" title="数据标注"></a>数据标注</h3><p>在完成数据收集后，需要考虑数据的标注问题，根据标签的多少，选取不同的策略</p>
<ol>
<li>标签充足-监督/半监督学习</li>
<li>标签不足-人工标注</li>
<li>标签+经费均不足-弱监督学习</li>
</ol>

<h4 id="半监督学习（Semi-supervised-learning-SSL）-简单理解"><a href="#半监督学习（Semi-supervised-learning-SSL）-简单理解" class="headerlink" title="半监督学习（Semi-supervised learning SSL）- 简单理解"></a>半监督学习（Semi-supervised learning SSL）- 简单理解</h4><blockquote>
<p>Semi-supervised learning is a class of machine learning tasks and techniques that also make use of unlabeled data for training – typically a small amount of labeled data with a large amount of unlabeled data.</p>
<p>李宏毅机器学习视频中有<a href="https://www.bilibili.com/video/BV1JE411g7XF?p=64">详细讲解</a></p>
</blockquote>
<p>半监督训练主要针对训练数据只有少部分已标注，大部分均未标注的情况，假设训练数据满足以下条件</p>
<ol>
<li>一致性假设(Continuity assumption) 具有相同特征的样本标签相同</li>
<li>聚类/簇假设(Cluster assumption) 若数据存在簇结构（即可以聚类），一个簇具有一个标签</li>
<li>流形假设(manifold assumption)  高维数据大致会分布在一个低维的流形上,邻近的样本拥有相似的输出,邻近的程度常用“相似”程度来刻画</li>
</ol>
<p><strong>半监督算法之一：自学习</strong></p>
<p>首先用带标签的数据训练一个模型，在未标注数据上进行预测，获得预测标签，也就是所谓的伪标签（Pseudo-labeled），根据置信度选择部分伪标签数据与标签数据合并训练一个新模型（自学习），不断循环训练，直到模型满足任务要求。</p>

<p><strong>半监督学习算法之二：主动学习（active learning）</strong></p>
<p>与自学训练过程类似，但是每次预测结果<strong>最典型的</strong>未标记样本，由人工标记</p>
<ul>
<li>uncertainty sampling 选取最不确定的样本作为最典型（概率为1/N）</li>
</ul>

<h4 id="Label-through-Crowdsourcing-众包"><a href="#Label-through-Crowdsourcing-众包" class="headerlink" title="Label through Crowdsourcing(众包)"></a>Label through Crowdsourcing(众包)</h4><p>花钱找人标注</p>

<h4 id="弱监督学习（Weak-Supervision）"><a href="#弱监督学习（Weak-Supervision）" class="headerlink" title="弱监督学习（Weak Supervision）"></a>弱监督学习（Weak Supervision）</h4><p>半自动生成标号，虽然比人工标注差，但是足够训练使用，常用手段 </p>
<p><strong>Data programming</strong></p>
<p>人工总结一些规律，设计一些规则（规则匹配），通过程序半自动生成标签</p>


<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4>]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_3.提升数据质量</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/</url>
    <content><![CDATA[<h2 id="提升数据质量"><a href="#提升数据质量" class="headerlink" title="提升数据质量"></a>提升数据质量</h2><p>在数据收集完成后，数据可能还存在大量的噪声、或者模型难以使用，需要我们进一步处理提高数据质量</p>
<ol>
<li>数据噪声较多（脏数据过多） - 数据清洗</li>
<li>数据格式与模型要求输入不符 - 数据变换</li>
<li>数据难学习                                - 特征工程</li>
</ol>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>针对数据噪声较多的问题，通过数据清洗改善数据质量，常见的Data Error由</p>
<ol>
<li>Outliers(离群值) 某些数据值远远偏离数据整体分布</li>
<li>Rule violations(违反约束) 例如某些非空字段为空</li>
<li>Pattern violation（语义语法冲突）单位是美元，数据给rmb；数据项目标类型是float，实际类型是string</li>
</ol>
<span id="more"></span>
<h4 id="离群检测-Outlier-Detection"><a href="#离群检测-Outlier-Detection" class="headerlink" title="离群检测(Outlier Detection)"></a>离群检测(Outlier Detection)</h4><h4 id="基于规则检测（Rule-based-Detection）"><a href="#基于规则检测（Rule-based-Detection）" class="headerlink" title="基于规则检测（Rule-based Detection）"></a>基于规则检测（Rule-based Detection）</h4><h4 id="基于模式检测（Pattern-based-Detection）"><a href="#基于模式检测（Pattern-based-Detection）" class="headerlink" title="基于模式检测（Pattern-based Detection）"></a>基于模式检测（Pattern-based Detection）</h4><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228150552932.png" class="" title="image-20220228150552932">
<h3 id="数据变换（Data-Transformation）"><a href="#数据变换（Data-Transformation）" class="headerlink" title="数据变换（Data Transformation）"></a>数据变换（Data Transformation）</h3><p>实值规范化（Normalization）</p>
<ol>
<li>归一化</li>
<li>Z-score</li>
<li>十进制放缩</li>
<li>log放缩</li>
</ol>
<p>图片转换（减少图片的空间占用）</p>
<ol>
<li>下采样、裁切</li>
<li>图像白化处理（Whitening） 减少像素量</li>
</ol>
<p>视频转换 （预处理以平衡 存储，质量和加载速度 三者之间的关系）</p>
<ul>
<li>通常使用 短视频裁切（&lt;10sec），每个切片内包含单个时间</li>
</ul>
<p>文本转换</p>
<ol>
<li>Stemming and lemmatization 还原词形</li>
<li>Tokenization 切词</li>
</ol>
<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228155016025.png" class="" title="image-20220228155016025">
<p>如何表示特征值？</p>
<ol>
<li><p>直接使用数值表示 或者 桶划分</p>
</li>
<li><p>类别特征可采用独热向量（one-hot）</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228155854227.png" class="" title="image-20220228155854227">
</li>
<li><p>日期 按照复合特征处理，划分为子特征</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228155800660.png" class="" title="image-20220228155800660">
</li>
<li><p>将几个单独特征组合形成新特征</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228160046548.png" class="" title="image-20220228160046548">
</li>
</ol>
<p><strong>文本数据</strong> 特征表示</p>
<ol>
<li><p>one hot 或者 word embedding</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228160535728.png" class="" title="image-20220228160535728">
</li>
<li><p>预训练模型做特征提取（上下文语义嵌入 context embedding）</p>
</li>
</ol>
<p><strong>图片/视频</strong> 特征表示</p>
<ol>
<li>传统的手工特征抽取，例如SIFT</li>
<li>深度神经网络特征提取（ResNet）,类似于提取文本特征的预训练网络</li>
</ol>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_3.%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/image-20220228161500068.png" class="" title="image-20220228161500068">]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_4.模型验证</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_4.%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<h2 id="模型验证（Validation）"><a href="#模型验证（Validation）" class="headerlink" title="模型验证（Validation）"></a>模型验证（Validation）</h2><h3 id="验证（validation）集与测试（test）集"><a href="#验证（validation）集与测试（test）集" class="headerlink" title="验证（validation）集与测试（test）集"></a>验证（validation）集与测试（test）集</h3><p>验证集往往是从训练集中划分出的一部分数据，用来验证模型泛化能力，可以使用多次；测试集是单独的一系列数据，在模型训练完成后，衡量模型效果，一般只使用一次</p>
<h3 id="如何生成验证集"><a href="#如何生成验证集" class="headerlink" title="如何生成验证集"></a>如何生成验证集</h3><h4 id="随机划分"><a href="#随机划分" class="headerlink" title="随机划分"></a>随机划分</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_4.%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/image-20220301142501284.png" class="" title="image-20220301142501284">
<h4 id="特殊情况"><a href="#特殊情况" class="headerlink" title="特殊情况"></a>特殊情况</h4><p>某些情况下，训练数据可能不适合采用随机划分的方式验证集合，如</p>
<ol>
<li>具有序列关系的数据-股价、房子销售<ul>
<li>验证集数据应在训练集后，避免模型训练使用到了验证集的未来信息，导致模型在验证集上的表现较好</li>
</ul>
</li>
<li>训练数据由不同组，每个组有多个样本-同一个人的多个照片<ul>
<li>以组为单位进行随即划分</li>
<li>一百组照片，选70个人训练，30个人验证</li>
</ul>
</li>
<li>类别不均衡数据<ul>
<li>对于较小类更多的采样</li>
</ul>
</li>
</ol>
<span id="more"></span>
<h4 id="K-fold-Cross-Validation-k折交叉验证"><a href="#K-fold-Cross-Validation-k折交叉验证" class="headerlink" title="K-fold Cross Validation k折交叉验证"></a>K-fold Cross Validation k折交叉验证</h4><p>将数据集划分为k个子集，每次选取一个子集作为有验证集，其余k个集合合并为训练集，重复k次，用k次平均验证误差作为验证集误差。</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_4.%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81/image-20220301144205630.png" class="" title="image-20220301144205630">
<h3 id="有关验证集的常见错误（common-mistakes）"><a href="#有关验证集的常见错误（common-mistakes）" class="headerlink" title="有关验证集的常见错误（common mistakes）"></a>有关验证集的常见错误（common mistakes）</h3><ol>
<li>验证集中有来自训练集的样本<ul>
<li>数据集中有重复样本</li>
</ul>
</li>
<li>数据泄露（leaking）<ul>
<li>训练时用到了验证集未来的数据（时间序列分析）</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_6.集成学习</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="集成学习（Ensemble-Learning）"><a href="#集成学习（Ensemble-Learning）" class="headerlink" title="集成学习（Ensemble Learning）"></a>集成学习（Ensemble Learning）</h2><blockquote>
<p>In <a href="https://en.wikipedia.org/wiki/Statistics">statistics</a> and <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>, <strong>ensemble methods</strong> use multiple learning algorithms to obtain better <a href="https://en.wikipedia.org/wiki/Predictive_inference">predictive performance</a> than could be obtained from any of the constituent learning algorithms alone.</p>
</blockquote>
<h3 id="Bagging-Bootstrap-Aggregating"><a href="#Bagging-Bootstrap-Aggregating" class="headerlink" title="Bagging-Bootstrap Aggregating"></a>Bagging-Bootstrap Aggregating</h3><p>Bagging主要思路是通过结合几个模型(<strong>多个相同模型</strong>)降低总体的泛化误差（bias+viariance），实际上降低的是<strong>方差</strong></p>
<ol>
<li>同时训练多个模型（parallel）</li>
<li>输出取模型平均值（回归模型）或投票（分类模型）</li>
</ol>
<p>其中每个模型训练数据通过bootstrap sampling方式采样</p>
<ol>
<li>有放回采样，m个训练数据，进行m次又放回采样</li>
<li>大概有 $1- \frac{1}e$ 63%的数据在一次bootstrap采样中未被采样到（out of bag），可以作为模型的验证集</li>
</ol>
<span id="more"></span>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220302112353956.png" class="" title="image-20220302112353956">
<h4 id="Random-Forest-特殊的bagging"><a href="#Random-Forest-特殊的bagging" class="headerlink" title="Random Forest-特殊的bagging"></a>Random Forest-特殊的bagging</h4><ul>
<li>基学习器为决策树</li>
<li>bootstrap采样过程中，不仅对样本进行随机采样，同样对属性列进行采样，增加决策树的多样性</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220302112534348.png" class="" title="image-20220302112534348">
<h4 id="Unstable-Learners"><a href="#Unstable-Learners" class="headerlink" title="Unstable Learners"></a>Unstable Learners</h4><p>对于不稳定（方差较大）模型效果提升较好</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303083634112.png" class="" title="image-20220303083634112">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303083728465.png" class="" title="image-20220303083728465">
<ul>
<li>当 $h(x)$ 即模型预测值，方差较小，上述不等式趋向于等号</li>
<li>极端情况，当 $h(x)$ 恒相等时， $E(h(x))^2 = E(h(x)^2)$ , 使用bagging对模型效果没有提升</li>
<li>由上公式易得，bagging能够通过较少viarance，降低模型泛化误差，模型方差越大，提升效果越好</li>
</ul>
<p>决策树就是一种 unstable learner,而线性回归是稳定的</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303084813664.png" class="" title="image-20220303084813664">
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303084859931.png" class="" title="image-20220303084859931">
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>将一系列的弱模型(<strong>多个相同模型</strong>)结合组成一个强模型，以降低模型的偏差（bias）</p>
<ul>
<li>按照顺序学习n个弱模型，每次模型训练完成后，根据该模型预测错误部分对数据重新采样，训练下一个模型</li>
<li>不断的迭代，“在bias上不断地boosting”</li>
</ul>
<h4 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h4><p>每次模型训练目标为拟合残差（有点类似于梯度拟合）</p>
<ol>
<li>训练新模型 $h_t$ 时，其<strong>训练目标</strong>为 <strong>预测真实值$y_i$</strong> 与 <strong>已训练模型预测值和 $H_{t}(x_i)$</strong>的差</li>
<li>累积得到新的预测值和 $H_{t+1}(x) = H{t}(x) + \eta h_t(x)$, 其中 $\eta$ 为正则项系数，为了避免模型过度拟合</li>
</ol>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303090038631.png" class="" title="image-20220303090038631">
<p>当损失函数为MSE，即均方误差损失时，实际上残差即为负梯度，Gradient 名字的由来</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303091042627.png" class="" title="image-20220303091042627">
<h4 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting  Decision Tree(GBDT)"></a>Gradient Boosting  Decision Tree(GBDT)</h4><p>使用决策树作为弱学习模型，问题就是构建、训练时间较长</p>
<ul>
<li>使用强模型，Gradient Boosting容易出现过拟合现象</li>
<li>通过限制决策树的层数（2-3）层，控制过拟合</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303091517929.png" class="" title="image-20220303091517929">
<p>Boosting VS 随机森林</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303091554319.png" class="" title="image-20220303091554319">
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>降低 <strong>偏差 偏差 偏差 ！！！</strong></p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303091702515.png" class="" title="image-20220303091702515">
<h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p>类似于bagging,将不同的基模型连接起来，共同预测结果以降低方差（variance）</p>
<ul>
<li><p>基模型可以是不同的类别</p>
</li>
<li><p>最后由一个线性全连接层，输入各个模型的输出，输出目标结果</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303092746542.png" class="" title="image-20220303092746542">
</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303092311096.png" class="" title="image-20220303092311096">
<h4 id="Multi-layer-Stacking"><a href="#Multi-layer-Stacking" class="headerlink" title="Multi-layer Stacking"></a>Multi-layer Stacking</h4><p>多层堆叠模型，降低模型偏差（bias）</p>
<ul>
<li>容易过拟合</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303094206264.png" class="" title="image-20220303094206264">
<p>如何降低过拟合问题</p>
<ol>
<li>将数据划分A和B两部分，其中A部分用来训练第一层，并用第一层预测B，预测结果作为第二层输入训练第二层（避免了原来多层堆叠出现的一个在不同层重复训练的情况）</li>
<li>重复 k-fold bagging <ul>
<li>使用k-fold训练k个模型（在多层堆叠中特指<strong>第一层的所有模型</strong>）</li>
<li>将每个模型在k-fold训练中作为验证集部分数据的输出拼接成一个份完整的第一层输出，输入到第二层训练</li>
<li><strong>进一步降低方差</strong>：重复n次k折交叉验证,每个数据均有n个输出，对n个输出做平均，获得一个完整的第一层输出，输入到第二层训练</li>
</ul>
</li>
</ol>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303095451723.png" class="" title="image-20220303095451723">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303095533009.png" class="" title="image-20220303095533009">
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303095827469.png" class="" title="image-20220303095827469">
<h3 id="集成学习总结"><a href="#集成学习总结" class="headerlink" title="集成学习总结"></a>集成学习总结</h3><p>简单理解就是</p>
<ul>
<li>增加模型数量，学习相同内容,可以降低 Variance</li>
<li>增加模型，不断学习误差，可以降低Bias</li>
<li>K-fold multi-level stacking 通过横向增加模型数量，纵向增加层数，可以既降低Bias，又降低 Variance</li>
<li>由于多个模型容易出现过拟合现象<ul>
<li>多模型降低Variance，通过 特殊采样方法（bagging的bootstrap，staking的k-fold）避免过拟合</li>
<li>降低Bias,通过 正则项 避免过拟合</li>
</ul>
</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_6.%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/image-20220303100132120.png" class="" title="image-20220303100132120">
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_7.模型调参</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/</url>
    <content><![CDATA[<h2 id="模型调参（Tuning）"><a href="#模型调参（Tuning）" class="headerlink" title="模型调参（Tuning）"></a>模型调参（Tuning）</h2><p>模型参数对模型效果有影响较大， 在不同的问题中，我们不仅需要选择合适的模型，也要选择合适的参数</p>
<ol>
<li><p>手动调参（Manual）</p>
<ul>
<li><p>从默认参数（工具包默认参数、论文推荐参数）开始</p>
</li>
<li><p>不断调整参数，记录调整后的结果（tensorboard, weight &amp; bias）</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220303145559540.png" class="" title="image-20220303145559540">
</li>
</ul>
</li>
<li><p>自动调参（Automated）</p>
<ul>
<li><p>计算成本在下降，人力成本在上升</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220303145731538.png" class="" title="image-20220303145731538">
</li>
</ul>
</li>
<li><p>AutoML(Automated Machine Learning)</p>
<ul>
<li>从数据清洗、特征提取到模型选择每一步均由AutoML自动完成</li>
<li>目前模型选择之前的步骤，AutoML完成效果并不好，主要能够解决的两个问题<ol>
<li>HPO（Hyperparameter optimization）选择合适的超参数</li>
<li>NAS（Neural architecture search）网络架构搜索</li>
</ol>
</li>
</ul>
</li>
</ol>
<span id="more"></span>
<h3 id="HOP-Algorithm-超参数选择"><a href="#HOP-Algorithm-超参数选择" class="headerlink" title="HOP Algorithm 超参数选择"></a>HOP Algorithm 超参数选择</h3><p>首先确定参数的搜索空间，例如</p>
<ul>
<li>避免超参数空间过大，导致搜索成本过高</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304082552518.png" class="" title="image-20220304082552518">
<p>在搜索空间上采取特定的搜索算法进行搜索，主要分为两大类别</p>
<ol>
<li>Black-box 每个参数集选择进行一次完整的训练，训练完成后比较不同参数集模型效果</li>
<li>Multi-fidelity 修改训练过程，降低搜索代价<ul>
<li>在训练数据子集上训练</li>
<li>减小模型大小（减少层数，减少channel等）</li>
<li>提前终止某些效果明显较差的参数实验</li>
</ul>
</li>
</ol>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304083338601.png" class="" title="image-20220304083338601">
<h4 id="两类常见的HPO算法"><a href="#两类常见的HPO算法" class="headerlink" title="两类常见的HPO算法"></a>两类常见的HPO算法</h4><ol>
<li><p>Grid Search 网格搜索</p>
<ul>
<li>传入不同参数的多个值，搜索所有参数不同值的所有组合</li>
<li>获得 最优的参数值组合</li>
<li>随着参数数量的增加，组合数量呈指数级上升，训练成本较高</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304083750975.png" class="" title="image-20220304083750975">
</li>
<li><p>Random Search</p>
<ul>
<li>与Grid Search类似，但是只随机选择n次参数组合</li>
<li>只搜索一部分参数组合空间，一定程度减少了训练成本</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304083937025.png" class="" title="image-20220304083937025">
</li>
</ol>
<h4 id="Bayesian-Optimization-BO-贝叶斯优化-不深入理解"><a href="#Bayesian-Optimization-BO-贝叶斯优化-不深入理解" class="headerlink" title="Bayesian Optimization(BO) 贝叶斯优化-不深入理解"></a>Bayesian Optimization(BO) 贝叶斯优化-不深入理解</h4><p>通过不断地对数据进行采样（超参数与模型评价指标的对应关系）学习一个从<strong>超参数</strong>到<strong>模型评价指标</strong>（用该超参数训练出来的模型的评价指标）之间的函数，每次采样会根据以往的采样结果，选取采样点(online learning的感觉)。</p>
<p><strong>Surrogate model</strong></p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304090035219.png" class="" title="image-20220304090035219">
<p><strong>Acquisition function</strong></p>
<ul>
<li>每次新采样点选取 <strong>Acquisition max</strong>，即时Acquisition function最大的点</li>
<li><strong>Acquisition max</strong>的样本点 <strong>约等于</strong> <strong>置信区间较大 + 可能取得较高评价指标</strong>的点（<strong>简单理解</strong>：置信区间小我就没必要再采样了，直接使用模型预测超参数；较高指标的超参数是模型追求的目标，总结就是 <strong>既要增加可信度又要找到最优解</strong>）</li>
<li>Trade off exploration and exploitation 在 <strong>探索未知解</strong> 和 <strong>最优解附近深挖</strong> 的权衡</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304090743169.png" class="" title="image-20220304090743169">
<p><strong>BO算法的局限性</strong></p>
<ul>
<li>算法的最初始阶段，近似于随机搜索</li>
</ul>
<h4 id="Successive-Halving"><a href="#Successive-Halving" class="headerlink" title="Successive Halving"></a>Successive Halving</h4><p>算法如其名，比较简单</p>
<ol>
<li>随机选择n个超参数组合，训练m轮</li>
<li>每m轮训练完毕，删除 n/2 个指标相对较差的超参数组合</li>
<li>不断重复第二步，直到只剩下一个超参数组合</li>
</ol>
<p>根据具体的预算，选取n和m</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304092244412.png" class="" title="image-20220304092244412">
<h4 id="Hyperband-实际使用比较多的算法"><a href="#Hyperband-实际使用比较多的算法" class="headerlink" title="Hyperband-实际使用比较多的算法"></a>Hyperband-实际使用比较多的算法</h4><p>在Successive Halving算法中，n和m的选取很大程度上会影响最后获得最优超参数组合</p>
<ul>
<li>资源固定的情况下，<strong>m*n = budget</strong> </li>
<li>当m选取不够大时，有些超参数组合可能在前m个epoch指标表现不好（训练不充分），导致提前被淘汰</li>
<li>当n选取不够大时，随机采样的超参数组合可能过少，无法找到最优解</li>
</ul>
<p>Hyperband算法针对Successive Halving算法的以上问题，进行了针对性改进</p>
<ol>
<li>运行多次 Successive Halving算法，每次运行降低n，增加m</li>
<li>先 exploration  再 exploitation,先 BFS 再 DFS</li>
<li>单次成本不变，多次运行，最后还是增加计算成本</li>
</ol>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304093734300.png" class="" title="image-20220304093734300">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304093845224.png" class="" title="image-20220304093845224">
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304094115462.png" class="" title="image-20220304094115462">
<h3 id="Neural-Architecture-Search-NAS-Algorithm"><a href="#Neural-Architecture-Search-NAS-Algorithm" class="headerlink" title="Neural Architecture Search(NAS) Algorithm"></a>Neural Architecture Search(NAS) Algorithm</h3><p>超参数选择中，除了学习率、epoch、batchsize等的训练超参数，还包括模型层数、隐藏层维度等的涉及到模型结构的参数</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304110012929.png" class="" title="image-20220304110012929">
<p>NAS算法用来解决模型结构相关参数的选择</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304110121568.png" class="" title="image-20220304110121568">
<h4 id="NAS-with-Reinforcement-Learning"><a href="#NAS-with-Reinforcement-Learning" class="headerlink" title="NAS with  Reinforcement Learning"></a>NAS with  Reinforcement Learning</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304110328974.png" class="" title="image-20220304110328974">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304110853192.png" class="" title="image-20220304110853192">
<h4 id="The-One-shot-Approach（思想）"><a href="#The-One-shot-Approach（思想）" class="headerlink" title="The One-shot Approach（思想）"></a>The One-shot Approach（思想）</h4><ul>
<li><p>将网络架构与模型参数的学习连接在一起（既学网络架构，又学网络参数）</p>
</li>
<li><p>训练一个大模型，其子模型为各种各样的备选架构（先搞大杂烩，再从大杂烩里挑我要的）</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304111150887.png" class="" title="image-20220304111150887">
</li>
<li><p>问题在于 大模型资源耗费过大，如何解决？</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304111204080.png" class="" title="image-20220304111204080">
</li>
</ul>
<p><strong>Differentiable Architecture Search</strong></p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304144329266.png" class="" title="image-20220304144329266">
<ul>
<li><p>每一层有多个候选网络/结构/模型</p>
</li>
<li><p>第l层的第i个候选网络的输出为 $0_i^l$</p>
</li>
<li><p>每一层后 select模块，权重为 $a^l$ ，对该层所有候选模型输出加权求和输入到 $l + 1 $ 层</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304144536920.png" class="" title="image-20220304144536920">
</li>
<li><p>最后选择每层中 参数最大的 候选模型</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304144709664.png" class="" title="image-20220304144709664">
</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304143711492.png" class="" title="image-20220304143711492">
<h4 id="Scaling-CNNs"><a href="#Scaling-CNNs" class="headerlink" title="Scaling CNNs"></a>Scaling CNNs</h4><p>对于卷积神经网络，有三种调整架构的方式</p>
<ul>
<li>更深：增加层数</li>
<li>更宽：增加channel</li>
<li>更大的输入：提高输入图像分辨率</li>
</ul>
<p>EfficientNet 提出了一种Scaling方式（调整一个，其他两个同时一起调节）</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304145127431.png" class="" title="image-20220304145127431">
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_7.%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/image-20220304145828105.png" class="" title="image-20220304145828105">]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_8.深度神经网络</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h2 id="深度学习模型设计模式"><a href="#深度学习模型设计模式" class="headerlink" title="深度学习模型设计模式"></a>深度学习模型设计模式</h2><p>随着深度学习的不断发展，各式各样包括bert、transformer在内的深度神经网络架构层出不穷，在这些不同的网络架构中往往包含一些通用的深度网络设计模式，主要理解三种：</p>
<ol>
<li>batch/layer normalization</li>
<li>残差</li>
<li>注意力机制</li>
</ol>
<h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><p>对输入的一个batch进行标准化处理（减均值，除以方差），能够有效的降低深度网络的学习难度</p>
<ul>
<li>l从梯度角度理解，当从x-&gt;y的梯度变化 $\beta$ 变化较大时，梯度下降时沿着x点梯度移动，学习会出现偏差(斜率替代每个点的导数，如果导数变化过大，沿着斜率走就会偏离函数图像)</li>
<li>对于分布变化较大的数据要采用较小的学习率，否则就需要通过Batch Normalization对输入进行平滑化（smooth）</li>
<li>只对线性方法起作用，深度神经不起作用</li>
</ul>
<span id="more"></span>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307084121951.png" class="" title="image-20220307084121951">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307084716730.png" class="" title="image-20220307084716730">
<p>批量归一化的主要步骤：</p>
<ol>
<li><p>首先将输入转化为2D形式数据</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307084939777.png" class="" title="image-20220307084939777">
</li>
<li><p>标准化</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307084955220.png" class="" title="image-20220307084955220">
</li>
<li><p>还原</p>
<ul>
<li>$\beta_j $ $\gamma_j$两个参数神经网络学习决定</li>
<li>形式上理解为 由模型通过学习决定是否真的需要normalization</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307085101509.png" class="" title="image-20220307085101509">
</li>
<li><p>转换为输入形状，输出</p>
</li>
</ol>
<p>实现代码如下</p>
<ol>
<li><p>训练过程中 并不保留所有batch的均值和方差平均值 供预测使用</p>
</li>
<li><p>每次使用动量更新一个新的moving_var,moving_mean在预测中使用</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307090421825.png" class="" title="image-20220307090421825">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307090430766.png" class="" title="image-20220307090430766">
</li>
</ol>
<p>完整代码：</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307090218611.png" class="" title="image-20220307090218611">
<h4 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h4><blockquote>
<p>BN在batch上做归一化，LN在样本上做归一化</p>
</blockquote>
<p>由于RNN循环计算特性，不同时间步类似于不同的batch，均值和方差变化较大，无法共享使用（若输入长度为10，需要维护10个不同时间步的均值和方差，当预测长度为20时，后10个时间步在训练过程中没有均值和方差）</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307091707388.png" class="" title="image-20220307091707388">
<p>相较于Batch Normalization，将时间步看作为batch维度，reshape维度改变，其他操作不同</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307091911670.png" class="" title="image-20220307091911670">
<h4 id="More-Normalization"><a href="#More-Normalization" class="headerlink" title="More Normalization"></a>More Normalization</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_8.%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/image-20220307092724701.png" class="" title="image-20220307092724701">
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>Normalization的主要目的是为了 使目标函数平滑化，降低模型学习难度（即可以使用更大的学习率）</li>
<li>一般步骤包括<ul>
<li>reshape</li>
<li>normalization</li>
<li>recovery</li>
</ul>
</li>
</ul>
<h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>略</p>
<h3 id="残差"><a href="#残差" class="headerlink" title="残差"></a>残差</h3><p>略</p>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>实用ML_9.迁移学习</title>
    <url>/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>由于深度网络的训练对数据要求较大，且训练成本较高，对在其他任务训练好的深度模型使用到相关任务的需求较大，主要方式有</p>
<ol>
<li>使用深度模型做特征抽取（bert，word2vec等），输入到不同模型，解决不同任务</li>
<li>在方便训练的相近的任务（可能是 训练数据充足等）上训练模型，在目标任务上重用训练好的模型</li>
<li>微调预训练模型</li>
</ol>
<h3 id="Fine-tuning（从CV方向进行讲解）"><a href="#Fine-tuning（从CV方向进行讲解）" class="headerlink" title="Fine-tuning（从CV方向进行讲解）"></a>Fine-tuning（从CV方向进行讲解）</h3><p>CV领域存在很多良好的数据集（imagenet），如何将在这些大数据集上训练好的模型（学到的知识）迁移到自己的任务上来？这就是Fine-tuning要做的任务。</p>
<h4 id="Pre-trained-Model"><a href="#Pre-trained-Model" class="headerlink" title="Pre-trained Model"></a>Pre-trained Model</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220307144746729.png" class="" title="image-20220307144746729">
<span id="more"></span>
<h4 id="如何进行Fine-Tuning"><a href="#如何进行Fine-Tuning" class="headerlink" title="如何进行Fine-Tuning"></a>如何进行Fine-Tuning</h4><p>模型构建</p>
<ul>
<li>直接使用预训练模型的所有参数和架构</li>
<li>只随机初始化最后一个输出层的参数</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220307145106552.png" class="" title="image-20220307145106552">
<p>模型学习</p>
<ul>
<li>使用小学习率寻找解（预训练模型已在解附近，小步探索）</li>
</ul>
<h4 id="Freeze-Bottom-Layers"><a href="#Freeze-Bottom-Layers" class="headerlink" title="Freeze Bottom Layers"></a>Freeze Bottom Layers</h4><p>深度神经网络不同层在具体任务中捕捉不同层级的特征信息，更接近输出层的网络层更加倾向于捕捉<strong>任务相关特征</strong>（task specific），底层网络更加倾向于<strong>捕捉通用的、一般的特征</strong>（图片中的曲线、边等）</p>
<p>针对预训练模型该特性以及要Fine-tuning目标任务，对底层和高层网络采用不同训练手段</p>
<ul>
<li>底层冻结或者低学习率</li>
<li>高层正常训练</li>
</ul>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220307150714650.png" class="" title="image-20220307150714650">
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220307150826148.png" class="" title="image-20220307150826148">
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220307151536617.png" class="" title="image-20220307151536617">
<h3 id="Fine-tuning-in-NLP"><a href="#Fine-tuning-in-NLP" class="headerlink" title="Fine-tuning in NLP"></a>Fine-tuning in NLP</h3><p>NLP领域面临的问题与CV不同，NLP没有大规模良好标记的数据集，只有大量未标记的文本数据（维基百科、电子书、爬取的数据等）</p>
<p>只能使用自监督学习学习的方式进行模型预训练</p>
<ul>
<li>生成伪标签，然后在伪标签上进行监督学习</li>
<li>主要的两种类型<ol>
<li>语言模型：给定序列预测下一个词</li>
<li>Masked language model：给定序列，预测序列中的某一个词</li>
</ol>
</li>
</ul>
<h4 id="常见预训练模型"><a href="#常见预训练模型" class="headerlink" title="常见预训练模型"></a>常见预训练模型</h4><ol>
<li>词嵌入模型：获得包含语义信息的词向量</li>
<li>基于transformer的预训练模型<ul>
<li>BERT：encoder  适用于文本分类等的NLU任务</li>
<li>GPT: decoder 适用于摘要、总结等NLG任务</li>
<li>T5: encoder-decoder 适用于摘要、总结等NLG任务</li>
</ul>
</li>
</ol>
<p><strong>bert微调小技巧</strong></p>
<ul>
<li><p>在将bert应用到自己任务时，可以将bert接近输出层的几层权重默认初始化</p>
</li>
<li><p>Hugging Face 获取预训练模型</p>
<img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220308085742505.png" class="" title="image-20220308085742505">
</li>
</ul>
<h4 id="应用-1"><a href="#应用-1" class="headerlink" title="应用"></a>应用</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220308085949407.png" class="" title="image-20220308085949407">
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><img src="/2022/03/08/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8ML_9.%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/image-20220308090255661.png" class="" title="image-20220308090255661">]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>实用机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-1.如何在计算机中表示词语</title>
    <url>/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/</url>
    <content><![CDATA[<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210809091658017.png" class="" title="image-20210809091658017">
<p>想要通过计算机解决NLP问题，首先要解决的就是词语表示问题，由于一个词语在不同语境以及不同文化背景下含义的多样性，如何在计算机中有效的存储，表示不同词语的不同含义，是需要解决的重要问题。</p>
<h3 id="传统表示方式"><a href="#传统表示方式" class="headerlink" title="传统表示方式"></a>传统表示方式</h3><h4 id="WordNet-（discrete-representation）"><a href="#WordNet-（discrete-representation）" class="headerlink" title="WordNet （discrete representation）"></a>WordNet （discrete representation）</h4><blockquote>
<p>上义词是对事物的概括性、抽象性说明；下义词是事物的具体表现形式或更为具体的说明</p>
</blockquote>
<p>采用同义词（synonym）和上义词（hypernym）两个相关词语集合来描述当前词语的含义，当前方法一定程度上能够正确表示词语含义，但是存在一定问题</p>
<ol>
<li>忽略了词语在不同语境中的细微语义差异（比如 “中” 只有在河南话中和 “好” 是同义词）</li>
<li>词语的新的词义的添加较为困难</li>
<li>同义词和上义词定义较为主观，需要人工来整理两个词语集合</li>
</ol>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210809091554618.png" class="" title="image-20210809091554618">
<span id="more"></span>
<h4 id="one-hot-词向量"><a href="#one-hot-词向量" class="headerlink" title="one-hot 词向量"></a>one-hot 词向量</h4><p>引入神经网络的向量思想，使用词的位置独热编码表示作为词在计算机中的表示形式，其中词向量的维度就是词典中词语的个数，这就导致了如果词典中词语数量增加，会导致词向量维度不断增加。</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210809093045800.png" class="" title="image-20210809093045800">
<p>另一问题是所有独热编码表示的词语，均正交，无法表示词语之间的关联关系，由此引出 要将词语的相似度表示在词向量中的想法。</p>
<h4 id="Word-Vector"><a href="#Word-Vector" class="headerlink" title="Word Vector"></a>Word Vector</h4><blockquote>
<p> <strong>Distributional semantics</strong>:一个词语的含义由其上下文的词语所决定</p>
</blockquote>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210809093839703.png" class="" title="image-20210809093839703">
<p>为了解决独热编码词向量的稀疏问题，引入分布式语义，根据上下文确定当前词语的dense vector，即Word Vector（Word Embedding）</p>
<h3 id="Word2Vec（跳词模型为例）"><a href="#Word2Vec（跳词模型为例）" class="headerlink" title="Word2Vec（跳词模型为例）"></a>Word2Vec（跳词模型为例）</h3><p>通过上下文相关性，确定当前词语的含义，即向量表示，这种相关性定义为某一单词上下文出现另一个单词的概率，如下图表示的为以C为中心词，周围出现单词o的概率。</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210809095950546.png" class="" title="image-20210809095950546">
<p>为了方便计算为每个词典中的词语定义了 中心词向量$v_i$​ 和背景词$u_i$​​两个特征向量。根据由中心词确定上下文的思想，因此整个上下文句子的似然函数为</p>
<script type="math/tex; mode=display">
L(\theta) = \prod^T_{t=1}\prod_{-m<j<m 且j\neq0}P(w_{t+j}|w_t,\theta)\tag{1}</script><p>即以上下文中所有词语作为中心词，在窗口大小为2m的条件下，出现背景词概率乘积的连，对应的损失函数形式为</p>
<script type="math/tex; mode=display">
J(\theta) = -\frac{1}{T}log(L(\theta))= -\frac{1}{T}\sum^T_{t=1}\sum_{-m<j<m 且j\neq0}log(P(w_{t+j}|w_t,\theta))\tag{2}</script><p>带入概率公式求损失函数（2）关于特定中心词向量$v_c$​​​​​的偏导数，可得</p>
<script type="math/tex; mode=display">
\frac{\partial J(\theta)}{\partial v_c} = \sum_{-m<j<m 且j\neq0} [u_{c+j} - \sum_{w \in v} P(w|c)u_w]\tag{3}</script><p>即损失函数以中心词$v_c$​ 背景词$u_{c+j}$​​​​的部分偏导数为：</p>
<ul>
<li><strong>当前背景词的背景向量 - 当前词库所有背景词以$v_c$为中心词概率分布的背景向量$u$的加权平均和</strong></li>
</ul>
<h4 id="为什么设置两个向量（背景向量-u-和-中心向量-v-）"><a href="#为什么设置两个向量（背景向量-u-和-中心向量-v-）" class="headerlink" title="为什么设置两个向量（背景向量$u$ 和 中心向量 $v$）"></a>为什么设置两个向量（背景向量$u$ 和 中心向量 $v$）</h4><p>为了便于损失函数求偏导计算，在真正使用时，使用两个向量的平均值作为词语的表征向量</p>
<h4 id="如何解决计算量过大的问题"><a href="#如何解决计算量过大的问题" class="headerlink" title="如何解决计算量过大的问题"></a>如何解决计算量过大的问题</h4><p>由条件概率公式可得，分母的计算需要遍历整个语料库，计算量过大</p>
<h5 id="随机梯度下降（Stochastic-Gradient-Descent）"><a href="#随机梯度下降（Stochastic-Gradient-Descent）" class="headerlink" title="随机梯度下降（Stochastic Gradient Descent）"></a>随机梯度下降（Stochastic Gradient Descent）</h5><p>按照特定抽样方法，每个训练epoch从语料库中抽取一部分的作为当前训练语料库，抽样能否代表整体，取决于抽样方法的设计</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811084901573.png" class="" title="image-20210811084901573">
<h5 id="负采样"><a href="#负采样" class="headerlink" title="负采样"></a>负采样</h5><img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811093414764.png" class="" title="image-20210811093414764">
<blockquote>
<p>样本量大时，k一般选择2-5,样本量小时，k一般选择5-20</p>
</blockquote>
<p>负采样通过两个思路解决计算量较大的问题：</p>
<ol>
<li>将概率公式从softmax替换为sigmoid</li>
<li>概率公式的计算范围为负采样空间内</li>
</ol>
<p>以词袋模型为例，当 $context(w)$ 预测 $w$ 时，以{ $context(w)$ , $w$ }作为正样本，并从语料库库中选取k个非 $w$ 词语，与 $w$ 上下文构成{ $context(w)$ , $w_i$​​​​ }负样本，以正负样本集对模型进行训练。</p>
<p>替换后的概率公式（D=1或0 1表示该情况出现，0表示该情况不出现）</p>
<script type="math/tex; mode=display">
P(D=1|w_c,w_o) = \sigma(u_o^Tv_c)\tag{4}</script><p>其中 $\sigma$ 为sigmoid函数</p>
<script type="math/tex; mode=display">
\sigma(u_o^Tv_c) = sigmoid(u_o^Tv_c) = \frac{1}{1 + exp(-u_o^Tv_c)}\tag{5}</script><p>新的概率计算公式为,P(w)为随机负采样的概率分布</p>
<script type="math/tex; mode=display">
p(o|c) = p(D=1|w_c,w_o)\prod_{k=1,k\in P(w)}p(D=0|w_c,w_k)</script><p>推导可得</p>
<script type="math/tex; mode=display">
-log(p(o|c)) = -log[\sigma(u_o^Tv_c)]-\sum_{k=1,k\in P(w)}log(1- \sigma(u_k^Tv_c))</script><p>随之而来的问题是<strong>如何进行负采样</strong>才能保证训练是有效的？（trick）</p>
<blockquote>
<p> word2vec论文作者通过观察测试发现最佳采样概率分布是采用特殊的独立分布，概率公式为$p(w_i) = \frac{count(wi)^{\frac{3}{4}}}{\sum_{j= 0}^{total}w_j}$</p>
</blockquote>
<h5 id="层序softmax"><a href="#层序softmax" class="headerlink" title="层序softmax"></a>层序softmax</h5><p>首先按照单词在语料库中出现的频率构建haffman树，每个叶子节点为语料库中的词语，将softmax概率函数转化为每个二叉树节点的二分类逻辑回归（sigmoid）函数，我们的目标就是最大化从根节点到目标词语叶子节点路径的似然函数。（类似于负采样的概率函数）</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811091807339.png" class="" title="image-20210811091807339">
<h4 id="词袋模型的概率公式"><a href="#词袋模型的概率公式" class="headerlink" title="词袋模型的概率公式"></a>词袋模型的概率公式</h4><p>已经知上下文，推导中心词，概率公式如下(窗口大小为2m)</p>
<script type="math/tex; mode=display">
p(w_c|w_{o1},......,w_{o2m}) = \frac{exp(\frac{1}{2m} u_c^T(v_{o1},......v_{om}))}{\sum_{i\in window}exp(\frac{1}{2m} u_i^T(v_{o1},......v_{om}))}</script><p>即背景词出现情况下中心词出现的条件概率（背景词向量取了平均值）</p>
<h3 id="词共现矩阵（co-occurence-matrix）"><a href="#词共现矩阵（co-occurence-matrix）" class="headerlink" title="词共现矩阵（co-occurence matrix）"></a>词共现矩阵（co-occurence matrix）</h3><p>首先限定句子窗口长度后，统计每个词在窗口长度内其他词出现的次数，记录在共现矩阵中，记录完成后以行作为每个词的特征向量</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811094558672.png" class="" title="image-20210811094558672">
<p>虽然一定程度上解决了独热编码的过于系数，无法表示词语之间关系的问题，仍存在向量维度爆炸，且过于稀疏的问题，课程中提发了集中解决方案：</p>
<ol>
<li>使用SVD分解后的矩阵作为特征向量，以降低向量维度</li>
</ol>
<h3 id="Glove"><a href="#Glove" class="headerlink" title="Glove"></a>Glove</h3><p>Glove算法通过结合传统计数思路对word2vec模型进行了改进，词与词之间的关系不再通过神经网络式的预测模拟，而是通过拟合词与词之间共同出现的条件概率，实现词向量的构建。</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811100512861.png" class="" title="image-20210811100512861">
<p>Glove为了实现计算出来向量满足线性计算，将 两个词语的词向量乘积 与  共现条件概率 对应起来</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811104406982.png" class="" title="image-20210811104406982">
<p>通过拟合共现条件概率，实现词向量的学习</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811104602858.png" class="" title="image-20210811104602858">
<p>动手学习机器学习中的讲解（另一个角度理解）</p>
<img src="/2021/08/11/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-1.%E5%A6%82%E4%BD%95%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E8%A1%A8%E7%A4%BA%E8%AF%8D%E8%AF%AD/image-20210811104020990.png" class="" title="image-20210811104020990">
<h3 id="如何评估一组词向量"><a href="#如何评估一组词向量" class="headerlink" title="如何评估一组词向量"></a>如何评估一组词向量</h3><ol>
<li>通过后续任务（文本分类，问答系统）等的效果评估</li>
<li>词向量是否易于构建（维度低，效果好）</li>
<li>通过余弦相似度，衡量词语之间的相似度</li>
</ol>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-10.上下文词嵌入</title>
    <url>/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/</url>
    <content><![CDATA[<h2 id="课程大纲"><a href="#课程大纲" class="headerlink" title="课程大纲"></a>课程大纲</h2><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013201952293.png" class="" title="image-20211013201952293">
<h2 id="预训练到来之前"><a href="#预训练到来之前" class="headerlink" title="预训练到来之前"></a>预训练到来之前</h2><h3 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h3><p>迄今为止，我们主要使用包括Word2Vec，Glove等词嵌入向量，通过大量的数据预训练，提供给下游任务作为单词输入</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013202450741.png" class="" title="image-20211013202450741">
<p>之后我们遇到了 OOV(out of dic)和各种英语后缀不同导致单词含义不同得问题，传统预训练向量难以解决，引入了character-level的向量嵌入，如fastText。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013203324779.png" class="" title="image-20211013203324779">
<p>然而以往的词向量存在<strong>两个问题</strong></p>
<ul>
<li>以往的词向量嵌入<strong>不考虑上下文语境信息（或者说只考虑一种固定的语境）</strong>，仅仅是固定的一个词向量，应用于不同的下游任务</li>
<li>一个词不止有字面意思，还有包括词性，语法以及适用的语境等其他隐含信息，以往词向量只考虑了词的字面含义</li>
</ul>
<span id="more"></span>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013204802812.png" class="" title="image-20211013204802812">
<h3 id="TagLM-“pre-EMLO”"><a href="#TagLM-“pre-EMLO”" class="headerlink" title="TagLM-“pre-EMLO”"></a>TagLM-“pre-EMLO”</h3><p>出发点：想要获得拥有上下文信息的词嵌入向量，但是又不想使用大量的标记数据</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013211127036.png" class="" title="image-20211013211127036">
<p>TagLM模型使用大量无标签数据，训练一个嵌入模型和一个基于RNN的语言模型，用两个模型的输出作为当前词语的嵌入向量，输入到词性标注模型中进行监督训练。</p>
<ul>
<li><strong>嵌入模型</strong>由字符集嵌入和词嵌入两个模型共同生成两个嵌入向量拼接，输入第一层双向RNN</li>
<li><strong>语言模型</strong>，由大量的无标签数据预训练后，输入上下文嵌入后与RNN第一层隐藏层输出拼接输入第二层</li>
<li>预训练<strong>语言模型</strong>，在预训练完成后就<strong>冻结</strong></li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013212332139.png" class="" title="image-20211013212332139">
<h3 id="EMLO"><a href="#EMLO" class="headerlink" title="EMLO"></a>EMLO</h3><p>ELMo 采用语言模型的思路，不输出固定的词向量表述，而是按照语言模型的方式根据上下文和当前词语，输入当前此与的向量表示。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211013213914902.png" class="" title="image-20211013213914902">
<p>ELMO使用了多层堆叠的双向LM（LSTM），与传统只选取最后一层隐藏状态输出不同，ELMO认为不同层抽出不同的特征信息（隐藏状态），使用各个层的隐藏状态加权平均，作为输出。</p>
<ul>
<li>加权平均的不同层权重 $s^{task}_j$ 以及学习率 $\gamma^{task}$ 取值，由下游任务(task)决定</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211014162907326.png" class="" title="image-20211014162907326">
<p>ELMo可以有不同的深度，提取不同深度的特征信息，适用于对应的问题</p>
<ul>
<li>浅层网络：Part-of-speech(词性标注)，syntactic dependencies（句法依存），NER（命名实体识别）</li>
<li>深层网络：sentiment（情感），Semantic role labeling(SRL 语义角色标注)，question andwering（阅读理解），SNLI（自然语言推理）</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211014164651518.png" class="" title="image-20211014164651518">
<h3 id="ULMfit-基于迁移学习思路"><a href="#ULMfit-基于迁移学习思路" class="headerlink" title="ULMfit-基于迁移学习思路"></a>ULMfit-基于迁移学习思路</h3><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211014182546795.png" class="" title="image-20211014182546795">
<p>ULMfit模型同样使用语言模型做词嵌入，共分为三步（文本情感分类为例）</p>
<ol>
<li>使用大量的领域数据对语言模型进行预训练</li>
<li>使用目标任务输入文本对训练好的语言模型进行微调（fine-tuning）</li>
<li>在模型的最后一层添加两个情感分类神经元</li>
</ol>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211014183233285.png" class="" title="image-20211014183233285">
<h2 id="预训练迁移模型-爆发"><a href="#预训练迁移模型-爆发" class="headerlink" title="预训练迁移模型 爆发"></a>预训练迁移模型 爆发</h2><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211014184204582.png" class="" title="image-20211014184204582">
<h3 id="Transformers简介"><a href="#Transformers简介" class="headerlink" title="Transformers简介"></a>Transformers简介</h3><p>为了解决RNN无法并行计算的问题，Transformer结合之前模型的经验，实现了高度的并行性</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-10.%E4%B8%8A%E4%B8%8B%E6%96%87%E8%AF%8D%E5%B5%8C%E5%85%A5/image-20211014185419211.png" class="" title="image-20211014185419211">
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-11.Transformers</title>
    <url>/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/</url>
    <content><![CDATA[<h2 id="主要概念理解"><a href="#主要概念理解" class="headerlink" title="主要概念理解"></a>主要概念理解</h2><h3 id="self-Attention-自注意力机制"><a href="#self-Attention-自注意力机制" class="headerlink" title="self-Attention 自注意力机制"></a>self-Attention 自注意力机制</h3><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/265108616">注意力机制介绍</a></p>
</blockquote>
<p>自注意力机制与注意力不同点在于，自注意力机制在序列内部进行注意力的计算，每个词与相邻词进行F(Q,K)计算，当前词作为Q，临近词作为K，计算主力注意力分数后，进行嵌入向量的加权平均。</p>
<ul>
<li>一个词语的含义取决于上下文临近词语的含义（语境），自注意力机制解决了RNN<strong>无法抽取长距离信息</strong>的问题</li>
<li>自注意力机制的计算可以通过矩阵运算实现并行化，解决了RNN<strong>无法并行优化</strong>的问题</li>
</ul>
<span id="more"></span>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211016162648608.png" class="" title="image-20211016162648608">
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017152513315.png" class="" title="image-20211017152513315">
<p><strong>self-attention过程简单总结</strong></p>
<ol>
<li>为每个输入词语随机初始化<strong>Query、Key、Value</strong>三个<strong>向量</strong>，其中，Value与注意力分数相乘做加权平均，输出结果</li>
<li>当需要计算某个词语表示时候，以当前词语的Query和相邻词Key（包括自己）用来计算注意力分数</li>
<li>使用上一步计算的注意力分数，输入softmax归一化，对相邻词的Value向量进行加权平均后输出当前词的向量表示</li>
</ol>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211016170802649.png" class="" title="image-20211016170802649">
<h3 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h3><p>降维思想，将原来的Q,K,V映射到多个不同得子空间(即一系列得$Q_i K_i V_i$ ,transformers中为八个)，这种映射通过矩阵乘法实现，每个一head维护一组$W_{iQ} W_{iK} W_{iV}$，通过单头中的$Q_i K_i V_i$ 与对应权重矩阵相乘得到对应得$Q_i K_i V_i$</p>
<ul>
<li>$QKV \in R^{1*512}$ </li>
<li>$W_{iQ}W_{iK}W_{iV} \in R^{512*64}$ </li>
<li>$Q*W_{iQ} = Q_i$ </li>
<li>可得 $Q_i K_i V_i \in R^{1*64}$，共计8个不同head，实现了从高维到低维得转换，但是没有增加参数数量。</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017103444937.png" class="" title="image-20211017103444937">
<p>在不同得子空间上进行注意力机制得计算后，进行拼接乘以权重矩阵获得多头注意力机制的输出</p>
<p>​                        <script type="math/tex">MultiAttention(Q, K, V) = concat(head_1,......,head_2) * W_{out}</script>  其中 $W_{out} \in R^{512*512}$</p>
<p>相当于 输出结果得每个位置都是由所有参数加权平均得到</p>
<p><strong>为什么要使用多头注意力机制</strong></p>
<ul>
<li>通过将QKV映射到不同的子空间，实现了从不同角度对于当前词语含义的捕捉，而在不同的翻译任务中，我们对不同角度的重视程度不同（例如 <a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> 举得it的例子），这种映射有助于模型自适应的捕捉特征，提升NMT的效果。</li>
<li>我觉得这就是个trick，到底有什么用也没人说清楚了（对黑盒算法强行解释），能用好用就完事了</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017105229086.png" class="" title="image-20211017105229086">
<h2 id="网络结构理解"><a href="#网络结构理解" class="headerlink" title="网络结构理解"></a>网络结构理解</h2><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017151555753.png" class="" title="image-20211017151555753">
<h3 id="Postion-Encoding-位置编码"><a href="#Postion-Encoding-位置编码" class="headerlink" title="Postion-Encoding 位置编码"></a>Postion-Encoding 位置编码</h3><p>transformer在对输入词语进行embedding后，由于transformer舍弃了RNN的时间序列输入形式，整个序列中不同位置的单词在输入时的地位是相同的，<strong>通过位置编码重赋予输入位置特征</strong>。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017110556688.png" class="" title="image-20211017110556688">
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017110713718.png" class="" title="image-20211017110713718">
<p>位置编码存在两种计算方式</p>
<ol>
<li><p>通过固定的公式，根据字符在序列中的位置，计算得到 (<a href="https://www.zhihu.com/question/347678607/answer/864217252">公式理解</a>),总结就是又要体现不同位置的差异性，又不能影响embedding的词语含义。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017111718315.png" class="" title="image-20211017111718315">
</li>
<li><p>随机初始化pos编码，通过模型学习生成对应编码</p>
</li>
</ol>
<h3 id="LayerNormalization层"><a href="#LayerNormalization层" class="headerlink" title="LayerNormalization层"></a>LayerNormalization层</h3><p>LN方法与BN方法类似，在一条数据不同特征之间进行归一化处理（BN对不同数据的同一特征归一化处理），由于RNN类似于一个不固定batchsize(时间步)的CNN网络，无法使用BN方法，采用LN方法一定程度上也可以实现BN方法的效果。</p>
<h3 id="Feed-Forward（FFN）层"><a href="#Feed-Forward（FFN）层" class="headerlink" title="Feed Forward（FFN）层"></a>Feed Forward（FFN）层</h3><p>类似于两个卷积核大小为1的卷积操作，目的是为了应用非线性激活函数RELU，增加<strong>非线性</strong>性质。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-11.Transformers/image-20211017150618854.png" class="" title="image-20211017150618854">
<h3 id="Decoder端"><a href="#Decoder端" class="headerlink" title="Decoder端"></a>Decoder端</h3><p>与encoder段基本一致，每个decoder块每部增加了一个 “encoder-decoder attention” 注意力机制，以encoder输出的K，V矩阵为输入，和Encoder当前词的Q进行注意力机制运算。</p>
<p><img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif" alt="img"></p>
<p>基本流程如图</p>
<p><img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="img"></p>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-12.自然语言生成</title>
    <url>/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/</url>
    <content><![CDATA[<h3 id="内容回顾"><a href="#内容回顾" class="headerlink" title="内容回顾"></a>内容回顾</h3><h4 id="Beam-Search：不同K的区别"><a href="#Beam-Search：不同K的区别" class="headerlink" title="Beam Search：不同K的区别"></a>Beam Search：不同K的区别</h4><ol>
<li>小K值可能导致生成序列效果较差（语法上、语义上、流畅度上）</li>
<li>大K值虽然能够解决以上问题，但是会带来更多的计算成本，一定程度上减低NMT任务中的BLUE分数<ul>
<li>开放式问答任务中，更大的K可能导致 回答更加的宽泛（与原问题的关联度更低）</li>
</ul>
</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019145744076.png" class="" title="image-20211019145744076">
<p><strong>其他的解决方案</strong></p>
<ol>
<li><strong>Sampling-based decoding</strong>（与Beam search不同在于decoder每一步只需要追踪一个词）<ul>
<li>Pure Sampling：每次随机选择概率分布中的某一个词，作为decoder输出词</li>
<li>Top-n Sampling：每次从前N个概率大小词语中选择某一个词，作为decoder输出词</li>
</ul>
</li>
</ol>
<h4 id="Softmax-temperature-带温度系数的Softmax方法"><a href="#Softmax-temperature-带温度系数的Softmax方法" class="headerlink" title="Softmax temperature: 带温度系数的Softmax方法"></a>Softmax temperature: 带温度系数的Softmax方法</h4><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/132785733">$\tau$解释</a></p>
</blockquote>
<p>在原始的Softmax函数中添加 <strong>temperature hyperparameter: $\tau$</strong> .</p>
<ol>
<li>$\tau$ 起到一种平滑作用， $\tau$ 越大softmax计算得到的概率分布越平滑，t越小分布越不均匀</li>
<li>在训练开始将 $\tau$ 值设置较大，概率分布较为平滑，loss较大可以避免模型落入局部最优解，随着训练的进行，不断增大 $\tau$ 值，从而提升模型的效果。（某一个 $\tau$ 值并不影响模型的结果）</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019151158168.png" class="" title="image-20211019151158168">
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019151618394.png" class="" title="image-20211019151618394">
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019151751505.png" class="" title="image-20211019151751505">
<span id="more"></span>
<h3 id="NLG"><a href="#NLG" class="headerlink" title="NLG"></a>NLG</h3><p>NLG主要解决的问题就是，给定输入文本，对文本进行分析和抽取，输出我们需要的指定文本信息（summary或者再创作）</p>
<ol>
<li>输入可以是单个文档，也可以是多个文档（多个文档通常内容是相关的）</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019152628788.png" class="" title="image-20211019152628788">
<p>目前NLG任务领域的主要数据集有</p>
<ol>
<li><p>single-document任务</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019153334719.png" class="" title="image-20211019153334719">
</li>
<li><p>句子简化（sentence simplification）</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019153513309.png" class="" title="image-20211019153513309">
</li>
</ol>
<p>NLG任务的<strong>两种</strong>主要实现方式</p>
<ol>
<li>抽取性（extractive）摘要</li>
<li>生成式（abstractive）摘要</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019153742775.png" class="" title="image-20211019153742775">
<h4 id="神经网络之前的NLG"><a href="#神经网络之前的NLG" class="headerlink" title="神经网络之前的NLG"></a>神经网络之前的NLG</h4><p>一般的单文本摘要流程如下</p>
<ol>
<li>首先从原文中选取特定的句子，作为摘要的句子组成内容（content selecting）</li>
<li>对选取的句子进行排序（Information Ordering）</li>
<li>对句子进行调整和修改（Sentence realization）</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019154611084.png" class="" title="image-20211019154611084">
<p>重点在于<strong>如何选择句子</strong></p>
<ol>
<li>基于算法对句子评分，选取评分高的句子作为候选摘要内容<ul>
<li>根据关键词出现频率，如tf-idf</li>
<li>句子在文章中出现的位置</li>
</ul>
</li>
<li>基于图算法（句子视为节点，句子之间的相似度视为边）</li>
</ol>
<h4 id="摘要评价-ROUGE"><a href="#摘要评价-ROUGE" class="headerlink" title="摘要评价-ROUGE"></a>摘要评价-ROUGE</h4><img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019164507272.png" class="" title="image-20211019164507272">
<p>ROUGE（Recall-Oriented Understudy for Gisting Evaluation）与BLUE类似，均基于n-gram共现评估生成文本与目标摘要文本的差距</p>
<ol>
<li>ROUGE在计算的过程中引入了召回率的概念，相较于NMT任务，摘要任务对召回率的重视程度更高</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019164852685.png" class="" title="image-20211019164852685">
<p>一种ROUGE评分只针对一种n-gram语法</p>
<ol>
<li>ROUGE-1: unigram overlap</li>
<li>ROUGE-2: bigram overlap</li>
<li>ROUGE-L: LCS overlap</li>
</ol>
<h4 id="Neural-Summarization-（2015-）发展历史"><a href="#Neural-Summarization-（2015-）发展历史" class="headerlink" title="Neural Summarization （2015-）发展历史"></a>Neural Summarization （2015-）发展历史</h4><ol>
<li><p>第一次使用seq2seq + attention实现单文档摘要</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211019170212035.png" class="" title="image-20211019170212035">
</li>
<li><p>2015后出现的一系列解决方案</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211020112720437.png" class="" title="image-20211020112720437">
</li>
</ol>
<h4 id="Copy-Mechanisms：解决seq2seq局限于特征"><a href="#Copy-Mechanisms：解决seq2seq局限于特征" class="headerlink" title="Copy Mechanisms：解决seq2seq局限于特征"></a>Copy Mechanisms：解决seq2seq局限于特征</h4><p>由于seq2seq机制中decoder基于encoder输出特征进行生成，无法满足<strong>保留源语句中某些关键词</strong>的要求（虽然fluent，但不够imformative），通过Copy Mechanisms解决这个问题。</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211020113937063.png" class="" title="image-20211020113937063">
<p>Copy Mechanisms 通过attention机制，将input中的某些词或者某些句子，<strong>直接作为output中的内容输出</strong>，通过与seq2seq结合，更好的适应文档摘要问题</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211020114155828.png" class="" title="image-20211020114155828">
<p>几个复制机制的实现</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211020114245710.png" class="" title="image-20211020114245710">
<p>存在的问题（单词级别的复制机制）</p>
<ol>
<li>复制的度难以把握，容易退化成抽取算法</li>
<li>复制时难以考虑整篇文章的信息，当文章过长时，复制效果不理想</li>
<li>如何选择，没有一个确定的策略</li>
</ol>
<p><strong>Bottom up summarization</strong></p>
<p>解决单词级别复制问题，将摘要过程分为两个阶段</p>
<ol>
<li>内容选择阶段: 使用标注模型，对原文章中的词进行标记是否需要</li>
<li>摘要阶段：同样的seq2seq+attention摘要模型，只是对上一步标记的不需要词语进行掩码覆盖，不参与预测</li>
</ol>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211023091146567.png" class="" title="image-20211023091146567">
<h3 id="Dialogue-对话生成任务"><a href="#Dialogue-对话生成任务" class="headerlink" title="Dialogue 对话生成任务"></a>Dialogue 对话生成任务</h3><p>对话生成任务的范围较为广泛，从日常对话、智能客服到辩论等，主要包括任务型对话和社会对话两种</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211023094731197.png" class="" title="image-20211023094731197">
<h4 id="pre-neural"><a href="#pre-neural" class="headerlink" title="pre-neural"></a>pre-neural</h4><p>由于开放式文档问题难度较高，神经网络应用之前的系统往往使用模板式回答或者从一系列语料中寻找回答的方式，实现对话。</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211023095226942.png" class="" title="image-20211023095226942">
<h4 id="seq2seq-based-dialogue"><a href="#seq2seq-based-dialogue" class="headerlink" title="seq2seq-based dialogue"></a>seq2seq-based dialogue</h4><p>虽然很会人们就发现seq2seq模型可以应用于解决对话生成任务，但是目前随着应用的开展，发现存在一系列的问题</p>
<ol>
<li>回答宽泛（虽然给了答案，但是答案没什么用） Genericness</li>
<li>回答与上下文不相关 Irrelevant</li>
<li>不断地重复 Repetition</li>
<li>缺乏上下文信息 （对话的上下文，对话的人等）</li>
</ol>
<p><strong>解决irrelevant问题</strong></p>
<ol>
<li>生成的一般回答，而不是想要的回答 （i don’t know）</li>
<li>回答的主题与问题不相关</li>
</ol>
<p>传统NN模型的优化目标往往是最大化  $p(Target|Source)$ ，即给定目前问题下得到对应答案的条件概率；当前解决方案采用互信息MMI作为优化目标\</p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211023101005268.png" class="" title="image-20211023101005268">
<p>在公式上体现为原条件概率减去了当前回答出现的概率（形式上理解为减去回答概率，对在预料中出现频率较高的通用回答进行了惩罚）</p>
<p><strong>解决genericness问题</strong></p>
<img src="/2021/11/21/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-12.%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90/image-20211023101625189.png" class="" title="image-20211023101625189">
<p><strong>解决repetition问题</strong></p>
<p>简单解决方案: 对于decoder输出的n-gram,禁止n-gram句子中存在相同词语。（简单而粗暴）</p>
<p>复杂方案</p>
<ol>
<li>避免注意力机制计算时重复的计算相同背景词（从源头铲除相同词语）</li>
<li>设置训练目标，减少重复出现</li>
</ol>
<h3 id="NLG-Evaluation"><a href="#NLG-Evaluation" class="headerlink" title="NLG Evaluation"></a>NLG Evaluation</h3><p>传统基于词覆盖的评价方式，例如BLUE、ROGUE等，并不适用于NLG任务（或者说无法真正反映一个NLG解决方案的好坏），既然无法找到一种衡量NLG任务好坏的方式，我们不如聚焦于生成结果的某一个方面</p>
<ul>
<li>流利性</li>
<li>正确的风格</li>
<li>多样性</li>
<li>相关输入</li>
<li>简单的长度和重复</li>
<li>特定于任务的指标，如摘要的压缩率</li>
</ul>
<p>人类评估（省略）</p>
<h3 id="NLG发展方向"><a href="#NLG发展方向" class="headerlink" title="NLG发展方向"></a>NLG发展方向</h3><ul>
<li>将离散潜在变量纳入NLG（不同任务可能有不同的潜在特征）<ul>
<li>可以帮助在真正需要它的任务中建模结构，例如讲故事，任务导向对话等</li>
</ul>
</li>
<li>严格的从左到右生成的替代方案<ul>
<li>并行生成，迭代细化，自上而下生成较长的文本</li>
</ul>
</li>
<li>替代teacher forcing的模型训练方法<ul>
<li>更全面的句子级别的目标函数（而不是单词级别）</li>
</ul>
</li>
</ul>
<p>目前NLG发展</p>
<ul>
<li>在NLP+深度学习的早期，社区主要将成功的机器翻译方法转移到NLG任务中。</li>
<li>现在，越来越多的创新NLG技术出现，针对非NMT生成环境。</li>
<li>越来越多（神经）NLG研讨会和竞赛，特别关注开放式NLG<ul>
<li>NeuralGen workshop</li>
<li>Storytelling workshop</li>
<li>Alexa challenge</li>
<li>ConvAI2 NeurIPS challenge</li>
</ul>
</li>
<li>这些对于组织社区提高再现性、标准化评估特别有用</li>
<li>最大障碍是评估</li>
</ul>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-2.使用神经网络解决nlp问题</title>
    <url>/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="神经网络介绍"><a href="#神经网络介绍" class="headerlink" title="神经网络介绍"></a>神经网络介绍</h3><p>神经网络介绍部分省略</p>
<h3 id="命名实体识别（NER）"><a href="#命名实体识别（NER）" class="headerlink" title="命名实体识别（NER）"></a>命名实体识别（NER）</h3><p>标注中句子中的目标词性词语-实体，其中实体是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210831093150777.png" class="" title="image-20210831093150777">
<p>命名实体存在的困难：</p>
<ol>
<li>难以确定实体的上下文边界（王小明 还是 小明）</li>
<li>难以确定词语是否为 实体</li>
<li>实体的具体含义依赖于上下文，难以确定</li>
<li>难以辨别不知道的实体（特定语境 特定环境下的某些词作为实体）</li>
</ol>
<span id="more"></span>
<h4 id="1-Binary-word-window-classification"><a href="#1-Binary-word-window-classification" class="headerlink" title="1.Binary word window classification"></a>1.Binary word window classification</h4><p>由于词语根据语境等具有不同的含义和词性，单独识别句子中的某个单词是不现实的，使用一个上下文窗口对词语进行分类</p>
<p><strong>思路：</strong> 使用上下文窗口中的背景词对当前词进行分类</p>
<ul>
<li><p>对窗口内词向量进行平均，作为分类输入。<strong>问题：</strong>忽略了位置信息和词语之间的关系</p>
</li>
<li><p>使用窗口内词向量拼接向量作为输入</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210831095343422.png" class="" title="image-20210831095343422">
</li>
</ul>
<p>训练分类函数</p>
<ol>
<li><p>softmax 或者 交叉熵函数，通过反向传播更新词向量和权重</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210831095949882.png" class="" title="image-20210831095949882">
</li>
<li><p>unnormarlized score</p>
<ul>
<li><p>选取一个正例窗口和一个反例窗口</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210831100250180.png" class="" title="image-20210831100250180">
</li>
<li><p>将拼接的窗口向量输入到具有一个隐藏层和一个全连接输出层的神经网络，输出一个评价分数（score)</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210831100708874.png" class="" title="image-20210831100708874">
<ul>
<li><strong>添加隐藏层的目的</strong>在于通过隐藏层的非线性激活函数，学习输入与输出之间的非线性关系（non-linear interaction）</li>
</ul>
</li>
<li><p>训练目标为：正例窗口分数最大，负例窗口分数最小</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210901090231216.png" class="" title="image-20210901090231216">
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-2.%E4%BD%BF%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A7%A3%E5%86%B3nlp%E9%97%AE%E9%A2%98/image-20210901090217098.png" class="" title="image-20210901090217098">
</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-3.依存分析问题</title>
    <url>/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h4 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h4><p>句法分析与上下文无关文法相对立，强调通过对于句子语法结构的分析，实现对于句子的理解。最常见的三种句法分析任务如下</p>
<ol>
<li>句法结构分析 识别句子中的短语结构和层次关系</li>
<li>依存关系分析 识别句子中词与词之间的依存关系，确定词语的含义</li>
<li>深层文法句法分析 利用深层文法对句子进行分析</li>
</ol>
<h4 id="依存句法分析（Dependency-Parsing）"><a href="#依存句法分析（Dependency-Parsing）" class="headerlink" title="依存句法分析（Dependency Parsing）"></a>依存句法分析（Dependency Parsing）</h4><p>依存结构展示了句子中依赖于其他词语的单词，这种依赖体现为被修饰或者被限定</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909082635347.png" class="" title="image-20210909082635347">
<span id="more"></span>
<p>同一个句子，在不同的依存关系下，理解的含义可能有所不同</p>
<ol>
<li>介词修饰歧义（preposition attachment ambiguity）(刀杀死了男人，还是杀死了带刀的男人）</li>
</ol>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909083302896.png" class="" title="image-20210909083302896">
<ol>
<li><p>修饰范围歧义（Coordination scope ambiguity）</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909084806696.png" class="" title="image-20210909084806696">
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909084821340.png" class="" title="image-20210909084821340">
</li>
<li><p>形容词修饰歧义</p>
</li>
</ol>
<h4 id="依存句法（Dependency-Grammar）"><a href="#依存句法（Dependency-Grammar）" class="headerlink" title="依存句法（Dependency Grammar）"></a>依存句法（Dependency Grammar）</h4><p>依存句法假设句子中的词语存在语法结构上的关联，这种通常为非对称的二元关联关系成为依赖（Dependency）</p>
<ol>
<li>依存语法树</li>
</ol>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909090638171.png" class="" title="image-20210909090638171">
<ol>
<li><p>直接在句子上标注</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909092703216.png" class="" title="image-20210909092703216">
</li>
</ol>
<p><strong>依赖关系的一般约束</strong></p>
<ol>
<li>依赖不循环</li>
<li>相依赖的词语一般距离较近</li>
<li>依赖项一般能够构成树形结构</li>
</ol>
<p><strong>依存句法分析的基本方法</strong></p>
<ol>
<li>Dynamic programming</li>
<li>Graph algorithms</li>
<li>Constraint Satisfaction</li>
<li>“Transition-based parsing” or “deterministic dependency parsing”</li>
</ol>
<h4 id="Greedy-transition-based-parsing-基于贪婪思想转换的依存分析"><a href="#Greedy-transition-based-parsing-基于贪婪思想转换的依存分析" class="headerlink" title="Greedy transition-based parsing 基于贪婪思想转换的依存分析"></a>Greedy transition-based parsing 基于贪婪思想转换的依存分析</h4><img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909103541425.png" class="" title="image-20210909103541425">
<p>简单理解就是 从句子的开头逐个单词进行压栈，判断即将入栈元素和栈顶元素的依存关系，根据依存关系在边集合<script type="math/tex">arcs A</script> 添加对应方向的边，弹出栈顶元素（reduce）(如果不存在关系，不弹)，并将当前元素压栈（shift）</p>
<p><strong>Arc-Standard transition-based parser</strong></p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909104413757.png" class="" title="image-20210909104413757">
<p><strong>MaltParser</strong></p>
<p>引入机器学习分类器，通过分类器判断添加的依赖，以及依赖的方向。避免了搜索，提供了一种线性的解析方式</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909104740587.png" class="" title="image-20210909104740587">
<h4 id="如何衡量依存分析的效果？"><a href="#如何衡量依存分析的效果？" class="headerlink" title="如何衡量依存分析的效果？"></a>如何衡量依存分析的效果？</h4><p><strong>Dependency Accurracy</strong></p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909105300077.png" class="" title="image-20210909105300077">
<h4 id="基于神经网络的依存分析器构建"><a href="#基于神经网络的依存分析器构建" class="headerlink" title="基于神经网络的依存分析器构建"></a>基于神经网络的依存分析器构建</h4><img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909110120011.png" class="" title="image-20210909110120011">
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-3.%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98/image-20210909111052510.png" class="" title="image-20210909111052510">
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-4.语言模型与RNN引入</title>
    <url>/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-4.%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERNN%E5%BC%95%E5%85%A5/</url>
    <content><![CDATA[<h4 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h4><p>通过语言模型的构建，实现能够根据已知序列推断序列中的下一个单词，如搜索引擎中的搜索推断等。</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-4.%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERNN%E5%BC%95%E5%85%A5/image-20210911095229424.png" class="" title="image-20210911095229424">
<p>模型的形式化定义如下，给定一系列单词，预测下一个单词的概率分布，该概率分布为当前模型词典库上词语的概率分布</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-4.%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERNN%E5%BC%95%E5%85%A5/image-20210911095436865.png" class="" title="image-20210911095436865">
<span id="more"></span>
<p>条件概率角度理解语言模型形式如下，即一系列条件概率的连乘</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-4.%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERNN%E5%BC%95%E5%85%A5/image-20210911095643154.png" class="" title="image-20210911095643154">
<h4 id="如何构建一个语言模型（N-grams模型）"><a href="#如何构建一个语言模型（N-grams模型）" class="headerlink" title="如何构建一个语言模型（N-grams模型）"></a>如何构建一个语言模型（N-grams模型）</h4><blockquote>
<p><strong><a href="https://baike.baidu.com/item/马尔可夫/2774684">马尔可夫</a></strong>（Markov）假设：下一个词的出现仅仅依赖于前面的几个词，而不是整个前部分句子（简化概率计算，减少模型参数）</p>
<p><strong>大数定理</strong>：在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。偶然中包含着某种必然</p>
</blockquote>
<p>N-grams模型基于马尔可夫假设，指给定的一段文本或语音中N个项目（item）的序列，项目可以是音节、词语或者碱基对等，N-gram模型中的N，即对应概率依赖的词语个数，例如：</p>
<ul>
<li><p>当N = 1时，1-gram模型（unigram）：$p(T) = p(W1)p(W2)…..p(Wn)$ 即词语的出现相互独立</p>
</li>
<li><p>当N = 2 时，2-gram模型（bigram）：$p(T) = p(W1)p(W2|W1)…..p(Wn|Wn-1)$ 即依赖前一个词语</p>
</li>
</ul>
<p>以N-gram模型为例子，根据大数定理可得，在语料库足够大的条件下，$W_n$关于$W_1…….W_{n-1}$的条件概率为</p>
<script type="math/tex; mode=display">
p(Wi|Wi-1) = \frac{count(W_1,W_2,.......W_{N-1},W_n)}{count(W_1,W_2,.......W_{N-1})}</script><p>即语料种$W_1^n$语句的出现次数除以$W_i^{n-1}$语句的次数</p>
<h5 id="单词稀疏问题（Sparsity-Problem）"><a href="#单词稀疏问题（Sparsity-Problem）" class="headerlink" title="单词稀疏问题（Sparsity Problem）"></a>单词稀疏问题（Sparsity Problem）</h5><p>根据N-grams的计算公式，如果语料库中不存在（或几乎没有）当前上文与目标推断单词共同出现的情况，则概率公式的分母为0，即<strong>稀疏问题</strong>，</p>
<p>解决方式为通过在概率公式中增加一个增量，使词库中的所有单词在给定上文预测的情况下，都具有一定的概率值（即使是不可能的单词），称之为<strong>平滑法</strong>。随着n元语法中的n不断增大，单词稀疏问题会更加严重</p>
<ul>
<li>Add‐One 平滑</li>
<li>Add‐K 平滑</li>
<li>等</li>
</ul>
<h5 id="固定窗口神经网络语言模型"><a href="#固定窗口神经网络语言模型" class="headerlink" title="固定窗口神经网络语言模型"></a>固定窗口神经网络语言模型</h5><p>固定输入窗口大小，将输入窗口内的词语向量拼接，作为模型输入，预测下一个单词的概率，解决了非神经网络语言模型存在的单词稀疏和存储稀疏问题，但是仍存在</p>
<ol>
<li>固定窗口有些时候可能太小</li>
<li>扩大窗口会导致模型参数量爆炸</li>
<li>窗口内不同位置单词对应不同的权重值（？）</li>
</ol>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-4.%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERNN%E5%BC%95%E5%85%A5/image-20210911103426907.png" class="" title="image-20210911103426907">
<h5 id="基于RNN的语言模型"><a href="#基于RNN的语言模型" class="headerlink" title="基于RNN的语言模型"></a>基于RNN的语言模型</h5><img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-4.%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8ERNN%E5%BC%95%E5%85%A5/image-20210911103854491.png" class="" title="image-20210911103854491">
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-5.RNN主要问题与改进</title>
    <url>/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/</url>
    <content><![CDATA[<h3 id="RNN梯度消失-爆炸问题（vanishing-exploding-gradient-problem）"><a href="#RNN梯度消失-爆炸问题（vanishing-exploding-gradient-problem）" class="headerlink" title="RNN梯度消失/爆炸问题（vanishing/exploding gradient problem）"></a>RNN梯度消失/爆炸问题（vanishing/exploding gradient problem）</h3><p>由于RNN对于不同时间步的输入使用同一个神经元，在反向传播计算梯度时，随着时间步的增加，会出现梯度爆炸和消失问题</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914151209756.png" class="" title="image-20210914151209756">
<span id="more"></span>
<p>RNN时间步t计算公式为</p>
<script type="math/tex; mode=display">
S_t = \sigma(S_{t-1}W_s + X_tW_x+b_t) \\
O_t = W_oS_t+b_o</script><p>反向传播的损失函数求导结果为</p>
<script type="math/tex; mode=display">
\frac{\partial L_t}{\partial W_x} = \sum_{k=0}^t \frac{\partial L_t}{\partial O_x}\frac{\partial O_t}{\partial S_t}(\prod_j^t \frac{\partial S_j}{\partial S_{j-1}})\frac{\partial O_k}{\partial W_x}</script><p>其中 $\frac{\partial s_j}{\partial S_{j-1}} = \sigma’ W_s$ (不考虑激活函数的情况下),由于累乘的性质，随着神经元系数W的累乘次数增加，如果$w$大于1，产生梯度爆炸问题；如果$w$小于，出现梯度消失问题。</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914152544786.png" class="" title="image-20210914152544786">
<p>梯度消失问题导致 <strong>RNN难以捕捉长时间步距离中的有效信息</strong></p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914153650599.png" class="" title="image-20210914153650599">
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914154543524.png" class="" title="image-20210914154543524">
<h4 id="解决梯度爆炸问题"><a href="#解决梯度爆炸问题" class="headerlink" title="解决梯度爆炸问题"></a>解决梯度爆炸问题</h4><p>梯度剪切（clipping）</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914154902059.png" class="" title="image-20210914154902059">
<h3 id="Long-Short-term-Memory-LSTM"><a href="#Long-Short-term-Memory-LSTM" class="headerlink" title="Long Short-term Memory(LSTM)"></a>Long Short-term Memory(LSTM)</h3><p>在原RNN每个时间步拥有一个隐藏状态 $h^{(t)}$ 的基础上，增加一个存储单元 $c^{(t)}$（cell state）存储RNN无法捕捉的长距离时间步信息</p>
<ul>
<li>LSTM能够从存储单元中删除、写入以及读取相关信息，是否执行这些操作由对应的控制门（gate）决定</li>
<li>每个时间步gate值由当前时间步信息动态计算</li>
</ul>
<p>三种类型门的值均采用神经网络方式预测得到</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914161611434.png" class="" title="image-20210914161611434">
<p><strong>基本计算流程：</strong></p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914162031478.png" class="" title="image-20210914162031478">
<ol>
<li>首先根据上一时间步隐藏状态和当前输入，计算当前存储单元候选值</li>
<li>根据<strong>遗忘门和输入门</strong>有选择的组合历史/当前存储单元计算值，获得当前存储单元值（忘记多少从前，留下多少现在）</li>
<li>根据<strong>输出门</strong>，决定隐藏状态值</li>
</ol>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914162308396.png" class="" title="image-20210914162308396">
<h4 id="为何LSTM能够解决梯度消失问题"><a href="#为何LSTM能够解决梯度消失问题" class="headerlink" title="为何LSTM能够解决梯度消失问题"></a>为何LSTM能够解决梯度消失问题</h4><p>关注点不在于解决梯度消失或者梯度爆炸，在于解决由梯度消失带来的 <strong>长距离信息无法捕捉的问题</strong>（不解决因，而改善果），类似于resnet中的残差思路</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210914163439128.png" class="" title="image-20210914163439128">
<h3 id="Gated-Recurrent-Units-GRU-降低了LSTM的复杂度"><a href="#Gated-Recurrent-Units-GRU-降低了LSTM的复杂度" class="headerlink" title="Gated Recurrent Units(GRU) - 降低了LSTM的复杂度"></a>Gated Recurrent Units(GRU) - 降低了LSTM的复杂度</h3><p>不使用cell存储单元，只采用们的思想控制历史隐藏状态以及当前隐藏状态对于结果的影响。、</p>
<ol>
<li>$u^t$ 更新门：控制当前生成当前隐藏状态时保留的历史状态和当前隐藏状态的比例</li>
<li>$r^t$ 重置门：历史隐藏状态信息 流入 当前候选隐藏状态的量</li>
</ol>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210915191812848.png" class="" title="image-20210915191812848">
<p>与LTSM应用效果区别不大，如果问题特别重视长距离信息的保存，默认使用LSTM</p>
<h3 id="其他类型神经网络中同样存在梯度消失爆炸问题"><a href="#其他类型神经网络中同样存在梯度消失爆炸问题" class="headerlink" title="其他类型神经网络中同样存在梯度消失爆炸问题"></a>其他类型神经网络中同样存在梯度消失爆炸问题</h3><p>随着网络层数的不断增加，梯度消失/爆炸更容易出现，导致深层神经网络的训练难度更高，出现了几种特殊类型网络，解决此类问题</p>
<ol>
<li><p>resnet 残差网络</p>
<blockquote>
<p><a href="https://www.cnblogs.com/shine-lee/p/12363488.html">相比于让$F(x)$学习成恒等映射，让$F(x)$学习成0要更加容易——后者通过L2正则就可以轻松实现</a></p>
</blockquote>
<p>残差网络采用 shortcut-connection的思想，将几个layer成为block，假设每个block拟合函数为$F(x)$ ,目标函数为$H(x)$。传统网络思想通过不断训练用拟合函数$F(x)$映射目标函数$H(x)$，resnet将拟合目标修改为$H(x)-x$ ,在输出增加一个<strong>shortcut connection</strong>，直接将$x$ 加到拟合结果上，实现与传统网络相同的效果。</p>
<p>也正是因为<strong>shortcut connection</strong>的存在，实现了长距离信息的保存</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210915194728672.png" class="" title="image-20210915194728672">
</li>
<li><p>densenet（<strong>待详细了解</strong>）</p>
<p>每一层的输入都包括前面所有层的输出</p>
</li>
</ol>
<h3 id="双向RNN（bidirectional）"><a href="#双向RNN（bidirectional）" class="headerlink" title="双向RNN（bidirectional）"></a>双向RNN（bidirectional）</h3><p>为了解决单向RNN存在的句子歧义问题（I am terribly exciting 是难受 还是特别兴奋？），通过两个独立的RNN网络，分别正/逆输入句子，将两个网络相同词语获得的隐藏状态拼接，形成新的隐藏状态，输入到输入层获得输入结果。</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210915195839882.png" class="" title="image-20210915195839882">
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210915200357516.png" class="" title="image-20210915200357516">
<h5 id="双向RNN的局限性"><a href="#双向RNN的局限性" class="headerlink" title="双向RNN的局限性"></a>双向RNN的局限性</h5><p>双向RNN只有在输入数据完整句子的情况下才能够使用，LM模型不适用。</p>
<h3 id="多层RNN（multi-layer）"><a href="#多层RNN（multi-layer）" class="headerlink" title="多层RNN（multi-layer）"></a>多层RNN（multi-layer）</h3><p>多个RNN单元堆积在一起组成深度网络，类似于卷积网络的思想，通过增加网络的深度，实现从浅层特征学习=&gt;深层特征学习。</p>
<img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210915200931271.png" class="" title="image-20210915200931271">
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><img src="/2021/09/15/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-5.RNN%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E4%B8%8E%E6%94%B9%E8%BF%9B/image-20210915201518821.png" class="" title="image-20210915201518821">
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-6.机器翻译</title>
    <url>/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/</url>
    <content><![CDATA[<h3 id="早期机器翻译"><a href="#早期机器翻译" class="headerlink" title="早期机器翻译"></a>早期机器翻译</h3><img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923165912958.png" class="" title="image-20210923165912958">
<p>采用 单词对应词典的形式，存储在磁带上，翻译时通过查字典的形式，找到对应词组合成句子。</p>
<h3 id="基于统计的机器翻译（Statistical-Machine-Translation-SMT）"><a href="#基于统计的机器翻译（Statistical-Machine-Translation-SMT）" class="headerlink" title="基于统计的机器翻译（Statistical Machine Translation SMT）"></a>基于统计的机器翻译（Statistical Machine Translation SMT）</h3><img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923165944670.png" class="" title="image-20210923165944670">
<p>从概率的角度解决机器翻译问题， 首先语料中学习概率模型（不同语言单词之间的概率和语言内的语言模型），通过建立的概率模型实现翻译功能。</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923170157170.png" class="" title="image-20210923170157170">
<span id="more"></span>
<h3 id="基于神经网络的机器翻译（Nerual-Machine-Translation）2014"><a href="#基于神经网络的机器翻译（Nerual-Machine-Translation）2014" class="headerlink" title="基于神经网络的机器翻译（Nerual Machine Translation）2014"></a>基于神经网络的机器翻译（Nerual Machine Translation）2014</h3><p>采用了一种叫做seq2seq（sequence to sequence）的模型,使用两个RNN单元（可以是任意类型的RNN）实现机器翻译问题</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923171554655.png" class="" title="image-20210923171554655">
<ol>
<li>Eecoder RNN：输入源语言句子，对该句子进行编码</li>
<li>Decoder RNN：输入编码器生成的编码（隐藏状态）和开始符，不断地生成预测单词，最后组合成为翻译句子</li>
</ol>
<p>几个主要的seq2seq类型任务</p>
<ol>
<li>总结摘要（原文章 到 摘要/总结）</li>
<li>对话 （前一句话 到 后一句话）</li>
<li>代码生成等</li>
</ol>
<p>seq2seq模型是一种<strong>条件语言</strong>模型</p>
<ol>
<li>seq2seq的作用仍然是给定上文推断出下一个词语，所以是语言模型</li>
<li><strong>条件</strong>体现在这种推断是基于源语言段落输入（在源语言的条件下）</li>
</ol>
<p>seq2seq相较于SMT更加优越是在于</p>
<ol>
<li><p>seq2seq模型直接模拟 目标语言在源语言条件下的语言模型</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923190656093.png" class="" title="image-20210923190656093">
</li>
<li><p>SMT 将这种模拟拆成两个子问题，源语言到目标语言的概率 和  目标语言的语言模型</p>
</li>
</ol>
<h3 id="如何训练seq2seq模型"><a href="#如何训练seq2seq模型" class="headerlink" title="如何训练seq2seq模型"></a>如何训练seq2seq模型</h3><p>输入 平行语料（源语言-目标语言的句子对），分别作为Encoder和Decoder的输入，Decoder每个时间步的预测输出与目标结果单独计算loss函数，最后以所有时间步的平均loss作为优化目标loss，反向传播实现训练。</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923191307147.png" class="" title="image-20210923191307147">
<ul>
<li>与预测不同，Decoder的每个时间步的输出不再作为下一个时间步的输入，输入来自于源语言对应的目标语言（类似于监督学习）。</li>
</ul>
<h3 id="解码器的解码策略"><a href="#解码器的解码策略" class="headerlink" title="解码器的解码策略"></a>解码器的解码策略</h3><h4 id="贪婪解码（greedy-decoding）"><a href="#贪婪解码（greedy-decoding）" class="headerlink" title="贪婪解码（greedy decoding）"></a>贪婪解码（greedy decoding）</h4><p>每个时间步选择预测概率最大的词作为预测结果，但是存在无法回退的问题</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923192446719.png" class="" title="image-20210923192446719">
<h4 id="束搜索解码（beam-search-decoding）"><a href="#束搜索解码（beam-search-decoding）" class="headerlink" title="束搜索解码（beam search decoding）"></a>束搜索解码（beam search decoding）</h4><p>由于穷举搜索的成本过高，贪婪解码又可能错过最优解，采用一种折中的思路，每次选取预测概率最大的k个词作为备选词，进入下一次预测，下一次同样选取概率最大的k个序列,其中k为束搜索的宽度。</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923193034552.png" class="" title="image-20210923193034552">
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923193403947.png" class="" title="image-20210923193403947">
<h5 id="如何结束搜索？"><a href="#如何结束搜索？" class="headerlink" title="如何结束搜索？"></a>如何结束搜索？</h5><ol>
<li>限定束搜索的最大时间步数</li>
<li>限定生成完整翻译句子的数字（最后一个时间步输出\<end\>标签）</li>
</ol>
<h5 id="解决束搜索倾向问题"><a href="#解决束搜索倾向问题" class="headerlink" title="解决束搜索倾向问题"></a>解决束搜索倾向问题</h5><p>由于score函数的计算方式，预测的翻译序列越长，其得分越高，导致束搜索更加倾向于短的翻译结果，通过对score归一化解决</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923194001899.png" class="" title="image-20210923194001899">
<h4 id="NMT的优势"><a href="#NMT的优势" class="headerlink" title="NMT的优势"></a>NMT的优势</h4><img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923194329188.png" class="" title="image-20210923194329188">
<h3 id="如何评价机器翻译效果"><a href="#如何评价机器翻译效果" class="headerlink" title="如何评价机器翻译效果"></a>如何评价机器翻译效果</h3><h4 id="BLUE-Bilingual-Evaluation-Understudy"><a href="#BLUE-Bilingual-Evaluation-Understudy" class="headerlink" title="BLUE(Bilingual Evaluation Understudy)"></a>BLUE(Bilingual Evaluation Understudy)</h4><p>将机器翻译结果语句（candidate）与一系列人类翻译的参考语句（references）相比较，比较相似度：</p>
<ol>
<li>依赖n-gram语法(以长度为n的子句子作为衡量的单元),计算 candidate中 n-gram在references中出现的个数 比上references中所有n-gram出现的次数。</li>
<li>并给倾向于生成过短翻译的系统以惩罚</li>
</ol>
<p>基本计算公式如下</p>
<script type="math/tex; mode=display">
BLUE=\frac{\sum_{n-gram \sub references}\sum_{n-gram \sub candidate \\ \& \\ n-gram \sub reference} Count_{clip}(n-gram)}{\sum_{n-gram \sub references}\sum_{n-gram \sub reference}}</script><p>通过召回率和惩罚因子，解决了重复出现和翻译较短给分较高的问题</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210923200515633.png" class="" title="image-20210923200515633">
<h3 id="机器翻译目前问题"><a href="#机器翻译目前问题" class="headerlink" title="机器翻译目前问题"></a>机器翻译目前问题</h3><ol>
<li>遇到语料库之外的词语，翻译效果较差</li>
<li>如果训练材料较为局限，训练出来的模型也不具备普适性（Domain mismatch）</li>
<li>无法解决长文本、书籍等的翻译问题（聚焦于句子，没有对全文信息的参考）</li>
<li>翻译好的 训练数据较少</li>
</ol>
<h3 id="Attention机制"><a href="#Attention机制" class="headerlink" title="Attention机制"></a>Attention机制</h3><p>编码器最后将整个句子的信息编码进入一个输出向量中，该向量可能无法包含所有的句子信息，导致解码器在信息缺失的情况下进行生成翻译短文（information bottleneck），注意力机制提供了一种解决这种问题的方法。</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210924144203179.png" class="" title="image-20210924144203179">
<p>在Decoder的每个时间步，不再直接使用隐藏状态作为预测输出层的输入，而是需要计算注意力输出</p>
<ol>
<li><p>当前时间步与编码器的每个时间隐藏状态输出点乘获得一个多个注意力分数，组成向量</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210924145511050.png" class="" title="image-20210924145511050">
</li>
<li><p>输入注意力分数向量到softmax计算概率分布</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210924145544523.png" class="" title="image-20210924145544523">
</li>
<li><p>对Encoder的每个时间步的隐藏状态进行概率分布加权平均（”注意力“ 就是 对哪个实践步隐藏状态的概率值大小，越大说明我对对应词语注意力越集中）</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210924145757503.png" class="" title="image-20210924145757503">
</li>
<li><p>将注意力输出与当前隐藏状态拼接，作为当前时间步输出层的输入，获得预测词语</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210924145905073.png" class="" title="image-20210924145905073">
</li>
</ol>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-6.%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/image-20210924144729428.png" class="" title="image-20210924144729428">
<p>Attention机制的优势</p>
<ol>
<li>显著提升了NMT系统的效果</li>
<li>解决了编码器存在的信息瓶颈问题</li>
<li>有助于解决梯度消失问题</li>
<li>提供了一定的可解释性（注意力分数）</li>
</ol>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-7.机器问答</title>
    <url>/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-7.%E6%9C%BA%E5%99%A8%E9%97%AE%E7%AD%94/</url>
    <content><![CDATA[<h3 id="Question-Answering"><a href="#Question-Answering" class="headerlink" title="Question Answering"></a>Question Answering</h3><p>相较于检索更进一步，给出一个问题，自动的找出这个问题的最合适答案，可以将这个问题划分为两个步骤</p>
<ol>
<li>找到包含问题答案的文档</li>
<li>在文档中找到当前问题的答案（阅读理解 Reading Comprehension）</li>
</ol>
<p>如果一个机器理解了一段问题，机器应该能够提供问题的正确答案，且答案中不包含与问题无关的相关信息</p>
<h3 id="SQuAD-Stanford-Question-Answering-Dataset"><a href="#SQuAD-Stanford-Question-Answering-Dataset" class="headerlink" title="SQuAD(Stanford Question Answering Dataset)"></a>SQuAD(Stanford Question Answering Dataset)</h3><p>每个问题对应一篇文章，答案是文章内的一段单词序列。</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-7.%E6%9C%BA%E5%99%A8%E9%97%AE%E7%AD%94/image-20210926161057907.png" class="" title="image-20210926161057907">
<p>为每个问题提供多个可选的标准答案</p>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-7.%E6%9C%BA%E5%99%A8%E9%97%AE%E7%AD%94/image-20210926161326100.png" class="" title="image-20210926161326100">
<h4 id="SQuAD如何评估（V1-1）"><a href="#SQuAD如何评估（V1-1）" class="headerlink" title="SQuAD如何评估（V1.1）"></a>SQuAD如何评估（V1.1）</h4><ul>
<li>为每个问题提供三个标准答案</li>
<li>使用两种评分机制<ol>
<li>Exact match：按照字面意思理解，如果答案在三个标准答案中(1),不在标准答案中(0)</li>
<li>F1-score：分别计算对于每个问题回答的F1-score(<strong>具体怎么算法不知道</strong>)，对整个数据集上求平均后得到结果</li>
</ol>
</li>
<li>两种评分机制军忽略标点符号和无关的词汇（a,an,the）</li>
</ul>
<span id="more"></span>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-7.%E6%9C%BA%E5%99%A8%E9%97%AE%E7%AD%94/image-20210926164152196.png" class="" title="image-20210926164152196">
<h4 id="SQuAD如何评估（V2-0）"><a href="#SQuAD如何评估（V2-0）" class="headerlink" title="SQuAD如何评估（V2.0）"></a>SQuAD如何评估（V2.0）</h4><p>SQuAD2.0中1/2的问题的答案在文章中，1/2的问题的答案不在文章中（并不是所有的问题的答案都在文章中）</p>
<ul>
<li>对于无答案问题的评价，答案是无答案，给1；找到了某个答案，给0。（对于原有的两种评分机制都一样）</li>
</ul>
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-7.%E6%9C%BA%E5%99%A8%E9%97%AE%E7%AD%94/image-20210926165758040.png" class="" title="image-20210926165758040">
<img src="/2021/09/30/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-7.%E6%9C%BA%E5%99%A8%E9%97%AE%E7%AD%94/image-20210926165628432.png" class="" title="image-20210926165628432">
<h4 id="SQuAD存在的问题"><a href="#SQuAD存在的问题" class="headerlink" title="SQuAD存在的问题"></a>SQuAD存在的问题</h4><ul>
<li>所有问题的答案都是文章的子序列，没有难度更高的隐含、推理等类型的答案（后者问题更为常见）</li>
<li>SQuAD中问题的构建是基于文章的，问题倾向于与文章相似（体现在结构、用词等），降低了回答的难度</li>
</ul>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-8.NLP中的CNN</title>
    <url>/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-8.NLP%E4%B8%AD%E7%9A%84CNN/</url>
    <content><![CDATA[<h3 id="从RNN到CNN"><a href="#从RNN到CNN" class="headerlink" title="从RNN到CNN"></a>从RNN到CNN</h3><p>RNN的输入是一个完整的序列，其每一个时间步的输出均受到之前时间步的影响，RNN最终捕捉的是整个序列的特征信息，而一些NLP问题可能更加关注于句子的局部信息(例如本文分类)，这一点是CNN的强项。</p>
<h4 id="CNN解决NLP问题的出发点"><a href="#CNN解决NLP问题的出发点" class="headerlink" title="CNN解决NLP问题的出发点"></a>CNN解决NLP问题的出发点</h4><p>按照窗口大小，在原序列上进行滑动，获得不同相同长度的子序列（语义可能无关），对于这些个子序列分别计算向量信息</p>
<ul>
<li>忽略了语法和语义信息，只是距离上的临近</li>
<li>没有RNN的语法语义上的说服性（你就这样随便划分，提取出来的向量能有用？）</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-8.NLP%E4%B8%AD%E7%9A%84CNN/image-20211005093410774.png" class="" title="image-20211005093410774">
<span id="more"></span>
<p>NLP中的CNN类似于图像处理中的多通道一维卷积问题(conv1d)</p>
<ul>
<li>同样通过增加空向量，实现padding操作</li>
<li>使用多个卷积核，实现多通道输出</li>
<li>pooling over time，k-max pooling over time,dilation pooling</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-8.NLP%E4%B8%AD%E7%9A%84CNN/image-20211005095925832.png" class="" title="image-20211005095925832">
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-8.NLP%E4%B8%AD%E7%9A%84CNN/image-20211005104515907.png" class="" title="image-20211005104515907">
<h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><blockquote>
<p>解释来自 <a href="https://www.cnblogs.com/shine-lee/p/11989612.html">Batch Normalization详解</a> </p>
</blockquote>
<p>作为网络的一层，对输入的一个batch进行标准化处理（减均值，除以方差），能够有效的降低深度网络的学习难度</p>
<p><strong>batch分布不断变化导致模型拟合偏差</strong></p>
<ul>
<li>每次梯度下降根据输入batch的分布计算，或者说拟合的是输入的分布</li>
<li>不同batch分布不同，导致每次拟合不断改变方向（类似于无头苍蝇），导致学习速率减慢</li>
<li>在机器学习或者浅层模型中，这种问题并不严重，而在深度网络中，每一层都在进行着（无头苍蝇拟合），为了避免震荡，必须将学习率设置的小一些（<strong>Internal Covariate Shift</strong>）。</li>
</ul>
<p><strong>BN的主要操作：</strong></p>
<ol>
<li>对batch数据进行标准化操作（减均值，除以方差）<ul>
<li>这一步的参数是由输入batch决定的不需要学习</li>
</ul>
</li>
<li>对标准化后的数据进行平移和放缩（修改均值，和方差）<ul>
<li>平移和放缩的量由网络学习得到，即batch分布的均值和方差由学习得到</li>
</ul>
</li>
</ol>
<p><strong>BN带来的好处：</strong></p>
<ol>
<li>所有变换均为线性变换，反向传播求导较为简单</li>
<li>可以使用更大的学习率</li>
<li>权重的大小和初始化值不再重要，bias也可以设置为0</li>
</ol>
<h3 id="CNN的应用"><a href="#CNN的应用" class="headerlink" title="CNN的应用"></a>CNN的应用</h3><p><strong>Translation</strong></p>
<p>使用cnn作为encoder，rnn作为decoder</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-8.NLP%E4%B8%AD%E7%9A%84CNN/image-20211005145436480.png" class="" title="image-20211005145436480">
<p><strong>使用cnn实现深度nlp文本分类系统</strong></p>
<h3 id="Quasi-Recurrent-Neural-Network"><a href="#Quasi-Recurrent-Neural-Network" class="headerlink" title="Quasi-Recurrent Neural Network"></a>Quasi-Recurrent Neural Network</h3><h3 id="Q-RNN-Experiments-语言模型"><a href="#Q-RNN-Experiments-语言模型" class="headerlink" title="Q-RNN Experiments: 语言模型"></a>Q-RNN Experiments: 语言模型</h3>]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>cs224n-9.子词模型</title>
    <url>/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h3 id="语言学背景-划分更小单位的词"><a href="#语言学背景-划分更小单位的词" class="headerlink" title="语言学背景-划分更小单位的词"></a>语言学背景-划分更小单位的词</h3><h4 id="语音学和音韵学"><a href="#语音学和音韵学" class="headerlink" title="语音学和音韵学"></a>语音学和音韵学</h4><p>语音学中将语音看作连续不断变化的声音流，音韵学将语音划分为不同的单位-音位（phoneme），同一个词的读法中音位的不同，对于不同群体理解可能有不同的含义。但是由于发音对于文本的理解并无意义，将此思想借鉴到单词形态分析上，形成了这种（parts of word）的思想</p>
<h4 id="形态学：部分词（part-of-word）"><a href="#形态学：部分词（part-of-word）" class="headerlink" title="形态学：部分词（part of word）"></a>形态学：部分词（part of word）</h4><p>如何对词进行拆分以更好地理解当前的单词（有点中文里的看半边猜词的味道，英文里去掉前缀后缀看词根）</p>
<ul>
<li>传统方式是将单词划分为最小语义单位</li>
<li>使用字符级n-grams对单词进行拆分</li>
</ul>
<span id="more"></span>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211009184508969.png" class="" title="image-20211009184508969">
<h4 id="不同语言词语组成形式各不相同"><a href="#不同语言词语组成形式各不相同" class="headerlink" title="不同语言词语组成形式各不相同"></a>不同语言词语组成形式各不相同</h4><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211009185807612.png" class="" title="image-20211009185807612">
<h4 id="为什么我们需要小于词语级别的模型"><a href="#为什么我们需要小于词语级别的模型" class="headerlink" title="为什么我们需要小于词语级别的模型"></a>为什么我们需要小于词语级别的模型</h4><ul>
<li><p>部分语言的单词空间过大</p>
</li>
<li><p>音译</p>
</li>
<li><p>非正式拼写</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211009190155726.png" class="" title="image-20211009190155726">
</li>
</ul>
<h3 id="Character-level-Model-字符级别模型"><a href="#Character-level-Model-字符级别模型" class="headerlink" title="Character-level Model 字符级别模型"></a>Character-level Model 字符级别模型</h3><p>当前字符级别模型主要有两个主要方向</p>
<ol>
<li>与词语级别模型相同架构，只是将单位缩小为 “word pieces”</li>
<li>复合架构，主要采用词语模型，对于特殊情况（未知词）等使用字符级模型</li>
</ol>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010152953701.png" class="" title="image-20211010152953701">
<h4 id="纯字符级别NMT模型"><a href="#纯字符级别NMT模型" class="headerlink" title="纯字符级别NMT模型"></a>纯字符级别NMT模型</h4><p>English-Czech WMT 2015 Results</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211009191631221.png" class="" title="image-20211009191631221">
<p>Fully Character-Level Neural Machine Translation without Explicit Segmentation</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211009192226372.png" class="" title="image-20211009192226372">
<p>Stronger character results with depth in LSTM seq2seq model</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211009192454633.png" class="" title="image-20211009192454633">
<p>模型较小使用word-level，较大使用character-level</p>
<h4 id="Byte-Pair-Encoding"><a href="#Byte-Pair-Encoding" class="headerlink" title="Byte Pair Encoding"></a>Byte Pair Encoding</h4><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010154156409.png" class="" title="image-20211010154156409">
<p>源于一种字符压缩算法，将共同出现频率较高的两个压缩成字典中不存在的新字符。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010154131682.png" class="" title="image-20211010154131682">
<p><strong>为了解决NMT翻译中的<UNK>问题以及英语中不同后缀含义不同</strong>，使用子词单元嵌入代替词语，利用BPE思想，每次选择词库中出现频率最高的词语对（不一定长度为2），作为新词典中的一个词，不断按照上述方式选择，直到达到词典目标大小。</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010155718892.png" class="" title="image-20211010155718892">
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010155859930.png" class="" title="image-20211010155859930">
<h4 id="Wordpiece-Sentencepiece-model"><a href="#Wordpiece-Sentencepiece-model" class="headerlink" title="Wordpiece/Sentencepiece model"></a>Wordpiece/Sentencepiece model</h4><p>google在BPE的基础上形成了两种类型的模型</p>
<ol>
<li>Wordpiece  单词为整体，以字母为单位，进行划分</li>
<li>Sentencepiece  句子为整体，以单词为单位，进行划分（有点<strong>意群</strong>的味道）</li>
</ol>
<p>bert使用了一种变种wordpiece模型</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010171122417.png" class="" title="image-20211010171122417">
<h4 id="Character-level-to-build-Word-level"><a href="#Character-level-to-build-Word-level" class="headerlink" title="Character level to build Word level"></a>Character level to build Word level</h4><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010171600247.png" class="" title="image-20211010171600247">
<p>对字符卷积获得词嵌入向量</p>
<h4 id="Character-level-based-LSTM-to-build-word-repesetation"><a href="#Character-level-based-LSTM-to-build-word-repesetation" class="headerlink" title="Character level based LSTM to build word repesetation"></a>Character level based LSTM to build word repesetation</h4><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010171833154.png" class="" title="image-20211010171833154">
<p>不使用卷积，使用bi-LSTM输入字符，输出词语嵌入</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010171929903.png" class="" title="image-20211010171929903">
<h3 id="Hybrid-NMT"><a href="#Hybrid-NMT" class="headerlink" title="Hybrid NMT"></a>Hybrid NMT</h3><p>将两种划分方式区分开</p>
<ul>
<li>主要使用词语层级的划分</li>
<li>使用字符划分作为补充</li>
</ul>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010173107643.png" class="" title="image-20211010173107643">
<h4 id="Fast-Test-Embedding"><a href="#Fast-Test-Embedding" class="headerlink" title="Fast-Test Embedding"></a>Fast-Test Embedding</h4><img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010174250157.png" class="" title="image-20211010174250157">
<p>基于character-level 和 word2vec，改善word2vec获得的词向量对于词典外词语（oov）以及词语的各种变形不适应的情况。</p>
<ul>
<li><p>将单词拆成字符级别的n-gram表示</p>
</li>
<li><p>使用n-grams中所有子词的向量作为词语的向量表示进行嵌入训练</p>
</li>
<li><p>训练完成后，简单求和作为词语的词嵌入形式</p>
<img src="/2021/10/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/cs224n%E7%AC%94%E8%AE%B0/cs224n-9.%E5%AD%90%E8%AF%8D%E6%A8%A1%E5%9E%8B/image-20211010175316928.png" class="" title="image-20211010175316928"></li>
</ul>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>cs224n</tag>
      </tags>
  </entry>
  <entry>
    <title>Subword分词:BPE&amp;word-piece</title>
    <url>/2022/03/27/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/BPE&amp;wordpiece/</url>
    <content><![CDATA[<h2 id="Subword分词-BPE-amp-word-piece"><a href="#Subword分词-BPE-amp-word-piece" class="headerlink" title="Subword分词:BPE&amp;word-piece"></a>Subword分词:BPE&amp;word-piece</h2><p>在读transforme论文时，论文中在两个NMT任务中分别使用了两种编码算法byte pair encoding和word-piece，似乎子词嵌入模型是解决OOV问题不二选择，稍微了解一下</p>
<h3 id="BPE"><a href="#BPE" class="headerlink" title="BPE"></a>BPE</h3><p>为了解决NMT中的OOV问题，基于子词模型（sub-word）以及Byte pair encoding思想提出了BPE算法，解决了词表大小压缩问题</p>
<h4 id="Byte-pair-encoding"><a href="#Byte-pair-encoding" class="headerlink" title="Byte pair encoding"></a>Byte pair encoding</h4><p>一种简单的数据压缩算法，寻找byte串中重复出现多次的byte对(pair of consecutive bytes)，使用串中未出现过的byte替代，直到byte串中不存在重复多次的byte串。</p>
<p>wekipedia的例子：</p>
<span id="more"></span>
<img src="/2022/03/27/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/BPE&wordpiece/image-20220315101051756.png" class="" title="image-20220315101051756">
<p>BPE算法与原Byte pair encoding算法完全一致，只是运行在character层级上，论文中思路主要为</p>
<ul>
<li>初始词表为所有单词拆分的字母+ 特殊的单词结束符（a special end-of word symbol ‘·’）</li>
<li>重复遍历使用频率最高的pair替换<ul>
<li>如  (‘A’, ‘B’) 用  ‘AB’ 替换（一个词替代两个词）</li>
<li>replace each occurrence of the most frequent pair (‘A’, ‘B’) with a new symbol ‘AB’.</li>
</ul>
</li>
<li>重复迭代直到满足要求</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re, collections</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stats</span>(<span class="params">vocab</span>):</span></span><br><span class="line">    pairs = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">for</span> word, freq <span class="keyword">in</span> vocab.items():</span><br><span class="line">        symbols = word.split()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(symbols) - <span class="number">1</span>):</span><br><span class="line">            pairs[symbols[i], symbols[i + <span class="number">1</span>]] += freq</span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_vocab</span>(<span class="params">pair, v_in</span>):</span></span><br><span class="line">    v_out = &#123;&#125;</span><br><span class="line">    bigram = re.escape(<span class="string">&#x27; &#x27;</span>.join(pair))</span><br><span class="line">    p = re.<span class="built_in">compile</span>(<span class="string">r&#x27;(?&lt;!\S)&#x27;</span> + bigram + <span class="string">r&#x27;(?!\S)&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v_in:</span><br><span class="line">        w_out = p.sub(<span class="string">&#x27;&#x27;</span>.join(pair), word)</span><br><span class="line">        v_out[w_out] = v_in[word]</span><br><span class="line">    <span class="keyword">return</span> v_out</span><br><span class="line">vocab = &#123;<span class="string">&#x27;l o w &lt;/w&gt;&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;l o w e r &lt;/w&gt;&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">         <span class="string">&#x27;n e w e s t &lt;/w&gt;&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;w i d e s t &lt;/w&gt;&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line">num_merges = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_merges):</span><br><span class="line">    pairs = get_stats(vocab)</span><br><span class="line">    //寻找出现次数最多的pair对</span><br><span class="line">    best = <span class="built_in">max</span>(pairs, key=pairs.get)</span><br><span class="line">    vocab = merge_vocab(best, vocab)</span><br><span class="line">    <span class="built_in">print</span>(best)</span><br></pre></td></tr></table></figure>
<h4 id="joint-BPE"><a href="#joint-BPE" class="headerlink" title="joint BPE"></a>joint BPE</h4><p>NMT需要输入源语言、输出目标语言，因此需要构建两个分别包括两种语言的词表，论文中提出了两种类型的BPE</p>
<ul>
<li>源语言与目标语言分别运行BPE算法，构建子词词表</li>
<li>源语言与目标语言合并在一起，共建一个BPE词表（joint BPE）</li>
</ul>
<p>两种方法优略</p>
<ol>
<li>第一种方法，确保两种语言词表中都只包含出现过的子词，不会存在另一种语言的子词干扰，保证了词表的大小</li>
<li>第二种方法，确保了基于统计切词在两种语言上运行的一致性，相同的词切分方式保持一致（比如说相同的人名）</li>
</ol>
<p>没细看实验</p>
<img src="/2022/03/27/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/BPE&wordpiece/image-20220315112028772.png" class="" title="image-20220315112028772">
<h3 id="wordpiece"><a href="#wordpiece" class="headerlink" title="wordpiece"></a>wordpiece</h3><p>方法来自于论文：<a href="http://ieeexplore.ieee.org/document/6289079">Japanese and Korean voice search</a>， 该方法的主要思路与BPE基本相同，只是每次不再按照频率的大小选取词对，而是选择能够使得语言模型最大似然增加（increases the likelihood），算法基本流程如下（贪心思路）：</p>
<ol>
<li>首先以字符为单位在语料集上构建词表</li>
<li>使用词表+语料训练一个语言模型</li>
<li>遍历词表，选取字符对（word unit pair）,使用字符对替换的词表+语料再训练一个语言模型，最终选择使得<strong>语言模型最大似然最大</strong>的字符对作为<strong>此轮迭代选择的字符对</strong>，更新词表</li>
<li>重2，3直到词表大小满足预期要求</li>
</ol>
<p>每次迭代都需要遍历整个词表，假设词表大小为k，能够找的 word unit pair 个数为 $k^2$, 也就需要训练 $k^2$ 个语言模型，计算复杂度多得离谱，因此原论文提出了几个加速方法</p>
<ol>
<li><p>每次选择字符对，只选择训练语料中已经存在(字面意思理解就是 在语料中相邻的 word unit)</p>
</li>
<li><p>只选择那些很有可能成为最优字符对的进行比较（不太懂如何判断最有可能）</p>
</li>
<li><p>c和d没太理解</p>
<img src="/2022/03/27/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/BPE&wordpiece/image-20220316085911584.png" class="" title="image-20220316085911584"></li>
</ol>
]]></content>
      <tags>
        <tag>NLP理论</tag>
        <tag>分词算法</tag>
      </tags>
  </entry>
  <entry>
    <title>读论文4-GPT系列</title>
    <url>/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/</url>
    <content><![CDATA[<h2 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h2><p>GPT作为NLP预训练语言模型的基石之一，从gpt1,gpt2到gpt3，不断扩大模型规模，将问题从fine-tuning拓展到zero-shot,试图解决更基础，但是更困难的无监督学习问题，三篇论文中的模型结构相同，不同的是试图解决的问题。</p>
<h3 id="GPT1"><a href="#GPT1" class="headerlink" title="GPT1"></a>GPT1</h3><blockquote>
<p><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></p>
</blockquote>
<h4 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h4><p>NLP中有监督训练数据较少，存在大量的无标签文本数据，如何使用这些数据解决NLP领域中各类问题？GPT提出了 <strong>自监督预训练+fine tuning</strong> 的方式，主要解决两个问题</p>
<ol>
<li>预训练的<strong>训练目标是什么</strong>？损失函数是什么？</li>
<li>预训练得到的特征表示<strong>如何迁移</strong>到下游任务中？</li>
</ol>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>使用语言模型作为预训练的目标，在下游任务上做有监督的fine tuning</p>
<span id="more"></span>
<p><strong>预训练</strong></p>
<p>预训练使用无标签语料作为输入，以语言模型的最大似然函数为训练目标（给定前n-1个token，预测第n个token的条件概率）</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328083725904.png" class="" title="image-20220328083725904">
<p>模型使用transformer-decoder结构，最后一层通过softmax计算预测词的概率</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084046552.png" class="" title="image-20220328084046552">
<p><strong>下游任务-fine tuning</strong></p>
<p>fine-tuning 使用下游任务的有标签语料，增加一个全连接sfotmax输出层，预测对应标签，损失函数为所有训练数据的log最大似然</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084332027.png" class="" title="image-20220328084332027">
<p>另外增加了一个辅助训练目标，在下游任务上训练语言模型，使用两个损失函数求和作为<strong>最终的训练目标</strong>（$\lambda$ 为控制辅助训练目标对结果影响程度的参数）</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084506127.png" class="" title="image-20220328084506127">
<p>针对不任务，仅仅使用softmax预测概率无法满足任务要求（如句子相似度衡量，需要输入两个句子，判断两个句子之间的相似度），gpt针对不同任务设计了不同类型的输入（<strong>Task-specific input transformations</strong>）</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084857519.png" class="" title="image-20220328084857519">
<h4 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h4><p>模型细节</p>
<ol>
<li>12层的transformer-decoder，768隐藏层维度+12注意力头数，去掉了与encoder输出共同计算的注意力层（或者说<strong>使用 masked Multi Self Attention的encoder</strong>）</li>
<li>使用GLUE作为激活函数</li>
<li>使用 bytepair encoding (BPE) 词典，包含4000词</li>
<li>使用<strong>模型学习position encoding</strong>，而不是transformer论文中的三角函数计算</li>
</ol>
<p>训练细节</p>
<ol>
<li>训练数据集为 BooksCorpus dataset（contains over 7,000 unique unpublished books）</li>
<li>预训练：优化器为Adam，最大学习率为 $2.5*10^{-4}$，dropout=0.1，在batchsize=64,seq_length=512的条件下，训练100个epoch</li>
<li>微调：lr = 6.25e-5 , batchsize = 32, dropout = 0.1，训练3个epoch</li>
</ol>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本文主要针对两个问题提出了解决方案，并在不同NLP上验证，得到了不错的效果</p>
<ol>
<li><p>预训练的<strong>训练目标是什么</strong>？</p>
<p>使用<strong>语言模型</strong>作为与训练目标（predict next token）</p>
</li>
<li><p>预训练得到的特征表示<strong>如何迁移</strong>到下游任务中？</p>
<p><strong>Task-specific input transformations + softmax predict层</strong> 在下游任务微调</p>
</li>
</ol>
<h3 id="GPT2"><a href="#GPT2" class="headerlink" title="GPT2"></a>GPT2</h3><blockquote>
<p><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">Language Models are Unsupervised Multitask Learners</a></p>
</blockquote>
<p>在BERT刷榜之后，GPT2带着更大的模型、更多的训练数据卷土重来，不再将关注点聚焦于 预训练+微调，转而研究语言模型在无监督多任务学习上的可能性</p>
<h4 id="要解决的问题-1"><a href="#要解决的问题-1" class="headerlink" title="要解决的问题"></a>要解决的问题</h4><p>论文中提出目前NLP领域主流的 <strong>预训练+微调</strong> 存在问题，即该方法仍需要监督学习，需要下游任务的大量有标签训练数据。本文将NLP的一般任务和特定任务定义为两种条件分布</p>
<ol>
<li>一般任务为 $p(output|input)$ 给定输入，对应输出的条件分布</li>
<li>特定任务  $p(output|input,task)$ 在特定任务上，输出不仅取决于输入，还取决于任务类型</li>
</ol>
<p>传统的预训练+fine-tuning方式</p>
<ol>
<li>预训练即模拟 $p(output|input)$条件分布</li>
<li>fine-tuning 通过在不同任务上<strong>调整模型架构、参数</strong>等，模拟  $p(output|input,task)$条件分布</li>
</ol>
<p>gpt2想要<strong>避免监督学习过程</strong>，即不在下游任务上做微调，引出了两个问题</p>
<ol>
<li>如何预训练能使得预训练过程中学到下游任务的信息？（原文中的句子：<strong>the global minimum of the unsupervised objective</strong><br><strong>is also the global minimum of the supervised objective.</strong> 全局非监督的收敛 等价于 全局监督学习的收敛）<ul>
<li>举个例子：像人学英语一样，背单词+看文章看看多了，就算从来没刷过题，题目也能做得效果不错</li>
</ul>
</li>
<li>如何<strong>不调整模型参数或者架构</strong>，<strong>实现从  $p(output|input)$ 到  $p(output|input,task)$</strong> 转变，以适应下游任务？</li>
</ol>
<h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>基本思路和GPT1区别不大，预训练语言模型+下游任务输入调整，不进行微调训练，个人觉得他的第二章Approach 前面关于理论来源的部分写的非常好，我读完感觉非常科学（也可能是我知识比较薄，看不出问题），分问题阐述一遍</p>
<p><strong>如何预训练能使得预训练过程中学到下游任务的信息</strong></p>
<blockquote>
<p>Preliminary experiments confirmed that sufficiently large <strong>language models are able to perform multitask learning</strong> in this toy-ish setup but learning is much slower than in explicitly supervised approaches.</p>
</blockquote>
<p>从两个角度解决该问题：</p>
<ol>
<li><p><strong>训练具备多任务学习能力的模型</strong>：语言模型 </p>
<ul>
<li>通过论文证明，语言模型具备多任务学习的能力，缺点是训练速度较慢</li>
</ul>
</li>
<li><p><strong>输入包含多任务信息的数据</strong>：WebText 数据集</p>
<ul>
<li><p>本文认为网络文本信息量巨大，包括各种下游任务中需要的数据信息，使用大量网络文本训练，能够使得模型学到不同任务的信息（multi task learning）</p>
</li>
<li><p>本文构造了一个WebText数据集，作者举了一些包含下游任务(NMT)数据的例子</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328101903526.png" class="" title="image-20220328101903526">
</li>
</ul>
</li>
</ol>
<p><strong>如何不调整模型参数或者架构，就能适应下游任务</strong></p>
<p>延续了GPT中的一些思路，通过修改输入表达方式，实现对下游任务的适应，以从英文到法文的机器翻译任务为例，在输入源句子的同时，以”english sentence = french sentence”为条件合并输入模型（文中成为 task hint）</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328143447270.png" class="" title="image-20220328143447270">
<p>在摘要任务中，论文尝试剔除了这种 <strong>”task hint“</strong>，发现任务指标下降了6.4个点，作者认为这证明了 使用自然语言提示模型针对任务改变的可行性</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328143917773.png" class="" title="image-20220328143917773">
<h4 id="顺带探讨的问题"><a href="#顺带探讨的问题" class="headerlink" title="顺带探讨的问题"></a>顺带探讨的问题</h4><p>在研究论文主要问题时，还顺带提了一下<strong>数据污染</strong>问题，即训练数据集和测试数据集之间重叠的问题，作者推荐在构建划分新的NLP数据训练集和测试集时，使用基于n-gram重叠的方法验证是否存在该问题</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328144755337.png" class="" title="image-20220328144755337">
<h4 id="实现细节-1"><a href="#实现细节-1" class="headerlink" title="实现细节"></a>实现细节</h4><p>模型细节</p>
<ol>
<li><p>使用<strong>BPE构建子词字典</strong>，为了避免无意义单词出现（”dog.“,”dog?”），限制不同类型字符共同出现，<strong>字典大小为 50257</strong></p>
</li>
<li><p>将transformer檐式结构结构中的 Post-LN 修改为了 Pre-LN(即把layer normalization移动到每个子层的前面，输入做归一化，输出不做)</p>
<ul>
<li>图片来自 <a href="https://arxiv.org/pdf/2002.04745v2.pdf">On Layer Normalization in the Transformer Architecture</a></li>
</ul>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328151023322.png" class="" title="image-20220328151023322">
</li>
</ol>
<p>训练细节</p>
<ol>
<li><p>batchsize=512，seq_length=1024</p>
</li>
<li><p>共有四个模型大小，最小的和gpt一一致，第二个与bert_large一致，最大的为GPT2</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328151832377.png" class="" title="image-20220328151832377">
</li>
</ol>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>本文使用更大的模型尝试证明语言模型在zero-shot上的可行性，在许多任务上取得不错的成绩。</p>
<h3 id="GPT3"><a href="#GPT3" class="headerlink" title="GPT3"></a>GPT3</h3><p>GPT3是对GPT2在zero shot learning上的进一步推进，GPT2效果没有达到预期，就在GPT3上继续增加模型和训练数据规模，提升效果，在完全预训练模型上继续推广，提出了三种将预训练应用到下游任务的非预训练方式（所谓的 <strong>in-context learning</strong>）</p>
<ol>
<li><p>Few-Shot 解决下游任务时，在输入中提供几个任务样例</p>
<ul>
<li><p>一个任务提示</p>
</li>
<li><p>几个任务样例（prompt）</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154323252.png" class="" title="image-20220329154323252">
</li>
</ul>
</li>
<li><p>One-shot</p>
<ul>
<li><p>只给一个任务提示</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154359207.png" class="" title="image-20220329154359207">
</li>
</ul>
</li>
<li><p>Zero-shot 完全不给任务提示，只告诉任务是什么</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154433953.png" class="" title="image-20220329154433953">
</li>
</ol>
<p>GPT3将模型规模增大到原来的1000倍</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154640571.png" class="" title="image-20220329154640571">
<p>又构建了一个集合以往各种文本数据的巨大数据集</p>
<img src="/2022/04/03/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154729495.png" class="" title="image-20220329154729495">
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>GPT3文章太长，我只粗略地读了一遍，总体思路还是企图证明大规模预训练语言模型，在下游任务中，即使没有经过预训练，也能实现不错的效果，相较于前两篇论文没有太多新的东西</p>
]]></content>
  </entry>
  <entry>
    <title>基于统计的文档语义表示</title>
    <url>/2022/04/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E6%96%87%E6%A1%A3%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA/</url>
    <content><![CDATA[<h2 id="基于统计的文档语义表示"><a href="#基于统计的文档语义表示" class="headerlink" title="基于统计的文档语义表示"></a>基于统计的文档语义表示</h2><p>在深度学习模型到来之前，通常使用统计学方法获得表示的文档语义的特征向量，主要方法包括</p>
<ol>
<li>TF-IDF</li>
<li>基于SVD分解的LSA（潜在语义索引/分析 Latent Semantic Indexing/Analysis）</li>
<li>LDiA 隐形迪利克雷分布</li>
</ol>
<p>其中前两种分布理解较为简单，LDiA涉及比较多的概率分布知识</p>
<h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><p><strong>t</strong>erm <strong>f</strong>requency–<strong>i</strong>nverse <strong>d</strong>ocument <strong>f</strong>requency，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加（TF），但同时会随着它在语料库中出现的频率成反比下降（IDF）</p>
<span id="more"></span>
<p><strong>TF</strong></p>
<p>term frequency，给定一个词，当前词在当前文件出现的频率（通常需要除文档长度），计算公式如下</p>
<script type="math/tex; mode=display">
tf_{ij}= \frac{n_{j}}{n_i}</script><p><strong>IDF</strong></p>
<p>inverse document frequency，给定一个词，IDF值为文档库中总文档数除以包含该词的文档数</p>
<script type="math/tex; mode=display">
idf = log\frac{n_{total}}{n_{contains}}</script><p>将两个值相即为当前文档中该词的TF-IDF值，计算文档在词表上所有词的TF-IDF值，即可获得<strong>相较于词袋向量更加稠密但维度相同</strong>的文档特征向量,TF-IDF作为语义特征向量还存在着一些问题</p>
<ol>
<li>无法解决不同拼写但意思相近的词，TF-IDF计算是会将其看作不同的特征</li>
<li>TF-IDF特征向量的维度还是过大，计算量大且在样本量小（维度与样本数量接近）的时候，容易出现过拟合</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 快速计算TFIDF值，问题是处理不了中文</span></span><br><span class="line">sklearn.feature_extraction.text.TfidfVectorizer</span><br><span class="line"><span class="comment"># 将词频矩阵快速转化为IDF值（中文只能用这个了）</span></span><br><span class="line">sklearn.feature_extraction.text.TfidfTransformer</span><br></pre></td></tr></table></figure>
<h3 id="LSA-潜在语义分析"><a href="#LSA-潜在语义分析" class="headerlink" title="LSA 潜在语义分析"></a>LSA 潜在语义分析</h3><p>LSA实际上就是SVD矩阵分解应用到NLP领域中换的一个名字，结合SVD和PCA对别进行理解</p>
<h4 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h4><p>常用的针对非方阵矩阵的一种分解方法</p>
<img src="/2022/04/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E6%96%87%E6%A1%A3%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA/image-20220411100221445.png" class="" title="image-20220411100221445">
<p>其中矩阵 U和V满足:</p>
<img src="/2022/04/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E6%96%87%E6%A1%A3%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA/image-20220411100348208.png" class="" title="image-20220411100348208">
<p>迁移到NLP领域中,使用截断的SVD分解（取前p大的奇异值）,定义为所谓的<strong>潜在语义主题</strong></p>
<ul>
<li>矩阵$M_{m<em>n}$为 **词 </em>文档** 的特征向量矩阵，每一列均为一篇文档的特征向量</li>
<li>矩阵 $U_{m<em>p}$ 为 **词 </em> 潜在语义主题** 的关系矩阵</li>
<li>矩阵 $V_{n<em>p}$ 为 **文档 </em> 潜在语义主题** 的关系矩阵</li>
</ul>
<p>通过矩阵分解，获得了文档的潜在语义主题表示，实现了<strong>文档特征向量的降维</strong>（从词维度降低到定义的主题维度）</p>
<h4 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a><strong>PCA</strong></h4><p>Principal Component Analysis，从降维的角度出发，发现PCA与SVD都是在做类似于矩阵分解的操作，实现降维的目的。PCA出发点为找到对$X$的一种降维方法$Y=WX$，使得损失的信息量最少，如何实现这个目标？</p>
<ol>
<li>降维后某个特征（或者说维度）的方差最大（组内多样化）</li>
<li>不同特征之间的协方差为0（组间相关性尽量小）</li>
</ol>
<p>根据降维要求和方差大小，舍弃较小方差特征，保留较大方差特征，实现降维。</p>
<ul>
<li>如何转化为数学问题求解？引出了<strong>协方差矩阵</strong>，上述两个目标即为将协方差矩阵相似对角化过程（非对角线元素（协方差）转化为0，对角线元素（方差）转化为特征值）</li>
<li>如何快速找到目标矩阵 $X$ 的协方差矩阵？当$X$不同特征内归一化处理后，$XX^T$即为协方差矩阵</li>
</ul>
<p>最终转化为求解 $XX^T$的特征向量矩阵 $W$</p>
<h4 id="PCA-VS-SVD"><a href="#PCA-VS-SVD" class="headerlink" title="PCA VS SVD"></a>PCA VS SVD</h4><p>经过分析两者均最终转化为了 $XX^T$的特征向量矩阵的求解过程，两者在计算上实际等价，不同点在于</p>
<ol>
<li>PCA目的为降维，SVD目的为分解</li>
<li>PCA只能应用于方阵，SVD均可</li>
<li>PCA需要对数据进行中心化处理</li>
</ol>
<p>sklearn中的PCA实际上就是用SVD方法求解的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 截断SVD</span></span><br><span class="line">sklearn.decomposition.TruncatedSVD([n_components, ...])</span><br><span class="line"><span class="comment"># PCA</span></span><br><span class="line">sklearn.decomposition.PCA([n_components, copy, ...])</span><br><span class="line"><span class="comment"># 增量PCA 解决数量过大内存不足问题的近似PCA</span></span><br><span class="line">sklearn.decomposition.IncrementalPCA([n_components, ...])</span><br><span class="line"><span class="comment"># 稀疏PCA</span></span><br><span class="line">sklearn.decomposition.SparsePCA</span><br></pre></td></tr></table></figure>
<h3 id="LDiA"><a href="#LDiA" class="headerlink" title="LDiA"></a>LDiA</h3><p>Latent Dirichlet allocation 隐含迪利克雷分布，即它认为一篇文档是由一组词构成的一个集合，词与词之间没有顺序以及先后的关系。一篇文档可以包含多个主题，文档中每一个词都由其中的一个主题生成。过程涉及到两个分布关系</p>
<ol>
<li>文档的主题<strong>分布</strong></li>
<li>每个主题的词<strong>分布</strong></li>
</ol>
<p>LDiA假设这两个分布均满足多项式分布，其中多项式参数个数为主题个数和词个数，在此假设下，我们已知<strong>数据+分布</strong>，<strong>如何求出目标分布的参数</strong>？LDiA假设主题分布和词分布的<strong>先验分布均为Dirichlet分布</strong>，即</p>
<img src="/2022/04/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E6%96%87%E6%A1%A3%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA/image-20220411153017543.png" class="" title="image-20220411153017543">
<ol>
<li>文档主题多项式分布参数 $p_1,p_2,p_3….p_n$满足Dirichlet分布（$p_i$ 为某文档中 $topic_i$ 出现的概率）</li>
<li>主题词多项分布 $p_1,p_2,p_3….p_n$满足Dirichlet分布（$p_i$ 即为某主题中 $word_i$ 出现的概率）</li>
</ol>
<p>常用方法有下面两种，不太清楚是否与贝叶斯估计有关系（<strong>不深入了解了，浪费时间也没必要</strong>）</p>
<ol>
<li>EM算法</li>
<li>Gibbs Sampling算法</li>
</ol>
<h4 id="想到了上学期学的贝叶斯估计求未知参数"><a href="#想到了上学期学的贝叶斯估计求未知参数" class="headerlink" title="想到了上学期学的贝叶斯估计求未知参数"></a>想到了上学期学的贝叶斯估计求未知参数</h4><p>我想到了数理统计里的贝叶斯估计，通过先验分布和后验分布，可以得到参数关于样本的概率分布，公式如下(应用数理统计-孙荣恒)</p>
<script type="math/tex; mode=display">
h(y|x_1,...,x_n) = \frac{\pi(y)f(x_1,...,x_n|y)}{g(x1,...,x_n)}\propto\pi(y)f(x_1,...,x_n|y)</script><p>其中 $y$ 后验分布中的未知参数，$\pi(y)$ 为先验分布（LDiA中的Dirichlet分布），$f(x_1,…,x_n|y)$ 为后验分布（LDiA中的多项式分布），得到未知参数关于实验数据（输入文档）的分布后，采取特定方法即可求得未知参数的估计值</p>
<h4 id="简单总结"><a href="#简单总结" class="headerlink" title="简单总结"></a>简单总结</h4><img src="/2022/04/17/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E6%96%87%E6%A1%A3%E8%AF%AD%E4%B9%89%E8%A1%A8%E7%A4%BA/image-20220411154536747.png" class="" title="image-20220411154536747">
<p>根据上述分析，我们可以得到LDA<strong>输入有两个超参数</strong></p>
<ol>
<li><strong>文档-主题</strong>先验Dirichlet分布的参数</li>
<li><strong>主题-词</strong>先验Dirichlet分布的参数</li>
</ol>
<p>LDA实际在求解的参数为</p>
<ol>
<li><strong>文档-主题</strong>多项式分布的参数</li>
<li><strong>主题-词</strong> 多项式分布的参数</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://zh.wikipedia.org/wiki/Tf-idf">tf-idf</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3">奇异值分解</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E9%9A%90%E5%90%AB%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83">隐含狄利克雷分布</a></li>
<li><a href="https://www.cnblogs.com/yifanrensheng/p/13143970.html">NLP-04 隐含狄利克雷分布(LDA)</a></li>
<li>应用数理统计-孙荣恒</li>
</ol>
]]></content>
      <categories>
        <category>ML/DL理论学习</category>
      </categories>
      <tags>
        <tag>NLP理论</tag>
        <tag>LDA</tag>
      </tags>
  </entry>
  <entry>
    <title>搜索算法整理</title>
    <url>/2022/06/08/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h2 id="搜索相关算法"><a href="#搜索相关算法" class="headerlink" title="搜索相关算法"></a>搜索相关算法</h2><p><em>开头废话：最近这几周搞辣鸡项目花了太长时间，好久没写博客了，整理一下这几周写的搜索算法</em></p>
<p>通过枚举遍历问题的解空间，实现问题的求解，搜索作为比较基础的算法问题之一，题目数量众多，问题难度可难可易，希望通过这篇博客的整理能够加深我对目前学习到的相关搜索算法的理解。</p>
<h4 id="主要的算法"><a href="#主要的算法" class="headerlink" title="主要的算法"></a>主要的算法</h4><ol>
<li>DFS 深度优先搜索</li>
<li>BFS 广度优先搜索</li>
<li>双向搜索</li>
<li>Best First Search 最佳优先搜索</li>
<li>迭代加深搜索</li>
<li>其他</li>
</ol>
<h4 id="基础搜索算法"><a href="#基础搜索算法" class="headerlink" title="基础搜索算法"></a>基础搜索算法</h4><p>最简单也是最常用的两个搜索算法（简单总结）</p>
<ol>
<li>深度优先搜索<ul>
<li>每次递归首先尝试向更深的结点走</li>
</ul>
</li>
<li>广度优先搜索<ul>
<li>每次枚举穷尽同一层的所有结点</li>
</ul>
</li>
</ol>
<p>其中深度优先搜索更适合搜索解空间深度与目标解<strong>深度相近</strong>类型问题，广度优先遍历更适合搜索目标解深度<strong>一定程度小于</strong>目标解深度类型问题</p>
<span id="more"></span>
<h3 id="双向搜索"><a href="#双向搜索" class="headerlink" title="双向搜索"></a>双向搜索</h3><p>与普通DFS和BFS不同的点在于，双向搜索同时从两个”方向“开始搜索，这里的方向包括两种形式</p>
<ol>
<li>从初始状态正向搜索+目标状态逆向搜索</li>
<li>将问题划分为两个规模为一半的子问题，分别进行搜索（meet in middle）</li>
</ol>
<p>双向搜索能够使得遍历解空间数量<strong>在幂级上缩小一半</strong></p>
<h4 id="正-逆双向搜索（BFS）"><a href="#正-逆双向搜索（BFS）" class="headerlink" title="正/逆双向搜索（BFS）"></a>正/逆双向搜索（BFS）</h4><p>基于BFS正/逆双向搜索，问题需要满足<strong>目标解已知</strong>，否则无法进行双向搜索，以深度为N的二叉问题为例</p>
<ul>
<li><p>若使用普通的BFS，找到解的BFS深度为N，时间复杂度为O(2^N)</p>
</li>
<li><p>双向bfs每次从初始状态和目标状态遍历深度加一，相当于两个深度为N/2的BFS，时间复杂度为0(2^(N/2))</p>
</li>
</ul>
<p>伪代码模板（自己写的）如下：</p>
<ul>
<li><p>两个访问标记，两个队列</p>
</li>
<li><p>每次训练，正向bfs一层，逆向bfs一层</p>
</li>
<li><p>终止条件：正/逆向bfs过程中，新状态存在于另一个方向的访问标记中；或队列为空</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//主函数每次循环，正向和逆均搜索一层</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; !forwardQue.isEmpty() || !backwardQue.isEmpty(); i++) &#123;</span><br><span class="line">            <span class="comment">//正向搜索一层</span></span><br><span class="line">            <span class="keyword">if</span> (!forwardQue.isEmpty() &amp;&amp; bfs(forwardVisitedMap, backwardVisitedMap, forwardQue, i)) <span class="keyword">return</span>;</span><br><span class="line">            <span class="comment">//逆向搜索一层</span></span><br><span class="line">            <span class="keyword">if</span> (!backwardQue.isEmpty() &amp;&amp; bfs(backwardVisitedMap, forwardVisitedMap, backwardQue, i)) <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//修改终止条件的bfs</span></span><br><span class="line">bfs(forwardVisitedMap, backwardVisitedMap, forwardQue, <span class="keyword">int</span> curDepth) &#123;</span><br><span class="line">        <span class="keyword">int</span> tempSize = forwardQue.size();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; tempSize; j++) &#123;</span><br><span class="line">            curState = forwardQue.poll();</span><br><span class="line">            <span class="comment">//遍历所有子状态</span></span><br><span class="line">            <span class="keyword">for</span>(childState of curState)&#123;</span><br><span class="line">                <span class="comment">//若逆向的map中包含当前状态，说明双向搜索相交，找到最优解</span></span><br><span class="line">                <span class="keyword">if</span>(backwardVisitedMap.contains(childState))&#123;</span><br><span class="line">                    <span class="comment">//记录或者输出解空间</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//否则按照普通的bfs继续执行</span></span><br><span class="line">                <span class="keyword">if</span>(!forwardVisitedMap.contains(childState))&#123;</span><br><span class="line">                    forwardVisitedMap.put(childState， curDepth);</span><br><span class="line">                    forwardQue.offer(childState)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>例题：</p>
<ul>
<li><p><a href="https://www.luogu.com.cn/problem/P1032">P1032 [NOIP2002 提高组] 字串变换</a> BFS VS 双向BFS </p>
<ul>
<li>时间空间复杂度均降低</li>
</ul>
<img src="/2022/06/08/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/image-20220530202815963.png" class="" title="image-20220530202815963">
</li>
</ul>
<h4 id="Meet-in-middle"><a href="#Meet-in-middle" class="headerlink" title="Meet in middle"></a>Meet in middle</h4><p>将规模为N问题，从中间拆分为两个N/2子问题，两个子问题分别进行dfs+状态存储，最后两个状态组合求解，已N个物品的背包问题为例</p>
<ul>
<li>与双向dfs相同，时间复杂度从 O(2^N)降低到0(2^(N/2))</li>
<li>空间复杂度由于要存储中间状态，最坏情况下为0(2^(N/2))</li>
</ul>
<p>这类问题的难点其实在判断直接暴力是否超时</p>
<ul>
<li>一般刷题平台的时间限制是1秒或2秒，<strong>操作次数应该控制在 $10^{7-9} \approx 2^{23-25}$ 左右（按照这个标准进行判断）</strong></li>
</ul>
<p>伪代码模板：</p>
<ul>
<li>另一种解法时前后dfs获得的状态均存下来，最后一块求解（我觉得空间复杂度太大，没用过）</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dfs1</span><span class="params">(depth, status)</span></span>&#123;</span><br><span class="line">     <span class="comment">//到中间停止dfs</span></span><br><span class="line">     <span class="keyword">if</span>(depth == N / <span class="number">2</span>)&#123;</span><br><span class="line">         <span class="comment">//不需要state，只需要value 直接存储在列表</span></span><br><span class="line">         states.add(value)</span><br><span class="line">         <span class="comment">//需要记录状态的数组或者Map中</span></span><br><span class="line">         states[status] = value</span><br><span class="line">         <span class="keyword">return</span>;</span><br><span class="line">     &#125;</span><br><span class="line">new_status = <span class="comment">//根据规则+status确定新的status</span></span><br><span class="line">     dfs1(depth + <span class="number">1</span>, new_status);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dfs2</span><span class="params">(depth, status)</span></span>&#123;</span><br><span class="line">     <span class="comment">//到N国模</span></span><br><span class="line">     <span class="keyword">if</span>(depth == N)&#123;</span><br><span class="line">         <span class="comment">//找到states数组中需要的value+当前dfs结果组成目标解</span></span><br><span class="line">        	<span class="comment">//可能会用到：二分查找</span></span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span>  dfs1(depth + <span class="number">1</span>, new_status);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">     <span class="comment">//首先第一个dfs，求前半部分状态</span></span><br><span class="line">     dfs1(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">     <span class="comment">//第二个dfs求第二部分状态，同时与第一个部分状态组合形成解</span></span><br><span class="line">     dfs2(N/<span class="number">2</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>例题：</p>
<ul>
<li><a href="https://www.acwing.com/problem/content/description/173/">AcWing171. 送礼物</a> <ul>
<li>暴力：$O(2^{46})$  动态规划：$O(46*2^{31}) $  明显超时</li>
<li>双向DFS：$O(2^{23})$</li>
</ul>
</li>
<li><a href="https://www.luogu.com.cn/problem/P3067">P3067 [USACO12OPEN]Balanced Cow Subsets G</a><ul>
<li>暴力：$O(2^{40})$  动态规划：$O(40*2^{18}) $  明显超时，且动态规划方法会超内存</li>
<li>双向DFS：$O(2^{20})$</li>
</ul>
</li>
<li><a href="https://www.luogu.com.cn/problem/P3067">P3067 [USACO12OPEN]Balanced Cow Subsets G</a>（知识点比较全的一道题 <strong>重点！！！</strong>）<ul>
<li>这道题双向DFS：$O(3^{20}) \approx O(10^{9})$</li>
<li>使用二分查找搜索状态会导致时间复杂度增加一个数量级超时，<strong>map存储状态</strong></li>
</ul>
</li>
</ul>
<h3 id="Best-First-Search-最佳优先搜索"><a href="#Best-First-Search-最佳优先搜索" class="headerlink" title="Best First Search 最佳优先搜索"></a>Best First Search 最佳优先搜索</h3><p>最佳优先搜索是一种结合了贪心的搜索思想：如果任意时刻能够近似估计到达目标点的成本，每次选取最底层进行扩展搜索，以降低搜索空间。主要的搜索算法有</p>
<ol>
<li>Greedy/Beam Search<ul>
<li>最简单应用贪心思路到搜索上的算法，每次扩展选择估计成本最低的结点加入到路径中（多个就是beam search）</li>
<li>这种方法简单且暴力，但是存在贪心算法的普遍问题，即可能<strong>无法找到最优解</strong></li>
</ul>
</li>
<li>Dijkstra’s algorithm<ul>
<li>每次选择距离出发点成本最低的点进行扩展</li>
<li>能够保证找到最优解，但是搜索复杂度还是较高（剪枝效率不高）</li>
<li>采用了堆优化的算法<strong>时间复杂度</strong>为 $O(E + V logV)$，空间复杂度为  $O(logV)$（其中 $E$ 为边数，$V$为结点数量）</li>
</ul>
</li>
<li>A* algorithm<ul>
<li>A<em> 算法类似于Dijkstra，只是Dijkstra会获得从出发点到所有目的地的最短路径生成树，A</em>只会找到出发点到目标点的最短路径</li>
</ul>
</li>
</ol>
<h4 id="A-算法"><a href="#A-算法" class="headerlink" title="A*算法"></a>A*算法</h4><blockquote>
<p><a href="https://wikimili.com/en/Peter_E._Hart">Peter Hart</a>, Nils Nilsson and <a href="https://wikimili.com/en/Bertram_Raphael">Bertram Raphael</a> of Stanford Research Institute (now <a href="https://wikimili.com/en/SRI_International">SRI International</a>) first published the algorithm in 1968. <a href="https://wikimili.com/en/A*_search_algorithm#cite_note-nilsson-4">[4]</a> It can be seen as an extension of <a href="https://wikimili.com/en/Dijkstra&#39;s_algorithm">Dijkstra’s algorithm</a>. A* achieves better performance by using <a href="https://wikimili.com/en/Heuristic_(computer_science">heuristics</a>) to guide its search.</p>
</blockquote>
<p>A*算法是对Dijkstra’s algorithm的扩展，A* 定义了特殊形式的函数$f(n)$作为结点优先级的衡量标准</p>
<script type="math/tex; mode=display">
f(n) = g(n) + h(n)</script><p>其中$g(n)$ 为起点到结点n的成本（已知），$h(n)$为结点n到终点成本的估计函数（对未知的估计）-<strong>启发函数</strong></p>
<p><strong>启发函数（<a href="https://wikimili.com/en/Heuristic">heuristic</a> function）</strong></p>
<p>其实仔细看看我们会发现，其实A*算法相较于Dijkstra只是增加了一个启发函数$h(n)$，为什么要添加启发函数？</p>
<ol>
<li>“以史为鉴” $g(n)$ ：从结点到当前节点的成本我是已知的，所以每次选成本最低的可能能找到最优解（Dijkstra）</li>
<li>“最速梯度下降” $h(n)$：如果我能够近似估计从当前结点到目标结点的距离，我肯定要选择估计上更近的点，更可能找到最优解（Greedy Search）</li>
</ol>
<p>所以启发函数的选取对于A*算法极为重要</p>
<ol>
<li>一方面决定剪枝效率</li>
<li>一方面决定能够A*能否找到最优解</li>
</ol>
<p>论文中证明了只要启发函数满足以下两个性质即能满足我们的要求</p>
<ol>
<li><strong>admissible</strong>：$h(x) \leq h^<em>(x)$ 其中 $h^</em>(x)$ 为到目标结点的真实距离，即<strong>到目标结点的估计距离非严格小于实际距离</strong></li>
<li><strong>consistent/monotone</strong>：若存在边$(x, y)$，则 $h(x) ≤ d(x, y) + h(y)$，即当前节点到目标结点的估计距离，小于当前结点到临接结点的距离+临接结点到目标结点的估计距离（可以理解成 <strong>两边之和大于第三边</strong>）</li>
<li>若启发函数满足admissible，则A<em>算法一定能够找到<strong>最优解</strong>；若启发函数满足consistent，则A\</em>算法不会向优先队列中重复添加点（即<strong>单调递增</strong>，后找到点的f(n) 一定小于前找到点），其中consistent性质蕴含admissible，若启发函数具有consistent，其一定满足admissible性质</li>
</ol>
<p>根据wiki百科中的解释简单理解一下两个性质为什么导致结果成立</p>
<ol>
<li>admissible $\rightarrow$ 能够找到最优解：反证法，由于最后一次目标结点进入队列时其 $f(n_{目标}) = g(n_{目标}) + (h(n_{目标}) = 0)$, 其函数值已不包括估计值，假设我们找到非最优解，则存在一条到目标点的路径长度小于A<em>迭代退出时选择的路径，取该路径上的任意一点 $n_{rand}$ ，其启发函数一定满足$f(n_{rand}) = g(n_{rand}) + (h(n_{rand}) &lt; 经过n_{rand}实际路径长 &lt; f(n_{目标}))$，所以优先队列不可能弹出目标结点，A\</em>此次迭代优先队列不可能弹出目标节点。</li>
<li>consistent $\rightarrow$ admissible：随便选一条从出发点到目标点的路径，根据 $h(x) ≤ d(x, y) + h(y)$ 不断的转换不等式: $h(x) ≤ d(x, y) + h(y) \leq d(x, y) + d(y, z) + h(z)…$ 直到不等式转换为$h(x) ≤ d(x, n_{目标})$，推导出admissible</li>
</ol>
<p>常用的启发函数有（别人的博客）</p>
<img src="/2022/06/08/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/image-20220606101813112.png" class="" title="image-20220606101813112">
<p>所以<strong>如何选择启发函数</strong>？</p>
<ol>
<li>首先要满足admissible的性质，保证算法能够找到最优解</li>
<li>其次<strong>启发函数的估计值尽量大</strong>，</li>
<li>极端情况（即$h(x) = h^<em>(x)$）下，A</em>算法转化为 <strong>保证能够找到解的贪心搜索</strong>；若 $h(x) = 0$，A<em>算法转化为 <em>*Dijkstra</em></em>算法</li>
</ol>
<p><strong>复杂度</strong></p>
<ol>
<li>时间复杂度：看不明白证明</li>
<li>空间复杂度：看不明白证明</li>
</ol>
<p><strong>伪代码模板</strong></p>
<p>在Dijkstra改改就是A*（<del>不会写伪代码，网上抄一个</del>）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">* 初始化open_set和close_set；</span><br><span class="line">* 将起点加入open_set中，并设置优先级为<span class="number">0</span>（优先级最高）；</span><br><span class="line">* 如果open_set不为空，则从open_set中选取优先级最高的节点n：</span><br><span class="line">    * 如果节点n为终点，则：</span><br><span class="line">        * 从终点开始逐步追踪parent节点，一直达到起点；</span><br><span class="line">        * 返回找到的结果路径，算法结束；</span><br><span class="line">    * 如果节点n不是终点，则：</span><br><span class="line">        * 将节点n从open_set中删除，并加入close_set中；</span><br><span class="line">        * 遍历节点n所有的邻近节点：</span><br><span class="line">            * 如果邻近节点m在close_set中，则：</span><br><span class="line">                * 跳过，选取下一个邻近节点</span><br><span class="line">            * 如果邻近节点m也不在open_set中，则：</span><br><span class="line">                * 设置节点m的parent为节点n</span><br><span class="line">                * 计算节点m的优先级</span><br><span class="line">                * 将节点m加入open_set中</span><br></pre></td></tr></table></figure>
<h4 id="典型例题"><a href="#典型例题" class="headerlink" title="典型例题"></a>典型例题</h4><ol>
<li><a href="https://www.luogu.com.cn/problem/P1379">P1379 八数码难题</a><ul>
<li>比较了几个不同的启发函数计算方式，确实是启发函数越大，剪枝效果越好</li>
</ul>
</li>
</ol>
<h3 id="迭代加深"><a href="#迭代加深" class="headerlink" title="迭代加深"></a>迭代加深</h3><p>通过限制DFS搜索的深度实现BFS效果，本质上还是DFS搜索，只是每次DFS增加了最大递归深度。</p>
<ul>
<li>当DFS达到最大深度时，即使未找到目标解，也要返回。</li>
<li>若某次深度d的DFS没有找到解，则将迭代深度+1，重新进行DFS搜索。</li>
</ul>
<p>伪代码如下:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> maxDepth = <span class="number">1</span>;maxDepth &lt;= 最大迭代深度；maxDepth++)&#123;</span><br><span class="line">	dfs(<span class="number">0</span>, maxDepth)</span><br><span class="line">&#125;</span><br><span class="line">dfs(depth, maxDepth)&#123;</span><br><span class="line">	<span class="keyword">if</span>(depth == maxDepth)&#123;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	dfs(depth + <span class="number">1</span>, maxDepth)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>迭代加深与BFS的区别在于</p>
<ol>
<li>迭代加深方法通过DFS实现BFS效果，避免了BFS队列对于状态的存储，降低了空间占用</li>
<li>每次增加迭代深度，会导致DFS重复遍历</li>
</ol>
<p>什么时机使用迭代加深？（玄学）</p>
<ul>
<li>当搜索树的分支比较多时，每增加一层的搜索复杂度会出现指数级爆炸式增长，这时前面重复进行的部分所带来的复杂度几乎可以忽略</li>
<li><p>为了避免过量的空间占用，采用迭代加深</p>
</li>
<li><p>题目特征：<strong>限定了搜索深度</strong>，要求找到解没有限定解的类型（<del>遇到这样的题，就嫁了吧</del>）</p>
</li>
</ul>
<h4 id="典型例题-1"><a href="#典型例题-1" class="headerlink" title="典型例题"></a>典型例题</h4><p>单纯的迭代加深方法应用的不多，与A<em>算法结合使用IDA\</em>的比较多</p>
<ol>
<li><a href="https://www.acwing.com/problem/content/172/">170. 加成序列</a><ul>
<li>BFS的<strong>最坏空间复杂度为O(N!)</strong>,当N=100时，对应复杂度能达到 $10^{158}$</li>
<li>迭代加深重复遍历相较于状态个数已经可以忽略不计</li>
</ul>
</li>
</ol>
<h3 id="IDA"><a href="#IDA" class="headerlink" title="IDA*"></a>IDA*</h3><p>迭代加深和A*结合，使用启发函数在dfs过程中减枝，从而实现算法时间复杂度的降低，伪代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> maxDepth = <span class="number">1</span>;maxDepth &lt;= 最大迭代深度；maxDepth++)&#123;</span><br><span class="line">	dfs(<span class="number">0</span>, maxDepth)</span><br><span class="line">&#125;</span><br><span class="line">dfs(depth, maxDepth)&#123;</span><br><span class="line">	<span class="keyword">if</span>(depth == maxDepth)&#123;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//只有在启发函数+当前代价小于最大代价时才继续进行迭代</span></span><br><span class="line">	<span class="keyword">if</span>(depth + h(curStatus) &lt;= maxDepth)</span><br><span class="line">		dfs(depth + <span class="number">1</span>, maxDepth)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>观察代码其实和迭代加深算法区别不大，只是增加了减枝函数，最难的点也就在如何决定这个剪枝函数-<strong>启发函数的选取</strong>，</p>
<h4 id="典型例题-2"><a href="#典型例题-2" class="headerlink" title="典型例题"></a>典型例题</h4><ol>
<li><p><a href="P2324 [SCOI2005]骑士精神">P2324 [SCOI2005]骑士精神</a>， 简单分析一下为什么要用IDA*</p>
<ul>
<li><p>类似于八数码难题，从空位置出发，每次寻找能够移动到</p>
</li>
<li><p>空位置的棋子，该问题每次最多可能有8个位置能够移动到空位置</p>
</li>
<li><p>bfs和迭代加深算法的最坏复杂度为<strong>O(8^15)</strong>（限制了递归深度最大为15），显然超时，且BFS还会出现MLE问题，所以只能尝试IDA*</p>
<img src="/2022/06/08/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/image-20220607170129957.png" class="" title="image-20220607170129957">
</li>
</ul>
</li>
<li><p><a href="https://www.luogu.com.cn/problem/P2534">P2534 [AHOI2012]铁盘整理</a></p>
<ul>
<li>IDA*的模板题目，难点是想出来启发函数，其他倒不难</li>
</ul>
</li>
</ol>
<h3 id="Dancing-Links"><a href="#Dancing-Links" class="headerlink" title="Dancing Links"></a>Dancing Links</h3><blockquote>
<p><a href="https://oi-wiki.org/search/dlx/">OIWIKI:Dancing Links</a></p>
</blockquote>
<p>舞蹈链是为了解决精确覆盖的一种特殊数据结构，精确覆盖问题目前只能通过暴力回溯法的方式实现求解，Dancing links通过链表存储的方式实现了时间和空间复杂度一定程度的降低（难度太大找工作用不到，了解一下，不深入学习，<del>贴张别人的图表示字自己学习过了</del>）</p>
<img src="/2022/06/08/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/image-20220608094659278.png" class="" title="image-20220608094659278">
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>算是把搜索问题的主要解题思路整理学习完毕，搜索问题的难点可以总结为：</p>
<ol>
<li>剪枝：无论是普通的DFS还是A<em>，IDA\</em>算法，实现难度其实都不是很大，最难的点还是在于<strong>找到合适的剪枝函数</strong></li>
<li>时间空间复杂度分析：很多时候问题的方法显而易见，难点反而在选用什么搜索方法才能适应题目的时间空间复杂度要求</li>
<li>问题抽象：如何讲问题转化为搜索问题是比较难的点，很多问题往往即使告诉你要用搜索（比如铁盘整理和骑士精神），我也会想不明白</li>
</ol>
<p>其他没什么可总结的了，其实目前很多算法只能说懂了怎么写，真正的解决相关搜索问题的能力还欠缺，继续努力！！！</p>
<h3 id="相关参考"><a href="#相关参考" class="headerlink" title="相关参考"></a>相关参考</h3><ol>
<li><a href="https://oi-wiki.org/search/">OI WiKi的搜索专题</a></li>
<li><a href="https://www.luogu.com.cn/training/9376">luogu官方搜索题单</a></li>
<li><a href="https://en.wikipedia.org/wiki/A*_search_algorithm">wikipeida A*_search_algorithm</a></li>
<li><a href="https://www.cnblogs.com/grenet/p/3145800.html">博客：跳跃的舞者，舞蹈链（Dancing Links）算法——求解精确覆盖问题</a></li>
<li><a href="https://www.acwing.com/problem/">部分题目：acWing</a></li>
</ol>
]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>如何做研究-第一部分</title>
    <url>/2022/07/13/%E6%9D%82%E6%96%87/%E5%A6%82%E4%BD%95%E5%81%9A%E7%A0%94%E7%A9%B6/%E5%A6%82%E4%BD%95%E5%81%9A%E7%A0%94%E7%A9%B6-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/</url>
    <content><![CDATA[<h2 id="写在开头"><a href="#写在开头" class="headerlink" title="写在开头"></a>写在开头</h2><p><em>开头废话：终于摆脱了没有前途的项目开始写论文了，虽然写论文不一定比做项目更有前途，但是可以预计的是只要我认真干，达到毕业标准是没问题的，而我目前对于实验室工作的目标就是满足毕业要求，所以说捋起袖子，加油干吧。正好李沐出了这个如何搞研究的视频，我也跟着学一学，不止为了写论文，更多的是从写论文这个经历里，为未来工作中各种报告文档的书写留下一点可用的经验。</em></p>
<p>跟着李沐的课程学习搞研究的基本概念，主要的学习资料有</p>
<ol>
<li>李沐的<a href="https://www.bilibili.com/video/BV1hY411T7vy">研究的艺术B站视频</a></li>
<li>研究的艺术中文版第四版</li>
</ol>
<p>计划是先自己读一遍中文书的对应章节，再去看李沐的视频，加深印象，下面是第一部分内容。</p>
<h2 id="研究、研究人员、读者"><a href="#研究、研究人员、读者" class="headerlink" title="研究、研究人员、读者"></a>研究、研究人员、读者</h2><h3 id="什么是研究"><a href="#什么是研究" class="headerlink" title="什么是研究"></a>什么是研究</h3><p>什么是研究？</p>
<ul>
<li><p>为了回答/解决某个问题搜集信息就是研究</p>
</li>
<li><p>日常生活中我们经常有类似的场景（例如百度小米的CEO是谁），只是我们并不会把这个过程规范化，结论文档化</p>
</li>
</ul>
<p>为什么要把研究内容写下来？</p>
<ul>
<li>为了方便记忆（俗话说得好：好记性不如烂笔头）</li>
<li>为了增进对于研究内容的理解。在梳理论据，描述论点的过程中，会加深自己对于相关内容的理解</li>
<li>为了检验自己的思想。只说是无法证明自己思想的正确性，写在纸上，通过论据论述，数学公式的证明，为自己的思想进行强有力的证明</li>
</ul>
<span id="more"></span>
<p>为什么写论文要遵循格式？</p>
<ul>
<li>写作不仅是为了自己，更是为了交流分享，你遵循外在的语言和格式要求，其实是在摆脱自己的主观愿望，使自己的思想向外界方便理解、更加真实的形式转变。（为了适应外界而改变自己，才能够好的理解自己的思想）</li>
<li>论文的格式是在长期实践中形成的，格式存在有其存在合理性（便于作者与读者联系起来，方便阅读等等）</li>
<li>用程序员的思路理解就是<strong>内容要满足通信格式才能在网络上发送和传播</strong></li>
</ul>
<p><strong>总结</strong></p>
<ul>
<li><strong>研究就是为了问题找答案</strong>，而这个寻找过程和答案本身需要<strong>通过规范的格式记录下来</strong></li>
<li>以规范格式记录研究的过程，也就是思考研究本身的过程，这个思考不仅是从<strong>自身的角度</strong>（能否解决问题），更是从<strong>读者的角度</strong>（研究是否有价值、论文是否容易理解和阅读）</li>
</ul>
<h3 id="与读者建立联系"><a href="#与读者建立联系" class="headerlink" title="与读者建立联系"></a>与读者建立联系</h3><p>撰写论文的过程中我们首先要确定我们自身的角色和预期读者的角色，才能确保我们的论文表达方式的正确的，有读者惯性感兴趣的。</p>
<h4 id="确定自己的角色"><a href="#确定自己的角色" class="headerlink" title="确定自己的角色"></a>确定自己的角色</h4><p>研究的过程不是你让你的老师知道你了解很多的事实，学会了很多的方法，应该是告诉老师问题是什么，方法的意义是什么，解决问题的效果如何，和其他方法相比有什么优略，从提供事实的角度自己可以分为三个角色</p>
<ol>
<li>找到了有趣的新信息 -<strong>提供关于问题的信息</strong><ul>
<li>职责：搜集信息</li>
<li>角色任务是陈列相关信息</li>
<li>撰写文档：尽可能全面的展示我搜集到的相关信息</li>
<li>eg: b站上的分享视频（我吃了什么，玩了什么）</li>
</ul>
</li>
<li>解决了重要的实际问题（作报告）-<strong>解决问题</strong><ul>
<li>职责：帮助决策者知道如何解决问题</li>
<li>角色任务是展示解决问题的方案、证明方案的正确性</li>
<li>撰写文档：使用合适的专业词汇，引用正确的信息，找到合适的证据，并以合适的方式表达，以达到说服决策者的目的</li>
<li>eg：csdn上各种代码bug的解决方案的博客</li>
</ul>
</li>
<li>给一个重要的问题找到了答案（<strong>做研究</strong>）-<strong>增进对问题的理解</strong><ul>
<li>职责：更好的理解问题+解决方案</li>
<li>角色任务是分析问题+阐述答案</li>
<li>撰写文档：阐明研究问题+研究方案</li>
</ul>
</li>
</ol>
<p>写作</p>
<h4 id="确定读者的角色"><a href="#确定读者的角色" class="headerlink" title="确定读者的角色"></a>确定读者的角色</h4><blockquote>
<p>读者是谁，读者读到这里知道什么了，接下来他们想要知道什么</p>
</blockquote>
<ol>
<li>图一乐，只是为了了解一下相关信息</li>
<li>希望通过读论文得到解决问题的方案</li>
<li>系统通过读论文对问题得到更深的理解</li>
</ol>
]]></content>
      <categories>
        <category>科研相关</category>
      </categories>
      <tags>
        <tag>杂文</tag>
        <tag>论文写作</tag>
      </tags>
  </entry>
  <entry>
    <title>如何做研究-第二部分</title>
    <url>/2022/07/13/%E6%9D%82%E6%96%87/%E5%A6%82%E4%BD%95%E5%81%9A%E7%A0%94%E7%A9%B6/%E5%A6%82%E4%BD%95%E5%81%9A%E7%A0%94%E7%A9%B6-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/</url>
    <content><![CDATA[<h2 id="第二部分-提问题，找答案"><a href="#第二部分-提问题，找答案" class="headerlink" title="第二部分 提问题，找答案"></a>第二部分 提问题，找答案</h2><p>这一部分主要提供如何从兴趣、专业领域中寻找研究问题，并寻找问题答案过程的建议和方法论。</p>
<h3 id="从话题到问题"><a href="#从话题到问题" class="headerlink" title="从话题到问题"></a>从话题到问题</h3><p>从感兴趣的话题领域到具体的研究问题是一个从大到小的过程</p>
<ul>
<li>话题是广泛的，往往涵盖大量的信息和资料，沉浸在一个话题中搜索查找相关信息，虽然能够搜集大量的信息，然而这些信息大部分往往是没有任何用途的，因为缺乏重点，在读者眼里可能仅仅是堆放在一起的事实。</li>
<li>问题是从话题中产生的，根植于话题的。一个好的问题的好的答案答案能够在一定程度上推进整个领域往前发展</li>
</ul>
<p>然而疑问（question）并不等于问题（problem）</p>
<ul>
<li>一个好的问题是具有实际价值的”疑问“，解答这个问题能给我们带来一些东西（eg：解决某个工程难题，提升程序运行效率等等）</li>
<li>通过问我们自己:”不解决这个问题会怎样’’来区分区分疑问和问题的方式，如果答案是”不会怎么样 so what?”，那么这个问题就<strong>不应该成为我们的研究问题</strong></li>
</ul>
<span id="more"></span>
<h4 id="话题"><a href="#话题" class="headerlink" title="话题"></a>话题</h4><p>在专业背景下从兴趣出发得到自己的话题</p>
<ul>
<li>书上讲的很虚，似乎是没什么方法论，还是要多看相关文献，结合自身的研究背景和兴趣</li>
<li>从我目前的角度来说，我并不需要自己找问题，把老师给的问题解决掉即可（不需要独立做研究）</li>
</ul>
<p>话题从宽到窄</p>
<ul>
<li>话题是研究的出发点，然而如果话题过于宽泛，研究相关资料需要耗费大量精力，很难有相关发现。</li>
<li>通过将话题转化为论点，并通过增加修饰词缩小话题限定范围<ul>
<li>托尔斯泰的自由意志-&gt;托尔斯泰的小说中有自由意志（变成论点）-&gt;托尔斯泰在战争与和平中描写了三次战役中自由意志与必然性之间的冲突</li>
<li>数据中心节能-&gt;数据中心需要节能-&gt;数据中心大量服务器运转消耗大量能量，如何通过优化算法降低能量消耗？（似乎不太贴切）</li>
</ul>
</li>
</ul>
<p>带着问题查阅话题相关资料，如果不是学习目的，而是研究目的，最好带着问题查阅相关资料，这样在查阅资料过程中才会更有针对性，不会陷入无头苍蝇式的无效查询。</p>
<p>从话题到问题，书中提出的三个步骤</p>
<ol>
<li>确定话题，并为话题确定一个名字<ul>
<li>我想了解/研究 xxx</li>
</ul>
</li>
<li>提出问题和间接疑问<ul>
<li>我想了解/研究，因为我想知道xxx</li>
</ul>
</li>
<li>问自己 “so what“<ul>
<li>解决这个问题有什么价值？不解决对别人来说有什么损失？</li>
</ul>
</li>
</ol>
<p>最终目的还是要<strong>找到一个有实际价值的能够解决的问题</strong></p>
<h4 id="寻找问题的意义"><a href="#寻找问题的意义" class="headerlink" title="寻找问题的意义"></a>寻找问题的意义</h4><p>研究问题主要分为两类：</p>
<ol>
<li><strong>实际问题</strong>：这类问题来源于现实中的某种情况（垃圾邮件、数据中心耗能），这种状况使得我们损失金钱、时间等等，解决这个问题能够为现实生活带来实际的改变</li>
<li><strong>观念问题</strong>：这类问题来源于我们对于世界认知的不完全性，当我们不理解现实中某些事物或者与预期想象不符时，就产生了一个观念问题，解决观念问题不能为现实带来实际的成果，更多的作用是完善我们的认知和观念。</li>
</ol>
<p>无论是哪类研究问题，均满足以下问题的结构：</p>
<ol>
<li>一种情况</li>
<li>这种情况导致的不良后果（这种后果往往是读者关心的），不良后果也就决定着研究问题意义</li>
</ol>
<p>实际问题与观念问题的<strong>主要区别</strong>就在于这种“不良后果”，</p>
<ol>
<li>实际问题的”不良后果”是不解决问题所带来的代价（如不解决数据中心节能问题，会带来大量能量浪费）</li>
<li><p>观念问题的“不良后果”是缺乏对某些问题的正确认知或者只是，导致无法回答另外一个更加重要的问题</p>
<ul>
<li>无法回答 数据中心节能的边界条件-&gt;我们就无法回答使用什么方法能够降低数据中心能耗</li>
</ul>
<p>实际研究问题的意义容易通过实际后果确定，然而<strong>如何确定观念问题的研究意义</strong>（或者说让读者觉得有意义）？</p>
</li>
</ol>
<ul>
<li><p>从初始的研究问题出发，引到更大更重要的问题（研究在中国历史中台湾与大陆的关系变迁-&gt;中国外交水平如何随着历史变迁）</p>
</li>
<li><p>将研究问题与实际问题联系起来（研究在中国历史中台湾与大陆的关系变迁-&gt;解决两岸同胞存在的认同问题）</p>
</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>从兴趣到研究话题再到研究问题是一个复杂的上升过程，在这个过程中我们能做的</p>
<ol>
<li>在开展研究之前，首先要想好研究的意义，不仅是对自己，更是对于读者</li>
<li>研究问题的获得是困难的，没有具体的方法论，需要不断地学习和实践</li>
</ol>
<p><img src="C:\Users\79351\OneDrive\桌面\正在写的文档\如何做研究-第二部分.assets\image-20220703095118304.png" alt="image-20220703095118304"></p>
<h3 id="从问题到资料"><a href="#从问题到资料" class="headerlink" title="从问题到资料"></a>从问题到资料</h3><p>书中说到的方法不太适合理工科资料查找，基本的资料查找方式：</p>
<ul>
<li>寻找研究类似问题的论文，向上找这些论文的引用，向下找引用这些论文的论文</li>
<li>在这些论文中找到较为关键的论文（与研究问题相关度较高的论文）</li>
</ul>
<p>如何评估论文的好坏：</p>
<ul>
<li>引用数量、所属会议和期刊的排名、论文发表时间</li>
<li>与自身研究问题联系密切程度</li>
</ul>
]]></content>
      <categories>
        <category>科研相关</category>
      </categories>
      <tags>
        <tag>杂文</tag>
        <tag>论文写作</tag>
      </tags>
  </entry>
  <entry>
    <title>线段树整理</title>
    <url>/2022/07/13/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E7%BA%BF%E6%AE%B5%E6%A0%91%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<h2 id="线段树总结"><a href="#线段树总结" class="headerlink" title="线段树总结"></a>线段树总结</h2><p>学完树状数组，很难控制住自己不学线段树，线段树是一种可以在$O(logN)$ 时间复杂度内实现区间和单点操作的数据结构：</p>
<ol>
<li>单点修改/查询</li>
<li>区间修改/查询</li>
</ol>
<p>与树状数组的区别在于：树状数组只能执行 单点修改+区间查询 或 区间修改+单点查询 。线段树能够均能支持，但是复杂度的常数系数显著大于树状数组（ps:能用树状数组就用树状数组）</p>
<span id="more"></span>
<p><strong>线段树从何而来？<del>我的简单理解</del></strong></p>
<ol>
<li>对于区间修改和区间查询，最朴素的思想就是遍历区间元素逐个修改，然而朴素的复杂度是我们无法接受的，所以我们如何改进？自然而然想到通过空间换时间的想法，通过提前存储要修改查询的“区间”，降低修改和查询的复杂度。由此我们确定了要<strong>“存区间”</strong></li>
<li>然而如何 <strong>“存区间”</strong>？每次查询和修改的区间左端点和右端点都是任意的，不可能把所有可能的左右端点组成形成的区间存下来，根据区间之间的重叠性质，我们能够想到：既然无法存储所有的区间，不如存储一定数量不重叠的区间，只要这些区间能够拼接出所有的目标区间即可，问题就变成了怎么<strong>拆分区间</strong>？</li>
<li>如何<strong>设计存储的现成区间</strong>？每次寻找给定一个区间，寻找已经存储的现成区间进行拼接，我们的目标自然而然是 <strong>拆分的次数越少越少</strong>（最好是我直接存了这个区间），这个<strong>拆分次数</strong>最少，自然而然想到，对 最大区间进行二分拆分，以树的形式进行存储，这样拆分次数最坏就是存储树的高度（<del>这一步逻辑还是有点问题</del>）</li>
<li>最终我们得到了线段树这一个存储结构</li>
</ol>
<h3 id="线段树定义"><a href="#线段树定义" class="headerlink" title="线段树定义"></a>线段树定义</h3><p>如下图所示，线段树每个结点对应一个区间，每个长度不为1的区间的结点包括两个子节点（划分为两个子区间），叶子节点为长度为1的区间。</p>
<ul>
<li>每个结点维护区间信息，例如区间和、最值等</li>
<li>通过递归修改查询等可以快速实现区间操作</li>
<li>线段树每次分裂两个子节点区间长度缩小两倍，所以线段树理想情况下为完全二叉树，普通情况下为近似完全二叉树，所以即可以使用树的方式存储，也可使用完全二叉树数组形式村存储</li>
</ul>
<img src="/2022/07/13/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E7%BA%BF%E6%AE%B5%E6%A0%91%E6%95%B4%E7%90%86/image-20220625113233442.png" class="" title="image-20220625113233442">
<h4 id="建树"><a href="#建树" class="headerlink" title="建树"></a>建树</h4><p><strong>建树</strong>代码如下：</p>
<ul>
<li><p>时间复杂度和线段树结点个数,空间复杂度为栈深度</p>
</li>
<li><p>空间复杂度： $log_2n$</p>
</li>
<li>时间复杂度： $2^{log_2{n} + 1} - 1 \approx 4 n$ (若使用二叉树数组存储，空间直接开4 * n)</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">buildTree</span><span class="params">(<span class="keyword">int</span> curPos, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span>[] aimArray)</span></span>&#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 建立线段树（区间和）</span></span><br><span class="line"><span class="comment">     * 1. 空间复杂度：o(4 * N)</span></span><br><span class="line"><span class="comment">     * 2. 时间复杂度：o(4 * N)</span></span><br><span class="line"><span class="comment">    * */</span></span><br><span class="line">    <span class="keyword">if</span>(left == right)&#123;</span><br><span class="line">        <span class="comment">//当前区间长度为1，叶子节点</span></span><br><span class="line">        heapArray[heapPos] = aimArray[left];</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> mid = left + (right - left) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="comment">//区间分裂，左节点+右节点</span></span><br><span class="line">    buildTree(curPos * <span class="number">2</span>, left, mid, aimArray);</span><br><span class="line">    buildTree(curPos * <span class="number">2</span> + <span class="number">1</span>, mid + <span class="number">1</span>, right, aimArray);</span><br><span class="line">    <span class="comment">//当前区间和等于两个子区间和求和</span></span><br><span class="line">    heapArray[curPos] = heapArray[curPos * <span class="number">2</span>] + heapArray[curPos * <span class="number">2</span> + <span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h4><p><strong>更新</strong>代码如下：</p>
<ul>
<li>若每次更新修改所有包含当前结点的区间，时间复杂度将远超目标复杂度，在实现过程中引入了”懒标记”</li>
<li>当修改某个结点时，不递归修改当前结点的孩子节点，而是将当前结点的”懒标记”，在下次修改或者查询涉及到当前节点，再进行“修改”（这里的修改时特殊的修改，即修改孩子结点，并将懒标记下推到孩子结点）- <strong>pushdown</strong></li>
<li>通过“懒标记”确保了，更新的<strong>时间复杂度为O(logN)</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">pushDown</span><span class="params">(<span class="keyword">int</span> heapPos, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(lazyLabel[heapPos] != <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">int</span> mid = left + ((right - left) &gt;&gt; <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//首先将积累的更新修改到孩子节点</span></span><br><span class="line">        heapArray[heapPos * <span class="number">2</span>] += (mid - left + <span class="number">1</span>) * lazyLabel[heapPos];</span><br><span class="line">        heapArray[heapPos * <span class="number">2</span> + <span class="number">1</span>] += (right - (mid + <span class="number">1</span>) + <span class="number">1</span>) * lazyLabel[heapPos];</span><br><span class="line">        <span class="comment">//孩子结点记录&quot;懒标签&quot;,下一次遍历到孩子结点继续下推</span></span><br><span class="line">        <span class="keyword">if</span>(mid != left)&#123;</span><br><span class="line">            lazyLabel[heapPos * <span class="number">2</span>] += lazyLabel[heapPos];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(mid + <span class="number">1</span> != right)&#123;</span><br><span class="line">            lazyLabel[heapPos * <span class="number">2</span> + <span class="number">1</span>] += lazyLabel[heapPos];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//清除当前结点的&quot;懒标签&quot;</span></span><br><span class="line">    lazyLabel[heapPos] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(<span class="keyword">int</span> heapPos, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span> leftRange, <span class="keyword">int</span> rightRange, <span class="keyword">int</span> value)</span></span>&#123;</span><br><span class="line">    <span class="comment">//当更新范围大于当前范围时，直接修改，并记录懒标记</span></span><br><span class="line">    <span class="keyword">if</span>(leftRange &lt;= left &amp;&amp; rightRange &gt;= right)&#123;</span><br><span class="line">        heapArray[heapPos] += (right - left + <span class="number">1</span>) * value;</span><br><span class="line">        <span class="comment">//叶子节点不标记</span></span><br><span class="line">        <span class="keyword">if</span>(right - left != <span class="number">0</span>)&#123;</span><br><span class="line">            lazyLabel[heapPos] += value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">//下推（</span></span><br><span class="line">        pushDown(heapPos, left, right);</span><br><span class="line">        <span class="comment">//向下更新</span></span><br><span class="line">        <span class="keyword">int</span> mid = left + ((right - left) &gt;&gt; <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//左节点区间交叉</span></span><br><span class="line">        <span class="keyword">if</span>(mid &gt;= leftRange)&#123;</span><br><span class="line">            update(heapPos * <span class="number">2</span>, left, mid, leftRange, rightRange, value);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//右节点区间交叉</span></span><br><span class="line">        <span class="keyword">if</span>(mid &lt;= rightRange)&#123;</span><br><span class="line">            update(heapPos * <span class="number">2</span> + <span class="number">1</span>, mid + <span class="number">1</span>, right, leftRange, rightRange, value);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//更新当前区间值</span></span><br><span class="line">        heapArray[heapPos] = heapArray[heapPos * <span class="number">2</span>] + heapArray[heapPos * <span class="number">2</span> + <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><p><strong>查询</strong>代码如下：</p>
<ul>
<li>会写更新就会写查询，而且查询比更新还要简单</li>
<li><strong>时间复杂度为O(logN)</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">query</span><span class="params">(<span class="keyword">int</span> heapPos, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span> leftRange, <span class="keyword">int</span> rightRange)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(leftRange &lt;= left &amp;&amp; rightRange &gt;= right)&#123;</span><br><span class="line">        <span class="keyword">return</span> heapArray[heapPos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//首先pushDown</span></span><br><span class="line">    pushDown(heapPos, left, right);</span><br><span class="line">    <span class="comment">//区间拆分</span></span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> mid = left + ((right - left) &gt;&gt; <span class="number">1</span>);</span><br><span class="line">    <span class="comment">//与左节点区间有交叉</span></span><br><span class="line">    <span class="keyword">if</span>(mid &gt;= leftRange)&#123;</span><br><span class="line">        result += query(heapPos * <span class="number">2</span>, left, mid, leftRange, rightRange);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//与右节点区间有交叉</span></span><br><span class="line">    <span class="keyword">if</span>(mid &lt; rightRange)&#123;</span><br><span class="line">        result += query(heapPos * <span class="number">2</span>, mid + <span class="number">1</span>, right, leftRange, rightRange);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="线段树例题"><a href="#线段树例题" class="headerlink" title="线段树例题"></a>线段树例题</h3><p>套模板</p>
<ol>
<li><a href="https://www.luogu.com.cn/problem/P2357">洛谷 P2357 守墓人</a> 状态为和</li>
<li><a href="https://www.luogu.com.cn/problem/P3870">洛谷 P3870 [TJOI2009] 开关</a> 状态为值为1的个数</li>
<li><a href="https://www.luogu.com.cn/problem/P3373">洛谷 P3373 【模板】线段树 2</a> 两种区间修改操作<ul>
<li>难点在于 lazylabel的设计</li>
</ul>
</li>
</ol>
<p>特殊区间状态</p>
<ol>
<li><p><a href="https://leetcode.cn/problems/the-skyline-problem/">lc 218. 天际线问题</a> 每个区间代表<strong>线段</strong>（不再是离散的点）</p>
<ul>
<li><p>扫描线+线段树，这里每个区间不再是每个点的集合，而是真正的线段</p>
<ol>
<li><p>建树修改，<strong>左区间的右端点与右区间的左端点相同</strong>（线段一分为二，不再是点一分为二）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="comment">//区间分裂，左节点+右节点</span></span><br><span class="line">buildTree(curPos * <span class="number">2</span>, left, mid, aimArray);</span><br><span class="line">buildTree(curPos * <span class="number">2</span> + <span class="number">1</span>, mid, right, aimArray);</span><br></pre></td></tr></table></figure>
</li>
<li><p>更新/查询修改，去掉了等号（线段相交，端点重合不叫线段相交）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(mid &gt; leftRange)&#123;</span><br><span class="line">    update(heapPos * <span class="number">2</span>, left, mid, leftRange, rightRange, value);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//右节点区间交叉</span></span><br><span class="line"><span class="keyword">if</span>(mid &lt; rightRange)&#123;</span><br><span class="line">    update(heapPos * <span class="number">2</span> + <span class="number">1</span>, mid, right, leftRange, rightRange, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><p>好玩的一点，这个题目<strong>不需要pushdown</strong>（因为查询只查根节点不需要pushdown，且lazylabel记录覆盖次数无法pushdown）</p>
</li>
</ul>
</li>
<li><p><a href="https://www.luogu.com.cn/problem/P2003">P2003 [CRCI2007-2008] PLATFORME 平板</a></p>
<ul>
<li>与上一道题类似，更简单，都是存储<strong>线段</strong></li>
</ul>
</li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://oi-wiki.org/ds/seg/">OIWIKI 线段树</a></li>
<li><a href="https://baike.baidu.com/item/%E7%BA%BF%E6%AE%B5%E6%A0%91/10983506?fr=aladdin">百度百科：线段树</a></li>
<li><a href="https://www.luogu.com.cn/training/3079">洛谷：线段树模板题</a></li>
</ol>
]]></content>
      <categories>
        <category>算法整理</category>
      </categories>
      <tags>
        <tag>线段树算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Frangipani分布式文件系统</title>
    <url>/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Frangipani%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="Frangipani-分布式文件系统"><a href="#Frangipani-分布式文件系统" class="headerlink" title="Frangipani 分布式文件系统"></a>Frangipani 分布式文件系统</h2><blockquote>
<p><a href="https://dl.acm.org/doi/10.1145/269005.266694">Frangipani: A Scalable Distributed File System</a></p>
</blockquote>
<p>Frangipani是20多年前发表论文中描述的一个分布式文件系统，之所以现在还要深度了解一篇这个“古老”的论文，是因为其中的一些设计思路值得我们学习和研究（<del>不还是因为MIT6.824里要讲吗</del>），Frangipani的设计出发点是要实现一个简单、方便扩展和管理的共享文件系统，在读论文时主要关注的点如下：</p>
<ol>
<li>如何在分布式环境下实现缓存一致性？</li>
<li>如何实现分布式事务？</li>
<li>如何在经常出错的分布式环境中，通过错误恢复实现容错？、</li>
</ol>
<span id="more"></span>
<h3 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h3><p>如下图所示，Frangipani的架构组成分为两层：</p>
<ol>
<li>Frangipani文件系统层（Frangipani file server module）：运行在操作系统kernel中，向kernel注册为一个文件系统实现，为上层的用于应用程序提供提供文件系统的操作接口</li>
<li>Petal 虚拟磁盘层（Petal virutal disk）：为了方便扩展，Frangipani底层基于虚拟磁盘Petal，简化了磁盘管理、扩容等操作</li>
</ol>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Frangipani%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/image-20220712154753633.png" class="" title="image-20220712154753633">
<p>整个系统中共有一下几种不同身份职责的运行进程：</p>
<ol>
<li>Petal server：Petal底层采用多个server+多块磁盘实现大容量分布式容错的虚拟磁盘，Petal server可以理解为接收磁盘操作请求、执行持久化操作的存储服务器</li>
<li>Lock server：文件系统肯定离不开锁，其中lock server用来管理文件系统中的锁（multiple reader/singlewriter lock）。锁由多个lock server分别进行管理，每个lock server管理整个文件系统中部分锁。</li>
<li>Clerk module：每个file server上运行的锁管理进程，用来维护和管理分配给当前file server的锁信息（申请、释放、锁降级等）</li>
<li>Frangipani file server：提供文件系统操作接口，与Petal server交互实现数据操作。</li>
<li>Petal device driver：隐藏petal的细节，使上层file server看起来就是一个大容量磁盘</li>
</ol>
<p>不同身份职责进程的实际部署情况：</p>
<ol>
<li>Pertal server: 运行于实际的存储节点上，多个server共同提供一个 <strong>large, scalable, fault tolerant</strong>的虚拟磁盘</li>
<li>Lock server：可以运行于Pertal server上，也可以运行于Frangipani file server，数量并不是与Pertal server一一对应的</li>
<li>Frangipani file server：运行于任意服务器上，不同的Frangipani file server是等价的，均为用户提供整个文件系统的读取和修改权限</li>
</ol>
<h3 id="文件系统结构"><a href="#文件系统结构" class="headerlink" title="文件系统结构"></a>文件系统结构</h3><p>Frangipani的文件系统结构如下图所示，和Unix的文件系统结构类似，均采用Inode+文件块的形式管理文件存储空间，由于Frangipani底层基于虚拟磁盘（优点是具备更大的可分配空间，缺点是虚拟磁盘上相邻的空间段可能分布于不同server上的磁盘），其对文件系统进行了更细致化的定义和管理。</p>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Frangipani%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/image-20220712161534127.png" class="" title="image-20220712161534127">
<p>Frangipani将虚拟磁盘空间划分为了6个逻辑块</p>
<ol>
<li>参数块（parameters 0-1T）：存储共享配置信息以及文件系统管理信息，实际上只能用到几kb的空间</li>
<li>存储日志块（logs 1-2T）：将1T的空间等大小划分为256块，其中每一块（$2^{40}$bytes）属于一个file server的日志存储区（<u>ps:日志是什么在下一部分进行介绍</u>），每个日志存储区可以存储256个日志，即每一条日志最大空间为（$2^{16}$bytes）。</li>
<li>分配bitmap块（Allocation bitmaps 2-5T）：用来表示剩余的空间块是否为被占用</li>
<li>Inodes块（Inodes 5-6T）：和unix文件系统中的inode功能相同，都是用来记录文件的元数据，每个inode大小与磁盘块大小保持一致512B（避免争抢情况），inode块与bitmap块的对应关系固定，即特定的bitmap永远标识指定的inode。(一方面释放文件是只需要释放bitmap，另一方面方便锁管理)</li>
<li>小块区（Small blocks 6-134T）：每块大小4 KB ($2^12$ bytes)，用来存储大小小于64kb的文件，当文件大小大于64KB时，剩余文件记录存储在大块区中</li>
<li>大块区（Large bolcks 136-$2^{34}$T）：每块大小为1T</li>
</ol>
<p>Frangipani在虚拟磁盘划分时，采用了大量的固定大小分块思想，这样必然会导致内存碎片问题（fragmentation），论文中表示将小文件数据直接存储在inode上，能够缓解这种问题（<del>存疑</del>）</p>
<p>另外Frangipani文件系统还有几个小的trick</p>
<ol>
<li>只有真正的写入虚拟空间时，才会真正的分配实际的物理存储空间</li>
<li>论文中说块的大小都是可调整的，Logs中日志存储区数量也是可调整的（<del>为了掩盖设计不完善，画的饼吧</del>）</li>
</ol>
<h3 id="基于log的持久化保证"><a href="#基于log的持久化保证" class="headerlink" title="基于log的持久化保证"></a>基于log的持久化保证</h3><p>Frangipani采用类似于WAL（write ahead log）日志机制，实现元数据（metadata）的容错，具体实现如下</p>
<ol>
<li>每个对于元数据的操作，首先创建一个相关日志写入到file server本地缓存中</li>
<li>日志周期性的将日志缓存持久化到petal磁盘上（即上面的logs），每个file server有自己单独的log存储区（论文中描述同样支持实时同步，即生成日志立刻持久化到petal磁盘上）</li>
<li>只有在日志持久化以后，才会真正的修改对应的metadata（<del>论文里没有说什么时候向客户端响应修改成功或者说修改对客户端可见？我觉得是修改缓存成功后，因为论文中说持久化的周期时30S，如果在持久化以后延迟太高</del>）</li>
<li>对于用户数据（修改文件内容等），Frangipani不通过日志管理，即<strong>不保证持久性</strong></li>
</ol>
<p>随着时间的的增长，log的数量会越来越多，如何解决log的空间占用/不足问题？</p>
<ul>
<li>Frangipani将Petal磁盘上的log存储区管理为环状存储（circular buffer），当log空间不足，删除最老的25%的日志（老日志确保大部分均已提交，并且在踢出日志时，Frangipani会检查未提交日志，执行完毕再踢出存储）</li>
<li>在两次从内存写入Petal磁盘上的刷新间隔中，最多允许1000-1600个对于元数据的操作</li>
</ul>
<h3 id="基于锁的一致性保证"><a href="#基于锁的一致性保证" class="headerlink" title="基于锁的一致性保证"></a>基于锁的一致性保证</h3><p>既然是文件系统就离不开锁，Frangipani提供了写锁和读写锁（multiplereader/singlewriterlocks）分布式锁实现，以实现文件系统的中的并发控制，从而保证数据一致性，基本实现机制如下：</p>
<ol>
<li>多个lock server+lock clerk模式：每个lock server管理一部分的锁，每个file server对应一个lock clerk，负责管理当前server的锁以及与lock server进行交互</li>
<li>其中锁以64位整数命名，每个lock server上的锁组织在一个以ASCII字符命名的table中</li>
<li>为了避免file server进程意外退出导致<strong>无限期占有锁</strong>，lock server分配锁时带有<strong>lease identifier</strong>（超时时间为30S），client必须在超时之前向lock server更新lease</li>
<li>为了避免死锁，Frangipani为整个文件系统中的锁分配了<strong>全局编号</strong>，client获取锁之前首先要确定需要的所有锁，之后<strong>按照编号顺序从小到大获取</strong>，失败则释放已经占有的锁，从头开始从新获取。（<strong>分布式事务</strong>）</li>
</ol>
<p>补充一条：Frangipani的锁是<strong>sticky</strong>的，即client会一直持有锁，直到另外一个client申请锁</p>
<p>lock server和lock clerk相关的锁操作包括：</p>
<ul>
<li>request：clerk向server发送的申请锁的请求</li>
<li>grant：server向clerk发送的授予锁的响应</li>
<li>revoke：server向clerk发送的撤销锁的请求</li>
<li>release：clerk向server发送的释放锁</li>
<li>另外以上四个操作，能够实现锁的升级和降级操作</li>
</ul>
<p><strong>如何保证一致性</strong></p>
<p>锁通过控制并发实现一致性控制，实际上就是<strong>dirty cache刷新时机和锁重分配之间的协调关系</strong>，当某个client在持有锁的过程中对数据进行了修改，此时要发生锁权限的变更，根据不同情况需要进行不同处理：</p>
<ol>
<li>当前client持有读/读写锁，因为争抢要释放：首先要将dirty cache持久化到petal磁盘中，并将cache标记为无效（等待垃圾回收），最后再释放锁</li>
<li>当前client持有写锁，要降级为读写锁共享锁（只读不写）：首先要将dirty cache持久化到petal磁盘中，锁降级。此时并不需要invalidate cache，因为另外的client也是读，并不会修改数据</li>
</ol>
<p>另个一角度理解（<strong>锁在缓存在，锁亡缓存亡</strong>-锁代表独占权，独占权保证了）：</p>
<ul>
<li>拥有数据的缓存，同时肯定拥有锁（如果是dirty cache，则拥有写锁）</li>
<li>当server释放锁，同时要释放锁对应的缓存段</li>
</ul>
<p>通过上述机制，即可保证Fragipani元数据的持久性和一致性</p>
<h3 id="容错和恢复（fault-tolerant-amp-recovery）"><a href="#容错和恢复（fault-tolerant-amp-recovery）" class="headerlink" title="容错和恢复（fault-tolerant &amp; recovery）"></a>容错和恢复（fault-tolerant &amp; recovery）</h3><p>容错和恢复是拆不开的两个话题，一般分布式系统中通过多server实现容错，当一个server崩溃其他server能够继续正常运行，恢复纸崩溃server恢复重新提供服务的过程，两者共同保证了分布式系统的高可用性质。由于Frangipani存在多种不同身份职责的进程，因此存在多种情况下的容错和恢复。</p>
<h4 id="Lock-server"><a href="#Lock-server" class="headerlink" title="Lock server"></a>Lock server</h4><p>lock server可以看作一系列地位对等的p2p节点，相互直接之间通hearteart消息，监控状态。通过公式算法（Paxos）实现对于元数据的管理和一致性保证。</p>
<ul>
<li>元数据包括locker server列表，每个server负责管理的锁</li>
<li>当lock server失效或者新的lock server加入时，lock会在不同节点间进行均匀分配，保证负载均衡</li>
</ul>
<p>当一个lock server失效时，他所持有的锁以及对映锁状态会重新分配到其他lock server上。lock server恢复即直接作为新的lock server加入server群即可</p>
<h4 id="File-server"><a href="#File-server" class="headerlink" title="File server"></a>File server</h4><p>虽然Frangipani中存在多个file server，然而每个server只为其挂载在unix系统提供服务，当file server崩溃时，唯一的容错措施即在重启file server(<del>看起来不是那么的分布式，或者可以理解为文件系统接口层实际上还是单机</del>)。</p>
<p>虽然只能通过重启进行file server的容错和恢复，在file server崩溃时，需要执行一系列操作以保证数据的一致性，因为当前file server可能存在未持久化的修改、占有锁资源等，具体机制如下：</p>
<ol>
<li><p>当client/lock server长期收不到file server响应时，即认为file server失效</p>
</li>
<li><p>当认定file server失效后，启动 recovery demon，获得失效server的log和lock,根据log重新执行未执行的更新，完成之后释放锁资源</p>
<blockquote>
<p>the changes to a block are applied only,if the block version number is less than the record version number.</p>
<p>通过数据的version number判断是否需要重新执行log记录的操作</p>
</blockquote>
</li>
</ol>
<p>上述机制中，即使是由于网络分区问题导致的无法联系到file server，file server由于无法更新相关锁的lease，即没有权限操作数据，<strong>不会出现“脑裂”问题</strong></p>
<h4 id="Petal-server"><a href="#Petal-server" class="headerlink" title="Petal server"></a>Petal server</h4><p>Frangipani实际上是偷懒了，由于Petal本身支持容错和恢复，所以存储层可以认识是可靠的</p>
<h3 id="备份（Backup）"><a href="#备份（Backup）" class="headerlink" title="备份（Backup）"></a>备份（Backup）</h3><blockquote>
<p><strong>Copy-on-write</strong>：sometimes referred to as <strong>implicit sharing</strong><a href="https://en.wikipedia.org/wiki/Copy-on-write#cite_note-1">[1]</a> or <strong>shadowing</strong>,<a href="https://en.wikipedia.org/wiki/Copy-on-write#cite_note-2">[2]</a> is a resource-management technique used in <a href="https://en.wikipedia.org/wiki/Computer_programming">computer programming</a> to efficiently implement a “duplicate” or “copy” operation on modifiable resources. - wikipedia</p>
<p>对于Copy-on-write，实际上可以简单理解为为了避免写阻塞读，写在副本上写，读此时在原数据上读，写完将副本更新到原数据上</p>
</blockquote>
<p>在Petal的Copy-on-wirte机制上加了一点微调，实现了自己的备份机制（备份启动不需要recovery过程）</p>
<ul>
<li>采用了barrier同步机制，使用一个全局锁作为barrier</li>
<li>file server执行任何修改之前，必须获得这个共享全局锁</li>
<li>当备份进程要执行时，向所有持有全局锁的file server申请释放，file server释放之前首先将dirty cache持久化，并释放其他锁后进入barrier</li>
<li>当所有file server进入barrier后，备份进程获得全局锁，开始备份，备份完成其他file server退出barrier</li>
</ul>
<p>显而易见的缺点是当系统备份时，整个系统只读不能写</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>读完这篇论文发现其中很多设计还是很落后的（file server假分布式等），也存在很多未解决的问题（写请求发送过程中锁超时等），然而其中比较值得学习的就是其锁的管理和缓存一致性的实现。</p>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>分布式文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title>AmazonAurora云数据库</title>
    <url>/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/AmazonAurora%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h2 id="Amazon-Aurora-云端分布式数据库"><a href="#Amazon-Aurora-云端分布式数据库" class="headerlink" title="Amazon Aurora 云端分布式数据库"></a>Amazon Aurora 云端分布式数据库</h2><blockquote>
<p>论文: <a href="https://dl.acm.org/doi/epdf/10.1145/3035918.3056101">Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Database</a></p>
</blockquote>
<p>Amazon Aurora是亚马逊从2014年开始提供的一种云上关系型数据库架构，基于mysql的基础上改进而来，在实现传统关系型数据库特性的基础上，实现了事务吞吐量、错误恢复等性能巨大提升。</p>
<h3 id="Amazon-Aurora到来之前"><a href="#Amazon-Aurora到来之前" class="headerlink" title="Amazon Aurora到来之前"></a>Amazon Aurora到来之前</h3><p>要理解Amazon Aurora的设计原理，首先要了解一般数据库的事务执行流程；传统单机事务型数据库数据一般以B-Tree形式组织存储在硬盘上，并在内存中存储数据的缓存以加速访问/修改过程。以写事务流程为例，<strong>一般的事务执行过程</strong>如下：</p>
<ol>
<li>首先锁定要想修改的数据，防止其他事务修改</li>
<li>在WAL（Write-ahead-log）中写入当前事务日志项</li>
<li>根据操作修改缓存中的数据项<ul>
<li>修改前镜像+修改日志+修改后进行</li>
</ul>
</li>
<li>提交事务，等待特定的时机(缓存区满等)，再将缓存持久化到磁盘中</li>
</ol>
<span id="more"></span>
<p>之所以采用WAL的形式，是因为写入磁盘的成本过高，通过追加形式写入WAL降低了提交事务的成本，再合适的时机再将修改持久化到磁盘中。</p>
<ul>
<li>另外通过多次修改合并，再一次将缓存持久化到磁盘，降低了磁盘读取写入的速度</li>
<li>MySQL通过redo、undo log实现了WAL的机制，最终实现了事务的原子性和持久化</li>
</ul>
<h4 id="为什么会有Aurora"><a href="#为什么会有Aurora" class="headerlink" title="为什么会有Aurora"></a>为什么会有Aurora</h4><p>论文中首先分析了在使用Aurora之前，Amazon云服务提供的基于MySQL的云上关系数据库服务存在的问题，基本架构如下图所示：</p>
<ul>
<li>每个数据库实例采用主从备份形式，分为主实例和从实例。负责存储数据的EBS（Amazon弹性块存储单元，我就理解为一个逻辑上的存储服务器），都带有一个镜像EBS，备份主EBS上的数据。</li>
<li>每当数据修改，首先在主服务上进行提交即执行1操作后，再被备份到从服务上即执行3操作</li>
</ul>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/AmazonAurora%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220710151104545.png" class="" title="image-20220710151104545">
<p>上述架构存在的问题，导致了Aurora的出现</p>
<ol>
<li><strong>写放大问题</strong>。写入涉及到大量数据，包括redo log、binaray log、修改的数据页、临时的double-write以及FRM元数据等，另外由于操作1-&gt;3-&gt;5必须顺序执行，增加了写入的延时。</li>
<li><strong>备份需要通过网络传输修改涉及到的数据，数据传输量过大</strong></li>
</ol>
<h3 id="相关概念和名词定义"><a href="#相关概念和名词定义" class="headerlink" title="相关概念和名词定义"></a>相关概念和名词定义</h3><p><strong>Availability Zone（AZ）</strong></p>
<p>服务器可用区。定义为一系列具有“区域”临近关系的服务器节点集合（可以理解为一个数据中心内的服务器节点）</p>
<ul>
<li>一个AZ内的节点被认为是既有错误相关性的，存在AZ内所有服务器因为某种原因宕机的情况（例如：网络中断、洪水、网络升级、软件部署等）</li>
<li>不同AZ之间通过低延迟网络连接，对于上述类型错误具有隔离性（例如:东部的服务器中心停电了，西部的没问题正常工作）</li>
<li>如磁盘错误、服务器过热宕机等等这里不具有相关性的导致服务器宕机的错误，在不同AZ内部普遍存在</li>
</ul>
<p><strong>Data Segment</strong></p>
<p>将数据库中的数据划分为固定大小（10G）的数据段，数据段是错误和恢复的最小单元</p>
<p><strong>Protection Groups (PGs)</strong></p>
<p>每个Data Segment在Amazon Aurora中共存储6份，这6份数据组成当前数据段的Protection Groups，存储在三个AZ上</p>
<p><strong>storage volume</strong></p>
<p>存储卷是一系列Protection Groups的组合，存储在大量的存储节点上，对外接口表现为一个使用带有存储的EC2的虚拟主机（我理解的对外看起来就是一个磁盘“卷”，屏蔽了底层多个节点分布式存储的细节），通过不断地增加PG，可以增加存储卷的大小（目前支持到64 TB）</p>
<h3 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h3><p>如果要在经常出错的分布式环境中构建一套可靠的关系型数据库服务，持久性和数据一致性是我们首先要满足的基本需求。另一方面之舍弃单机/主从架构转向分布式，也是从性能的角度出发，期望兼具分布式系统的高性能和高可用特征。针对上述问题，Amazon Aurora提出了主要三个方面的设计思想</p>
<ol>
<li>Offloading Redo Processing to Storage：只传输log，不传输数据本身，存储节点在接收到log后，执行操作实现数据变更，从而降低了网络IO负担</li>
<li>Replication and Correlated Failures：使用多副本+quorum机制，保证持久性+多副本下的数据一致性</li>
<li>Segmented Storage：通过对数据划分，实现快速错误恢复</li>
</ol>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/AmazonAurora%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220710155140778.png" class="" title="image-20220710155140778">
<h4 id="传输日志"><a href="#传输日志" class="headerlink" title="传输日志"></a>传输日志</h4><p>Aurora中不同副本存储节点之间数据同步并不直接传输数据，只通过网络传输redo log，由存储节点在接收到日志后，在内存中按照日志操作进行变更，基本流程如下：</p>
<ol>
<li>主实例收到写操作，将redo持久化到本地，向6个副本节点发送redo log</li>
<li>存储节点接收到redo log持久化到本地，在内存中按照日志操作进行变更</li>
<li>主实例接收到多数派应答后，认为日志被持久化</li>
<li>通过链式复制（chain replication），两外两个AZ中的从实例进行日志备份同步</li>
</ol>
<p>存储节点内存的持久化（写入磁盘），会在特定的时机（缓存满等）进行，同样会将多个修改合并为一次磁盘写入。</p>
<ul>
<li>Aurora设计原则上保证后台处理与前台处理负相关（优先满足前台请求，与传统数据库不同），写入磁盘实际上就是后台处理</li>
</ul>
<p>通过传输日志，相较于上文中的mysql主从复制架构中传输数据，实现了性能35倍的提升（事务处理速度）</p>
<blockquote>
<p>The results of our experiment are summarized in Table 1. Over the 30-minute period, Aurora was able to sustain 35 times more transactions than mirrored MySQL.</p>
</blockquote>
<h4 id="多副本-quorum"><a href="#多副本-quorum" class="headerlink" title="多副本+quorum"></a>多副本+quorum</h4><p>如上图所示，Aurora中每个数据段存储6个副本，每两个副本存储在一个AZ中，多副本在读取和的写入时就涉及到了共识问题</p>
<ul>
<li>确保写入的数据在下次读取中能够读到；假设写入需要W个节点的确认，读取需要R个节点的确认，当 W + R &gt; N(副本节点数量)时，保证读取一定能够读到之前的写入。</li>
<li>Aurora中有6个副本，设定W=4、R=3，即W + R = 7 &gt; 6</li>
</ul>
<p>通过以上设置，Aurora实现了读和写不同程度的容错</p>
<ol>
<li><strong>写操作</strong>：最低可保证在一个AZ失效，或者两个不同AZ节点失效时可正常写入</li>
<li><strong>读操作</strong>：保证AZ+1，即一个AZ失效+一个节点失效的情况下可以读到所有写入的数据</li>
</ol>
<h4 id="数据分块"><a href="#数据分块" class="headerlink" title="数据分块"></a>数据分块</h4><p>数据分块主要从错误恢复的角度出发，其中论文定义列两个概念</p>
<ol>
<li>MTTR（Mean Time to Repair）平均错误修复时间。当一部分数据失效时，我们需要花费一定时间恢复数据，使得副本恢复到失效前状态</li>
<li>MTTF（Mean Time to Failure ）平均错误时间。即系统错误出现的时间间隔</li>
</ol>
<p>论文中认为MTTF时难以改变的，只有通过减少MTTR，使得在错误修复过程中尽量的避免另外的错误发生</p>
<ul>
<li>数据块一旦失效，需要从其他副本传输获得失效的数据，此时数据大小和网络IO是决定MTTR的主要因素</li>
<li>因此Aurora通过将数据分块，降低数据块的大小，从而降低MTTR</li>
</ul>
<p>论文中列举的数据是10G的数据块通过10Gbps的网络需要花费十秒完成错误恢复</p>
<blockquote>
<p>A 10GB segment can be repaired in 10 seconds on a 10Gbps network link.</p>
</blockquote>
<h3 id="如何保证日志持久性和一致性"><a href="#如何保证日志持久性和一致性" class="headerlink" title="如何保证日志持久性和一致性"></a>如何保证日志持久性和一致性</h3><p>按照上文中描述qurorum模型，由于不同副本节点log接收的情况不同，可能存在不同存储节点缺失不同数量的log情况，当单个存储节点失效或者数据库系统失效时(即主实例)，如何保证日志持久性和一致性，也就相当于保证了数据库的持久性和一致性，不难想到肯定是<strong>给log进行编号</strong>。</p>
<ul>
<li>数据库系统主实例会为每个事务的log添加一个原子递增的编号：<strong>Log Sequence Number (LSN)</strong></li>
<li>主实例维护一个特殊的编号 <strong>VDL or the Volume Durable LSN</strong>，我理解时当前数据库提交的（已经认为持久化的）最大的LSN</li>
<li>不同副本节点会定时与同一个PG中的其他节点进行通信，根据LSN同步自己缺失的log</li>
</ul>
<p>当系统<strong>重启</strong>时，主实例会与存储节点进行通信（qurorum 读），确定当前PG的持久化点（VCL），然后发送命令通知所有的存储节点，截断LSN大于VCL的日志。</p>
<p>当<strong>单个节点失效重新上线</strong>时，需要进行状态同步，即将未执行的log在数据副本的基础上进行重放</p>
<ul>
<li>Aurora则将重放的过程放到了数据存储节点，完全后台化操作。即使故障发生时正在处理100K TPS，也能在10秒内恢复</li>
</ul>
<p>另外Aurora将事务进行更细粒度的划分-mini transection:</p>
<ol>
<li>每个数据库层的事务会被划分为多个 <em>mini</em> 事务，这些事务是有序的，并且被原子地执行</li>
<li>每个 <em>mini</em> 事务由多个连续的日志记录组成</li>
<li><em>mini</em> 事务的最后一个日志记录就是一个 <em>CPL</em> （不是所有的mini事务都能提交，只有CPL才能提交）</li>
</ol>
<p>mini事务+CPL使得每条日志提交，变成了每个事务最后一个mini事务的日志提交（细中带粗）</p>
<h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><blockquote>
<p>In Aurora, background processing has negative correlation with foreground processing.</p>
</blockquote>
<p>正如上文中所描述的，Aurora的设计出发点之一就是要保证前台操作的高吞吐，所有的后台操作的优先级都是低于前台操作，在这个基础上去理解实现细节，稍微有条理一些</p>
<h4 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h4><p>在遵循quorum机制的基础上，添加了以下实现细节</p>
<ol>
<li>每当主实例写入log收到存储节点的多数派响应后，增加VDL（相当于记录当前PG的log提交进度）</li>
<li>LSN Allocation Limit (LAL)：限定当前分配的LSN不能超过VDL一定的数量（接收的请求不能超过提交过多），以避免写入请求接受速度远远大于数据库写入速度。通过LSN约束，反向降低了接收请求的数量</li>
<li>Segment Complete LSN（SCL）：每个数据段只能看到影响自己的log,每个log中包含一个backlink，用来标记当前log在PG中的前一个log。这个反向连接在节点之间相互通信时用来确定自己缺失的log。</li>
</ol>
<p>在日志写入提交时，并不时满足提交条件即立即提交（asynchronously）</p>
<ul>
<li>处理当前事务的线程将待提交记录添加到在一个单独的事务队列（COMMIT LSN）中等待被确认提交。</li>
<li>当 <em>VDL</em> 不断的增加，数据库找到哪些事务等待被确认，用一个单独的线程给等待的客户端返回事务完成的确认。</li>
<li>属于是 事务处理线程只管先扔到队列里然后继续处理其他事务，由另一个线程专精队列中事务提交+响应 （<del>~没看明白这么做有什么意义</del>）</li>
</ul>
<h4 id="读操作-副本"><a href="#读操作-副本" class="headerlink" title="读操作 + 副本"></a>读操作 + 副本</h4><p>首先介绍一下传统数据库中的读操作：</p>
<ol>
<li>首先寻找缓存中是否存在当前读操作命中的缓存页</li>
<li>如果没有，需要从磁盘加载到内存中</li>
<li>如果缓存满了，需要将缓存中的某些页换出，如果换出的页是脏页（dirty page）,则需要持久化到磁盘上</li>
</ol>
<p>上述机制就导致了读操作可能会引发数据库的持久化写操作，这与Aurora的<strong>前台操作（读操作）与后台操作（持久化）操作负相关</strong>的原则是不符的，理想的方式是：前台读操作不引发缓存持久化，由系统在后台根据前台请求负载周期性（特定条件触发）进行持久化操作。</p>
<p>针对以上问题，Aurora修改了缓存页踢出机制</p>
<ul>
<li>Aurora在缓存踢出是不会进行缓存持久化，而是简单的踢出</li>
<li>只有LSN版本号大于等于VDL的缓存数据页才会被踢出，该性质保证<ol>
<li>所有页面的修改均已持久化在log中</li>
<li>如果缓存失效，可以通过获取最新页来构造当前<em>VDL</em> 所对应的页面。（难道说是：磁盘加载+日志重放）</li>
</ol>
</li>
</ul>
<p>Aurora的读取不需要通过quorum机制实现</p>
<ol>
<li>当从盘里面读一个页的时候，数据库建一个读取点，代表请求发生时的 <em>VDL</em></li>
<li>数据库选择一个带有当前VDL最新修改的数据页节点，返回给读取请求</li>
</ol>
<h4 id="持久化时机"><a href="#持久化时机" class="headerlink" title="持久化时机"></a>持久化时机</h4><p>Aurora不通过缓存踢出持久化，如何实现修改的持久化？实际上还是基于日志的持久化操作</p>
<ol>
<li>数据库系统首先从所有未完成的读取记录中，获得读取数据版本的最小LSN，即之后的所有读取都是在LSN操作发生后进行读取的</li>
<li>通过合并最小LSN之前的日志项并将对应修改的数据页持久化到数据库中，从而实现日志的垃圾回收和修改的持久化</li>
</ol>
<h3 id="实现架构"><a href="#实现架构" class="headerlink" title="实现架构"></a>实现架构</h3><ol>
<li><p>数据引擎是魔改MySQL得到的，论文中说法是：<em>fork of “community” MySQL/InnoDB</em>，支持与MySQL相同级别的写隔离</p>
</li>
<li><p>每个数据库集群包括一个主读写实例和多个只读实例，不同实例之间通过RDS VPC(Amazon Virtual Private Cloud)通信，通过RDS(Amazon Relational Database Service)管理主从实例</p>
</li>
<li><p>存储节点部署在 <em>EC2</em> 虚拟机上，通过SSD存储日志和持久化数据，不同存储节点之间通过Storage VPC通信</p>
</li>
<li><p>并使用<em>Amazon DynamoDB</em>在S3备份存储节点元数据，在节点失效时进行恢复操作</p>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/AmazonAurora%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220711104512699.png" class="" title="image-20220711104512699">
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>基本上算是理解Aurora的设计思路和实现原理，但是由于数据库知识缺失的比较多，所以很多知识点和设计出发点理解的不是很深入，不是很理解为什么要用某些设计、某个设计为什么能起到效果，等进一步学习数据库知识后，再回看可能会由理解上的进步。</p>
<p>从Aurora的设计思路和设计出发点，我觉得可以总结几条经验（就是说点废话）</p>
<ol>
<li>问题来自生产实际，Aurora许多设计思想实际上都是来自于具体的业务需求，有需求才有改进的方向，闭门造车哪来的问题？</li>
<li>要做分布式还得是再真正的云环境下。每天学学课本，在一两台机器上跑跑实验，是真的很难切实感受到分布式理论中所要解决的内些问题，因为在小吞吐量下，类似问题根本就不会出现，而从未遇到并解决这些问题，又怎么能说自己精通分布式原理？（想表达的意思：工作还是要找大厂，遇到实际问题并解决，才是真的能力提升，小厂连业务量都不够，哪能遇到问题？）</li>
<li>大的progress往往是修修补补的积累。可以参考Aurora的实现，无非是在amazon已有的技术的基础上，进行拼装修改组合+新思路，才最终实现了一个成熟的系统。研究生阶段很多项目、很多研究上来就是做个什么高大上的东西出来，然而并没有先前的积累我能做出来什么？要么是借学长东风，要么是找现成的方案拼凑，这样能做出来有价值的工作嘛？我觉得并不行。简而言之，就是<strong>培养积累的过程缺失，很难做出有价值的工作</strong></li>
</ol>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>分布式数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>GFS论文总结</title>
    <url>/2022/04/17/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/GFS%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h3><blockquote>
<p>论文地址：<a href="https://research.google/pubs/pub51/">The Google File System</a></p>
</blockquote>
<p>google file system，入门大数据必读三篇文章之一，最近懒得看视频，小研究一波这篇论文，读完发现这种系统论文要比人工智能论文难读一些，涉及的技术比较多，粗浅的总结一下。</p>
<h4 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h4><p><del>论文结构有点像我的毕业论文</del>，首先从系统的结构出发，描述系统架构、组成等,从静态角度了解系统组成，然后从动态系统交互出发，描述系统交互，主要数据和操作流，最后单独两章描述mater节点的主要职责以及系统如何实现fault tolerance.</p>
<ol>
<li><p>intro 介绍</p>
<p>没讲很多背景，直接讲GFS这套解决方案与以往的GFS不同点，解决不同问题：</p>
<ol>
<li>分布式系统中组件经常失效（norm rather than exception）</li>
<li>按照以往的标准，目前文件大小都很大</li>
<li>目前对文件操作主要是添加和顺序读</li>
<li>面向应用设计GFS，增加了整个系统的灵活性</li>
</ol>
</li>
<li><p>DESIGN OVERVIEW </p>
<p>系统的组成+一致性模型，基本讲明白了系统怎么实现的文件系统功能</p>
</li>
<li><p>SYSTEM INTERACTIONS</p>
<p>描述了系统与client读写文件的交互流程，在这过程中如何保证GFS特性（从使用的角度，描述系统）</p>
</li>
<li><p>MASTER OPERATION</p>
<p>阐述master节点的职责，client与GFS交互中不直接相关的操作（从管理的角度）</p>
</li>
<li><p>FAULT TOLERANCE AND DIAGNOSIS</p>
<p>阐述容错机制（从策略角度）</p>
</li>
<li><p>MEASUREMENTS + EXPERIENCES + RELATED WORK + CONCLUSIONS</p>
<p>实验验证+经验总结+相关工作+总结</p>
</li>
</ol>
<span id="more"></span>
<h4 id="前提假设"><a href="#前提假设" class="headerlink" title="前提假设"></a>前提假设</h4><p>论文中说了GFS的设计是<strong>文件系统API</strong>和<strong>服务于应用</strong>的co-designing（需求来源于生活）， 对其解决的问题做了一定的假设和限定：</p>
<ol>
<li>分布式系统构建于便宜、容易出错的硬件上</li>
<li>系统存储一定数量的大文件（GB级别）</li>
<li>系统将要面临的读操作主要为大量的顺序读和少量随机读</li>
<li>系统面临的写操作主要为大量顺序添加操作，但也支持随机写</li>
<li>系统必须高效支持多客户端并发append写操作</li>
<li>重要性：高带宽&gt;低延时</li>
</ol>
<p>从前提假设中，我们就能得到GFS设计目标中的重点</p>
<ol>
<li><strong>重点</strong>：为<strong>多客户端</strong>的<strong>大文件存储</strong>以及<strong>顺序读+追加写</strong>提供<strong>高稳定高带宽</strong>服务</li>
<li><strong>相对而言不重要的</strong>（系统支持，但不一定效率高）：随机读+随机写+低延时</li>
</ol>
<h4 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h4><p>单管理节点（master）+多存储节点（chunk server）+多客户端（client）架构</p>
<ol>
<li>master节点职责<ul>
<li><strong>管理文件系统的元数据</strong>，包括访问控制信息，文件命名空间，文件到存储块的映射，存储块到存储节点的映射</li>
<li><strong>进行系统管理活动</strong>，包括存储块释放，垃圾回收，不同存储节点上存储块的迁移、复制，定时获取chunk server状态</li>
</ul>
</li>
<li>chunk server节点职责<ul>
<li>存储文件存储块（chunk）</li>
<li>通过HeartBeat消息，告知master节点自身状态</li>
<li>与client进行文件操作交互</li>
</ul>
</li>
<li>client主要操作<ul>
<li>与master节点进行元数据操作（获取文件存储的chunkserver等）</li>
<li>与chunk server进行文件操作（文件实际读写）</li>
</ul>
</li>
</ol>
<img src="/2022/04/17/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/GFS%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220413194306905.png" class="" title="image-20220413194306905">
<h4 id="几个主要概念"><a href="#几个主要概念" class="headerlink" title="几个主要概念"></a>几个主要概念</h4><h5 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h5><blockquote>
<p>The master stores three major types of metadata: the file and chunk namespaces, the mapping from files to chunks, and the locations of each chunk’s replicas</p>
</blockquote>
<p>文件系统的元数据，存储在master节点的<strong>内存中</strong>（论文里不断强调这一点，为了方便master扫描，执行一些列管理操作，主要包括三种类型</p>
<ol>
<li>文件和文件块的命名空间信息（前缀压缩减少空间占用）</li>
<li>文件到文件块的映射</li>
<li>文件块的存储位置<ul>
<li>master节点在每次启动时，向chunk server请求其拥有的chunk信息，初始化文件块存储位置信息</li>
<li>并通过不断的Heatbeat Message 保证chunk信息不过时。（某种程度的低耦合）</li>
</ul>
</li>
<li>operation Log 操作记录</li>
</ol>
<h5 id="Operation-Log"><a href="#Operation-Log" class="headerlink" title="Operation Log"></a>Operation Log</h5><p>记录系统操作、作为系统逻辑时间的最重要的元数据</p>
<ul>
<li>operation log持久存储，多处备份，每次操作只有真正的记录到Operation Log中时，才会对客户端可见</li>
<li>operation log大小超过一定程度时，系统创建checkpoint，将当前operation log存储到本地</li>
<li>以compact B-tree的形式存储checkpoint，方便快速读取和加载</li>
<li>checkpoint的创建与切换新 operation log file并行进行</li>
</ul>
<h5 id="atomically-at-least-once"><a href="#atomically-at-least-once" class="headerlink" title="atomically at least once"></a>atomically at least once</h5><p>追加写操作保证”原子性“，我理解的是：真实追加写入的offset相较于client发出请求offset不一定一致，但是我保证所有副本最后在追加的offeset一定相同，并将这个offset返回给客户端。</p>
<p>举个例子，例如向A,B,C三个chunk server的同一文件的副本追加文件，<strong>A，B写入成功，C写入失败</strong>，GFS并不会单独重新在C上追加，而是在C上补充空白（insert padding or record duplicates in between.），使得三个文件的偏移量相同，重新写入ABC。</p>
<p>这样做会导致文件中出现<strong>无效数据</strong>，但是论文中说这些数据和用户数据相比<strong>微不足道</strong>（are typically dwarfed by the amount of user data）</p>
<h5 id="一致性模型中的consistent-和-defined"><a href="#一致性模型中的consistent-和-defined" class="headerlink" title="一致性模型中的consistent 和 defined"></a>一致性模型中的consistent 和 defined</h5><p>两者定义</p>
<ul>
<li><p>consistent 指所有的client看到相同的数据，即所有副本均相同</p>
</li>
<li><p>defined 指看到自己操作对于数据的改变 = 期望中的改变</p>
</li>
</ul>
<p>成功和失败的操作定义为：</p>
<ul>
<li>成功：可能会导致操作后<strong>undefined</strong>(无法预期操作的结果)，但数据仍为<strong>consistent</strong></li>
<li>失败：导致unconsistent，即不同数据备份不一致</li>
</ul>
<h5 id="Leases-and-Mutation-Order"><a href="#Leases-and-Mutation-Order" class="headerlink" title="Leases and Mutation Order"></a>Leases and Mutation Order</h5><p>lease用来记录对于一份文件多个并发操作的执行顺序，由master节点选取其中chunk server一个作为primary lease决定执行顺序，所有文件副本均按照primary lease操作顺序执行</p>
<ul>
<li>每个lease 60秒失效</li>
<li>在与master节点的Heartbeat中primary的授权信息（These extension requests and grants are piggybacked on the HeartBeat messages regularly exchanged between the master and all chunk server）</li>
</ul>
<h4 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h4><img src="/2022/04/17/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/GFS%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220415142928379.png" class="" title="image-20220415142928379">
<p>以写流程流程为例，涉及client、Master、Chunk server之间的交互</p>
<ol>
<li>Client 向 Master请求写入文件的Chunk Server地址（包括备份的Chunk Server）</li>
<li>Master 返回给Client请求的Chunk Server地址，Client拿到地址后，将写入文件发送到所有目标Chunk Server中（不是<strong>分发</strong>，而是<strong>链式传输</strong>，论文中称“decoupling the data flow from the control flow”，提高了系统performance）</li>
<li>所有接收文件的Chunk Server确认接收完成后，client向被选为primary lease的Chunk Server发送写请求，由改Chunk Server确定包括该请求在内的其他并发请求的执行顺序，通知其他Replica Chunk Server，包括自在内按照该顺序执行操作（forwards the write request to all secondary replicas）</li>
<li>Replica Chunk Server向Primary Chunk Server返回执行完成确认，Primary Chunk Server向Client返回执行完成确认。</li>
</ol>
<p>一旦其中有一步失败，即向Client汇报失败，由Client自己进行处理（重试操作）</p>
<h4 id="几个主要操作（策略）"><a href="#几个主要操作（策略）" class="headerlink" title="几个主要操作（策略）"></a>几个主要操作（策略）</h4><h5 id="Data-Flow-数据传输"><a href="#Data-Flow-数据传输" class="headerlink" title="Data Flow-数据传输"></a>Data Flow-数据传输</h5><p>在Client向多个备份Chunk Server传输文件时，并不是采取传统的一个Client对多个Server的集中发送的方式，而是采取<strong>链式传输</strong></p>
<ol>
<li>Client首先选取最近(<strong>IP地址上的近</strong>)的Chunk Server传输文件</li>
<li>该Chunk Server再选取离他最近的未传输过文件的ChunkServer传输文件</li>
<li>重复传输，直到所有待传输Chunk Server获得文件</li>
</ol>
<h5 id="Atomic-Record-Appends"><a href="#Atomic-Record-Appends" class="headerlink" title="Atomic Record Appends"></a>Atomic Record Appends</h5><p>传统基于offset的写入，同一个区域的并发写入操作是无法序列化的（需要严格同步机制），针对record append操作，GFS舍弃了由应用输入offset的机制，应用只需要写入数据，由GFS写入后，向应用返回offset，其中一致性保证 <strong>atomically at least once</strong> </p>
<ul>
<li>若添加的文件使得chunk大小超出了最大限制，Primary Chunk Server会在填充当前Chunk剩余空间，创建新Chunk存储添加的文件内容</li>
<li>GFS限制写入文件大小小于Chunk块大小的四分之一，避免padding导致的碎片问题过于严重</li>
</ul>
<h5 id="Namespace-Management-and-Locking"><a href="#Namespace-Management-and-Locking" class="headerlink" title="Namespace Management and Locking"></a>Namespace Management and Locking</h5><p><del>说实话没理解并不是很深刻</del>， GFS为系统中的每个路径前缀均设置了读写锁</p>
<ol>
<li><p>读操作需要获取叶子节点所有前缀read-lock</p>
</li>
<li><p>写操作只需要叶子节点路径write-lock(因为目录并不是实际的数据结构，不需要修改目录，只需修改文件)</p>
<img src="/2022/04/17/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/GFS%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220415152805791.png" class="" title="image-20220415152805791">
</li>
</ol>
<h5 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h5><p>系统快照，快速保存文件系统状态，其主要步骤为</p>
<ol>
<li>master首先撤下快照涉及文件的primary lease(避免在快照过程中文件上发生操作)</li>
<li>master将log record 操作记录存储到磁盘中</li>
<li>快照完成后，master接收到来自client对快照文件访问的新请求（通过操作记录数大小判断）时，延迟返回结果，创建一个与原Chunk相同的新Chunk供Client访问（懒备份）</li>
</ol>
<p>这一过程对于Cilent来说是无感的</p>
<h5 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h5><p>当删除一个文件时，GFS并直接回收文件占用资源，而是将文件名修改为hidden状态，待日后删除，基本流程</p>
<ol>
<li>删除文件，master结点记录删除操作，在chunk中将文件修改为hidden状态</li>
<li>master扫描到hidden状态文件，删除meta数据中关于hidden文件信息</li>
<li>chunk server与master 的Heatbeat message交换中，发现master已没有了这部分信息，<strong>chunk server回收空间</strong></li>
</ol>
<p>同样通过Garbage Collection回收stale Replica</p>
<h5 id="Data-Integrity"><a href="#Data-Integrity" class="headerlink" title="Data Integrity"></a>Data Integrity</h5><p>checksum+chunk version number机制保证数据正确性和及时性（up-to-date）</p>
<ol>
<li>每次读操作时，cunkserver验证本机数据check sum是否正确，不正确返回失败</li>
<li>为每个副本维护一个版本号，操作递增，当版本号不同时，由master在Garbage Collection回收过期副本</li>
</ol>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>按照自己的理解对GFS论文简单的理解了一下，感觉有些东西理解的还不是很透彻，慢慢深入了解</p>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>GFS</tag>
        <tag>分布式</tag>
        <tag>分布式文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Mapreduce论文总结</title>
    <url>/2022/04/24/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Mapreduce%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="Mapreduce"><a href="#Mapreduce" class="headerlink" title="Mapreduce"></a>Mapreduce</h3><blockquote>
<p>论文地址: <a href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf">MapReduce: Simplified Data Processing on Large Clusters</a></p>
</blockquote>
<p>Mapreduce分布式编程模型，理解起来比较简单，主要总结一下模型+实现细节</p>
<h4 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h4><p>将任务划分为Map和Reduce两个阶段由用户实现，每个阶段输入输出key-value对（形象理解可以看论文中的例子）</p>
<img src="/2022/04/24/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Mapreduce%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220420082702737.png" class="" title="image-20220420082702737">
<ol>
<li>Map 输入key-value，经过处理输出新的中间 key-value对，由MapReduce执行程序，将相同<strong>中间key</strong>聚集发送给某一个reduce执行程序</li>
<li>Reduce 输入一个中间key和key对应的value列表，reduce执行具体聚集操作后，获得最终的输出key-value</li>
</ol>
<span id="more"></span>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>基本执行流程包括</p>
<ol>
<li>将输入文件划分为m份（16-64mb），对应m个map任务。在集群上启动多份应用程序</li>
<li>其中一个master程序，将map任务和reduce任务分配给空闲的worker(不同的worker可能是一台机器)</li>
<li>map任务程序首先执行，读取对应的文件块，将输出中间键值对缓存在内存中</li>
<li>每隔一段时间，map worker将缓存中的中间键值对存储到本地磁盘（根据key-&gt;reduce的映射进行partition）。这些中间键值对的地址，将传给master worker,供reduce worker远程读取</li>
<li>reduce worker由master唤醒后，通过RPC读取映射到本reduce worker的中间键值对输出</li>
<li>当属于某个reduce worker的中间键值对读取完成后，按照中间键值排序，对不同的key分组处理，也就是所谓的reduce输入key-value list</li>
<li>所有reduce程序完成后，结束mapreduce过程</li>
</ol>
<p>总结一下，就是map-&gt;partition-&gt;sort-&gt;reduce</p>
<img src="/2022/04/24/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Mapreduce%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220420083217188.png" class="" title="image-20220420083217188">
<h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p>为map和reduce任务定义了执行状态存储在master结点中，通过状态实现容错，每个任务的状态为</p>
<ol>
<li>idle 等待处理</li>
<li>in-progress 处理中</li>
<li>completed 处理完成</li>
</ol>
<p>master定期ping所有执行或者执行过任务的worker，若worker失效，将worker上执行过的所有任务（in-progress或者completed）状态设置为idle，等待分配给其他worker处理。</p>
<ul>
<li>若mapreduce任务执行在类似GFS的文件系统上，则complete类型任务不需要重新执行，因为输出文件不仅仅存储在失效的worker上</li>
<li>每当一个map任务重新执行后，需要通知所有的reduce任务该map任务的新执行</li>
</ul>
<h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><ol>
<li>map任务分配任务时遵循“靠近输入文件的原则”，首先考虑分配在包含输入文件的机器上，其次考虑靠近存储文件的机器上（移动计算比移动数据更有效）</li>
<li>用一些backup worker，替代拖后腿的worker，提升系统效率下限</li>
<li>map和reduce任务数量M和R要比机器数量大得多，以更好地负载均衡（每个workerp平均一个任务都分不到，谈何负载均衡?）和恢复错误（没太理解？）</li>
</ol>
<h4 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a>问题思考</h4><ol>
<li><p>如何把map任务的输出分配给R个reduce worker（<strong>partition</strong>）</p>
<ul>
<li><p>原则：相同key必须分配到同一个reduce worker</p>
</li>
<li><p>最简单方式就是使用key的哈希值进行映射</p>
<img src="/2022/04/24/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Mapreduce%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220420092210098.png" class="" title="image-20220420092210098">
</li>
</ul>
</li>
<li><p>既然有了partition，为什么要combiner?</p>
<ul>
<li>相同key值的key-value对可能很多(例如wordcount)，通过网络传播对带宽压力较大，</li>
<li>在map端先进行<strong>一部分的reduce操作</strong>，合并重复key，也能一定程度减轻reduce的计算压力</li>
</ul>
</li>
<li><p>直觉上为什么mapreduce能解决分布式计算问题？</p>
<p>从程序角度看，不管的单机还是分布式，其本质都是<strong>程序读取输入-&gt;程序计算-&gt;程序输出结果</strong>，我要实现分布式程序，无非要实现 <strong>分布计算 = 单机计算</strong></p>
<ol>
<li><strong>程序输入：</strong> 分布式文件存储在不同机器上，自然而然能够想到<strong>多个map程序读取文件</strong>的操作</li>
<li><strong>程序计算：</strong>难点在于分布式读入文件，我如何实现等价于单机计算的效果？我觉得这就reduce设计巧妙地地方，<strong>文件的分块不等于计算的逻辑分块</strong>，通过map—&gt;reduce程序的计算，实际上将<strong>文件的分块映射到计算的逻辑分块</strong></li>
<li><strong>程序输出：</strong> reduce输出实际逻辑子问题的输出-&gt;实际问题的输出（这一点我还没想明白，类似于归并排序 reudce制作到了归没有做并）</li>
</ol>
<p>以wordcount为例，讲一下我的理解</p>
<ol>
<li><strong>文件分块：</strong>整个文本文件-&gt;子文本文件块 （<strong>问题数据规模上分布</strong>）</li>
<li><strong>计算逻辑分块</strong>：统计每个不同字的字数-&gt;单独统计每个字的字数（<strong>问题逻辑规模上分布</strong>）</li>
</ol>
<p>map解决每个文本文件内字数的统计，reduce解决每个字字数统计</p>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>mapreduce只看理论理解还是太表面，还是需要写代码实战，学到了继续深化吧</p>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>mapreduce</tag>
      </tags>
  </entry>
  <entry>
    <title>共识算法-Paxos</title>
    <url>/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Paxos/</url>
    <content><![CDATA[<h2 id="分布式共识算法-Paxos"><a href="#分布式共识算法-Paxos" class="headerlink" title="分布式共识算法-Paxos"></a>分布式共识算法-Paxos</h2><p>共识算法目的是通过一系列通信约束，使得依靠不可靠通信网络上的不同结点之间能够通过算法得到一致的结论（区别于分布式一致性这一概念）,共识算法是实现<a href="https://en.wikipedia.org/wiki/State_machine_replication">state machine replication</a> 的基础，后者是分布式系统中较为重要的备份容错算法策略</p>
<h3 id="分布式CAP"><a href="#分布式CAP" class="headerlink" title="分布式CAP"></a>分布式CAP</h3><p>一个分布式系统只能满足一下三条性质中的两条</p>
<ol>
<li>Consistency(一致性)：每个客户端的读操作均能读取到最近的写入内容或者返回错误</li>
<li>Availability(可用性): 客户端的每个请求均能收到非报错响应（回复不一定正确即不一定保证C）</li>
<li>Partition Tolerance(分区容错性)：不同结点或分区之间的网络故障不会影响系统的正常运行</li>
</ol>
<p>为什么说分布式系统只能保证其中两条？</p>
<ol>
<li>分布式系统由于系统结点/分区分布于不同的网络环境，通过网络进行通信，不可避免地会出现结点由于网络故障下线问题，为了系统的可用性，必须保证Partition Tolerance</li>
<li>当部分结点出现网络故障时，面对客户端请求，系统有两种处理方式<ul>
<li>回退操作，相当于保证了C但舍弃了A</li>
<li>继续执行操作，由于部分结点下线，此时执行操作无法保证C，但是保证了A</li>
</ul>
</li>
</ol>
<p>单机系统由于不会出现分布网络失效，所以也就不需要P，可以同时保证CA</p>
<span id="more"></span>
<h3 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h3><blockquote>
<p>The Paxos protocol was first submitted in 1989 and named after a fictional legislative consensus system used on the <a href="https://en.wikipedia.org/wiki/Paxi">Paxos</a> island in Greece</p>
</blockquote>
<p>Paxos是经典的基于消息传递共识算法，然而理解难度过高，简单整理以加深印象，算法中定义了四种不同的角色（一个结点可以有多个不同的角色）</p>
<ol>
<li>Client: 客户端向系统发送请求（例如：向分布式文件系统写入）</li>
<li>Proposer: 提出提案</li>
<li>Acceptor:  判断是否接受提案</li>
<li>Learner: 当提案被接受时，执行具体操作（例如：执行写入操作）</li>
<li>Leader: 唯一的Proposer</li>
</ol>
<p>其他概念</p>
<ol>
<li>Proposal: 提案，每个提案由提案号n和提案值组成v:<n, v></li>
<li>Quorums: 由大多数Accepter组成的集合，用来投票确定是否接受提案</li>
<li>safety/liveness/fault tolerance: 共识算法的三个形式，类似于CAP三者只能满足其二<ul>
<li>safety: “坏事”永远不会发生</li>
<li>liveness: “好事”终将发生</li>
<li>没太理解和fault tolerance之间的关系和区别</li>
</ul>
</li>
</ol>
<p>Paxos保证safety+fault tolerance，不保证liveness</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Paxos/image-20220531103804034.png" class="" title="image-20220531103804034">
<h4 id="算法流程（Basic-Paxos）"><a href="#算法流程（Basic-Paxos）" class="headerlink" title="算法流程（Basic Paxos）"></a>算法流程（Basic Paxos）</h4><p>分为确定提案值+接受提案两个阶段</p>
<ol>
<li>阶段1（prepare+promise）<ul>
<li>由Proposer创建Prepare message，其中包括此次提案号n（n保证大于之前任何Prepare中的n），发送给至少一个Quorums（确定谁来投票）</li>
<li>接收到Prepare message的Acceptor，根据提案号n确定返回消息类型<ul>
<li>若Acceptor已通过提案，返回通过提案号m+提案value</li>
<li>若Prepare message中的提案号大于之前任何接收到的提案号，返回Promise message</li>
<li>若存在大于Prepare message中的提案号的历史提案号，忽略Prepare Message</li>
</ul>
</li>
<li>若Proposer未收到大多数Acceptor的响应信息,终止此次提案过程</li>
</ul>
</li>
<li>阶段2（accept+accepted）<ul>
<li>Proposer根据接收到的响应类型确定提案value，之后发送Accept message (n,v)到Acceptor<ul>
<li>若响应中包含提案号m+提案value，将当前提案value设置为最大m对应的value</li>
<li>若只有Promise响应，将提案value设置为 originally wanted value</li>
</ul>
</li>
<li>Acceptor只有在未通过过提案且当前Accept message (n,v)中的提案号最大时，通过该提案，并向Proposer和所有的Learners发送接受信息</li>
</ul>
</li>
</ol>
<p>理解的还是比较浅薄，但是基本理解算法流程了,形式上理解为什么Paxos能够实现共识（safety）</p>
<ol>
<li>同一个Acceptor不会出现同一个提案多个值的情况。一旦Acceptor接受一个提案，其不会再接受其他提案</li>
<li>不同Acceptor不会出现同一个提案多个值的情况。提案号递增，且Acceptor不会响应提案号小于已经接受过的提案</li>
</ol>
<p>每个通过的提案不保证所有Acceptor均收到通过信息，但保证收到通过信息的Acceptor通过的为同一value</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Paxos/image-20220531112542422.png" class="" title="image-20220531112542422">
<p>Basic Paxos无法保证livness，即无法保证算法能够终止找到共识</p>
<ul>
<li>两个Proposer在Accept阶段争抢,如下<ul>
<li>Proposer1此时提出提案1，即将走到Accept阶段时，Proposer2提出提案2，导致提案1的编号因为小于最新提案2，无法通过，Proposer1重新提交提案3，导致提案2小于提案3，无法通过</li>
<li>最终导致无限的抢占，无法达共识</li>
</ul>
</li>
<li>通过Proposer的随机休眠避免抢占冲突发生</li>
</ul>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Paxos/image-20220531112719316.png" class="" title="image-20220531112719316">
<h4 id="Multi-Paxos"><a href="#Multi-Paxos" class="headerlink" title="Multi Paxos"></a>Multi Paxos</h4><p>为了解决Paxos算法存在的争抢以及两段式RPC的通信成本问题，改进得到Multi Paxos算法</p>
<ol>
<li>选举一个固定的Proposer,提案编号中变为 Proposer编号+提案编号<ul>
<li>通过一个和basic Paxos相同两阶段选举主Proposer</li>
</ul>
</li>
<li>每次提出提案，直接进行第二阶段</li>
</ol>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Paxos/image-20220531143508710.png" class="" title="image-20220531143508710">
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://en.wikipedia.org/wiki/Paxos_(computer_science">Paxos (computer science) From Wikipedia</a>)</li>
<li><a href="https://zhuanlan.zhihu.com/p/31780743">知乎：Paxos算法详解</a></li>
</ol>
]]></content>
      <categories>
        <category>分布式理论</category>
      </categories>
      <tags>
        <tag>共识算法</tag>
        <tag>CAP</tag>
      </tags>
  </entry>
  <entry>
    <title>ZooKeeper论文总结</title>
    <url>/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/ZooKeeper%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="分布式消息中间件-ZooKeeper"><a href="#分布式消息中间件-ZooKeeper" class="headerlink" title="分布式消息中间件-ZooKeeper"></a>分布式消息中间件-ZooKeeper</h2><h3 id="线性一致性（linearizability）"><a href="#线性一致性（linearizability）" class="headerlink" title="线性一致性（linearizability）"></a>线性一致性（<strong>linearizability</strong>）</h3><p><strong>线性一致性</strong>是指分布式系统面对网络延迟和系统故障保证不同分布之间的数据一致性，使分布式系统在客户端看起来就像一个没有副本的单机系统。</p>
<ul>
<li><p>也成为 <strong>原子一致性（atomic consistency）</strong>，<strong>强一致性（strong consistency）</strong>，<strong>立即一致性（immediate consistency）</strong> 或 <strong>外部一致性（external consistency ）</strong>。</p>
</li>
<li><p>换一个角度：一旦新的值被写入或读取，所有后续的读都会看到写入的值，直到它被再次覆盖</p>
</li>
</ul>
<span id="more"></span>
<p>线性一致性例子如下：</p>
<ul>
<li>其中Client B最后一个读取请求读到了2，由于Client A在其时间点前的一个读读到了最新的写入4，所以Client B的读取结果违背了线性一致性</li>
<li>通过记录所有请求和响应的时序，并检查它们是否可以排列成有效的顺序，通过该方式判断系统是否满足线性一致性</li>
</ul>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/ZooKeeper%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220625103136312.png" class="" title="image-20220625103136312">
<h4 id="可串行化（Serializability）-VS-线性一致性（Linearizability）"><a href="#可串行化（Serializability）-VS-线性一致性（Linearizability）" class="headerlink" title="可串行化（Serializability） VS 线性一致性（Linearizability）"></a>可串行化（Serializability） VS 线性一致性（Linearizability）</h4><p>两者衡量的问题：</p>
<ol>
<li>可串行化针对的是多个并发数据库事务，这些<strong>并发</strong>事务之间<strong>没有特定的顺序</strong>。可串行化指的是可以找到<strong>任意一个可行事务执行顺序</strong>，使得数据库的状态改变<strong>符合实际情况</strong>。（ <strong>multi-operation, multi-object, arbitrary total order</strong>）</li>
<li>线性一致性针对的是多个具有严格时序的事务，事务的发生顺序由全局时钟（也可能是逻辑时钟）衡量。线性一致性指的是按照事务之间的时序，判断按照该时序，系统状态变化是否出现冲突（<strong>single-operation, single-object, real-time order</strong>）</li>
</ol>
<p>另外两者应用领域不同：</p>
<ol>
<li>可串行化对应数据库ACID属性中的 <strong>“I”</strong>，即isolation 数据库的隔离性</li>
<li>线性一致性对应分布式系统CAP理论中的<strong>“C”</strong>，即Cosistency 分布式系统的一致性</li>
</ol>
<p>可串行化 + 线性一致性 = 数据库的强一致性</p>
<ol>
<li>数据库中基于两阶段锁定的一致性保证同时满足 可串行化 和 线性一致性</li>
<li>可串行化的快照隔离（数据库的弱一致性，不太理解） 无法保证 线性一致性</li>
</ol>
<p>我的简单理解:</p>
<ol>
<li>可串行化就是一个单机系统的概念，单机系统中在执行顺序确定的情况下结果必然是确定的，只有可能在并发条件下才可能出现不一致的问题，可串行化就是说寻求一个顺序使得并发请求结果保持一致。</li>
<li>线性一致性是分布式系统中的概念，由于不同备份之间存在版本差距，即使是顺序确定的一系列请求（访问了不同服务器上不同版本的副本）也可能出现，后发出请求反而读到了旧值的情况，线性一致性是寻求一个顺序使得分布式系统中具有确定顺序的请求出现结果冲突的问题（在分布式全局逻辑时钟衡量下也可能出现并发情况，此时与串行化一致）</li>
</ol>
<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><blockquote>
<p>ZooKeeper is essentially a <a href="https://en.wikipedia.org/wiki/Service_(systems_architecture">service</a>) for <a href="https://en.wikipedia.org/wiki/Distributed_computing">distributed systems</a> offering a <a href="https://en.wikipedia.org/wiki/Hierarchical_database_model">hierarchical</a> <a href="https://en.wikipedia.org/wiki/Key-value_database">key-value store</a>, which is used to provide a distributed <a href="https://en.wikipedia.org/wiki/Configuration_management">configuration service</a>, <a href="https://en.wikipedia.org/wiki/Synchronization_(computer_science">synchronization service</a>), and <a href="https://en.wikipedia.org/wiki/Directory_service">naming registry</a> for large distributed systems (see <em><a href="https://en.wikipedia.org/wiki/Apache_ZooKeeper#Use_cases">Use cases</a></em>).<a href="https://en.wikipedia.org/wiki/Apache_ZooKeeper#cite_note-3">[3]</a> ZooKeeper was a sub-project of <a href="https://en.wikipedia.org/wiki/Hadoop">Hadoop</a> but is now a <a href="https://en.wikipedia.org/wiki/Apache_Software_Foundation#Projects">top-level Apache project</a> in its own right.</p>
</blockquote>
<p>ZooKeeper是一个分布式应用程序协调服务(coordination service)，为分布式应用提供配置管理、成员管理以及分布式锁等服务（<del>人如其名</del>），其底层基于Fast Paxos一致性算法，下面通过论文对ZooKeeper原理进行了解和研究。</p>
<h4 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h4><p>ZooKeeper使用znode作为元数据存储节点，其中znode以类似于unix文件系统的树型组织（如下图），每个znode拥有自己的命名空间</p>
<ul>
<li>znode不存储实际的数据，而是存储协调分布式应用的相关元数据（如配置）或仅仅通过znode实现协调功能（分布式锁）</li>
<li>client通过Zookeerper提供的API<strong>修改znode元数据或者添加/删除znode</strong> 实现分布式协调原语</li>
</ul>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/ZooKeeper%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220701141843134.png" class="" title="image-20220701141843134">
<p>znode分为以下不同类型：</p>
<ol>
<li>Regular：普通节点。由client主动创建和删除</li>
<li>Ephemeral：临时节点。同样由client主动创建和删除，但是当创建该节点的client的session结束时，节点自动删除（容错）</li>
</ol>
<p>另外创建znode时，可显式指定znode带有序列号(<strong>sequential flag</strong>)</p>
<ul>
<li>该机制保证新创建的znode的sequential flag在父节点所有儿子节点中最大</li>
<li>sequential flag可以方便的实现读写锁、无<em>羊群效应</em>（herd effect）的排他锁</li>
</ul>
<p>zookeeper提供了znode的<strong>watch</strong>机制，允许client主动监视znode的状态变更（异步）</p>
<ul>
<li><p>client 可对指定znode进行watch标记，当该znode状态修改时（删除、修改配置等），zookeeper发送消息提醒client</p>
</li>
<li><p>watch配合其他机制可方便实现一系列分布式写作原语（分布式锁）</p>
</li>
<li><p>我认为 <strong>watch机制</strong>也是ZooKeeper把自己称为 <strong>wait free</strong>的原因之一</p>
</li>
</ul>
<p>zookeeper将与client的交互定义为<strong>session</strong></p>
<ul>
<li>在session内，当ZooKeeper超过一定时间（session timeout）未收到client的请求，ZooKeeper会主动结束session</li>
<li>client也可主动关闭session，否则通过发送heartbeat请求维持session不会timeout</li>
</ul>
<h4 id="ZooKeeper基本操作"><a href="#ZooKeeper基本操作" class="headerlink" title="ZooKeeper基本操作"></a>ZooKeeper基本操作</h4><p>ZooKeeper本身采用主从复制的形式（如下图），实现高可用分布式协调服务，其中ZooKeeper主要包括两种操作</p>
<ol>
<li>写请求：接收到请求的follower服务器转发给leader，由leader运行共识算法得到共识后，提交当前写请求，并最终会在所有副本上写入</li>
<li>读请求：接收到请求的server直接读取本地数据，返回读取结果</li>
</ol>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/ZooKeeper%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220701150857515.png" class="" title="image-20220701150857515">
<p>不难看出ZooKeeper处理读请求的方法可能会导致client读到stale数据，ZooKeeper设计中接受这种程度一致性，其基本保证为</p>
<ol>
<li><strong>Linearizable writes</strong>(线性一致写)：明显写请求通过共识算法后才提交，能够保证在所有副本上实现写的线性一致性</li>
<li><strong>FIFO client order</strong>：所有来自同一个客户端请求保证按照请求发送顺序执行（client视角的线性一致性：即client不会出现先读到新数据，后读到旧数据的情况，每次读都保证至少和上次读取新旧程度相同的数据）</li>
</ol>
<p>由性质2可以得到，ZooKeeper的设计目标并没有<strong>读写线性一致性</strong>，仅仅保证单客户端的线性一致性，然而在处理读请求时仅仅时简单的读取本地数据无法保证性质二</p>
<ul>
<li>例如：client从一个最新的server上读取数据，该服务器宕机，client被分配到另一个数据不是最新的server,此时新的读请求会读到stale数据</li>
<li>针对此Zookeeper为处理的每个请求打上当前服务器已提交的写请求的<strong>zxid</strong>(<strong>zxid用来标记写请求的顺序</strong>),当client与新server建立session时，server会在确认自己至少拥有client的zxid相同新鲜程度数据的情况下，才与client建立session，否则等待直到数据更新到至少相同新鲜程度（<strong>as recent as the client</strong>）</li>
<li>由于共识算法的作用，大多数server必定带有最新更新，这就<strong>保证了client最终一定会找到可以建立连接的server</strong></li>
</ul>
<p><strong>Atomic Broadcast-Zab</strong></p>
<p><strong>Zab-ZooKeeper Atomic Broadcast</strong>，论文中只是引用了一下，这里简单介绍一下原理：</p>
<ol>
<li>正常状态下与fast paxios区别不大，leader收到一个事务（transaction）,为事务带上<strong>序列号</strong>和<strong>当前leader的epoch号</strong>（ 64位zxid,32epoch,32序列号），之后发送到所有的follower,多数通过即提交</li>
<li>leader和follower通过heartbeat信息交互，当一方超过一定时间未收到另一方的heartbeat，即认为另一方失效，当follower认为leader失效时，其进入错误恢复阶段</li>
<li>恢复模式（选主）：和raft类似，follower向其他follower发送选举请求，投票超过半数，成为新的leader（类似于gossip，follower之间不断pk，直到出现一个过半选票）</li>
<li>同步阶段：leader将最新zxid发送给follower,follower根据zxid与leader保持状态同步</li>
</ol>
<p>zab基于TCP实现leader到follower请求的fifo管道</p>
<p><strong>snapshot</strong></p>
<p>ZooKeeper使用一种 fuzzy snapshot的方式进行系统快照</p>
<ol>
<li>在进行快照的过程中，服务器继续响应请求</li>
<li>得到的快照可能处于中间状态，所以叫<strong>fuzzy snapshot</strong></li>
</ol>
<p>在启用快照时为了避免fuzzy snapshot导致的状态不正确问题，ZooKeeper通过Zab重传操作（ Zookeeper状态变更是幂等，所以即使重复执行也保证状态正常变更），保证最终状态与系统崩溃前一致</p>
<h4 id="Client-API"><a href="#Client-API" class="headerlink" title="Client API"></a>Client API</h4><p>ZooKeeper为Client提供了操作znode基本API，类似于文件系统的增删改查操作，每个操作均包括同步和非同步版本</p>
<ol>
<li>create(path, data, flags)：创建znode，其中flag用来指定znode类型：rugular,ephemeral,sequential</li>
<li>delete(path, version)：删除znode</li>
<li>exists(path, watch): 判断znode是否存在</li>
<li>getData(path, watch): 获得znode中存储的元数据</li>
<li>setData(path, data, version)：修改znode中元数据</li>
<li>getChildren(path, watch)： 获得当前路径的所有子znode</li>
<li>sync(path)：主动同步命令（path无关）</li>
</ol>
<p>通过以上API，Client可以方便的实现多种分布不是协调原语</p>
<ol>
<li><p>分布式互斥锁：基本原理是通过一个znode或者多个同父节点的znode实现锁</p>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/ZooKeeper%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220702090302676.png" class="" title="image-20220702090302676">
</li>
<li><p>Double Barrier：我理解的是双重同步，实现多个进程的同步。基于特定路径子znode的增删。</p>
</li>
<li><p>配置管理/成员管理：znode代表逻辑上的节点，通过znode修改删除等实现管理功能</p>
</li>
</ol>
<h4 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h4><p>ZooKeeper已经成功的应用于分布式用服务，论文中举了几个例子</p>
<ol>
<li>The Fetching Service：Yahoo的搜索引擎通过该服务实现数十亿级的网页爬取，该服务器有master和fecher组成，其中master管理fetcher的配置信息，fetcher进行网页的爬取并向master汇报自身状态信息。<ul>
<li>使用ZooKeeper目标：master容错，master配置职责解耦</li>
<li>用到的原语：配置管理、主节点选举</li>
</ul>
</li>
<li>Katta：分布式索引器，Katta将检索过程分布在不同的服务器上<ul>
<li>使用ZooKeeper目标：master容错，master配置职责解耦，成员容错</li>
<li>用到的原语：配置管理、主节点选举、成员管理</li>
</ul>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>ZooKeeper通过特殊的文件系统+zab算法实现了一个可定制化的分布式协作服务，在我看来ZooKeeper最大的优点在于屏蔽了底层共识算法的复杂细节，为分布式协作提供了简单、通用而又高度可定制化的实现接口。</p>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>大数据组件</tag>
      </tags>
  </entry>
  <entry>
    <title>共识算法-Raft</title>
    <url>/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/</url>
    <content><![CDATA[<h2 id="分布式共识算法-Raft"><a href="#分布式共识算法-Raft" class="headerlink" title="分布式共识算法-Raft"></a>分布式共识算法-Raft</h2><p>Raft是基于Paxos改进的共识算法，其最开始的设计目标即为容易理解且容易实行，所以相较于Paxos学起来更容易（<del>确实比Paxos容易，但我还是看不懂啊</del>）。</p>
<p>Raft中定义了三种角色：</p>
<ol>
<li>Leader：唯一的leader，负责与Client交互，在其他follower上备份log日志。</li>
<li>Follower: 多个Follower，接收Leader的日志备份请求，当Leader出现问题时，选举成为新的leader。</li>
<li>Candidate: 当Follower认为Leader失效时，Follower状态转换为Candidate，进行Leader的竞选。</li>
</ol>
<p>Raft中只包括两种类型的RPC消息</p>
<ol>
<li>RequestVote RPC：参与选举的Candidate发送的选举消息</li>
<li>AppendEntries RPC:  Leader向Follower发送的添加日志信息</li>
</ol>
<span id="more"></span>
<h3 id="Raft的一般流程"><a href="#Raft的一般流程" class="headerlink" title="Raft的一般流程"></a>Raft的一般流程</h3><p>算法主要包括两个步骤（均基于Majority Vote思想）</p>
<ol>
<li>Leader election: 选举出全局的Leader</li>
<li>Log replication: 日志备份，每当Leader接收到Client的一个请求，Leader将日志成功的备份到多数Follower后，提交操作，向Client返回操作信息</li>
</ol>
<p>基本流程</p>
<ol>
<li>Server集群启动，开始选举，部分Follower Server转化为Candidate状态向其他的Server发送RequestVote RPC</li>
<li>每个收到RequestVote RPC的Server按照”first come first serve”的原则，给对应的Candidate投票，获得过半投票的Candidate成为Leader</li>
<li>Leader接受Client请求，写入log，并向其他Follower发送AppendEntries RPC备份log，保证所有server的state machine状态一致</li>
</ol>
<p>Raft将时间划分为了固定的 “term”，不同服务器通过term作为逻辑时钟实现同步和一致性的保持</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602150043559.png" class="" title="image-20220602150043559">
<h3 id="Leader-election"><a href="#Leader-election" class="headerlink" title="Leader election"></a>Leader election</h3><p>要了解选举，首先要了解<strong>触发选举的条件</strong>，为了避免Leader崩溃导致的系统单点失效，Raft通过“heart beat”机制实现Leader状态的监控</p>
<ol>
<li>Leader周期性所有的Follower的发送heartbeart消息（不包含log的(AppendEntriesRPC）</li>
<li>每个Follower设定了一个 “election timeout” 超时时间，当Follower超过该时间为收到来自Leader的heartbeart消息时，该Follower认为Leader失效，发起选举。</li>
<li>服务器启动时初始化所有服务为Follower状态，并启动”election timeout”计时器</li>
</ol>
<p>所以Leader election的<strong>触发时机为某个Follower超时，转化为Candiate状态</strong></p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602153212870.png" class="" title="image-20220602153212870">
<h4 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h4><img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602153043100.png" class="" title="image-20220602153043100">
<p>Follower转化为Candidate后，开启新一轮选举，执行一下几个操作后，等待选举结果</p>
<ol>
<li>term增加1，代表进入下一个逻辑时间段</li>
<li>为自己投票</li>
<li>重置election timer</li>
<li>向其他Server发送RequestVote RPC，请求成为Leader</li>
</ol>
<p>其他Server收到请求后，按照”first come first serve”原则向Candidate投票</p>
<ol>
<li><p>若RequestVote RPC的term值小于当前term值，说明当前投票信息已过期，拒接投票</p>
</li>
<li><p>若未投过票，则未接收到的第一个 RV RPC投票，否则拒绝投票（”first come first serve”）</p>
</li>
<li><p><strong>election restriction</strong>：RequestVote RPC中的 more up-to-date，投票，否则拒绝</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602201511973.png" class="" title="image-20220602201511973">
</li>
</ol>
<p>等待成为Leader的Candidate可能等到三种情况</p>
<ol>
<li>收到了过半的投票（包括自己）<strong>-&gt;</strong> 竞选成功，转换状态为Leader</li>
<li>收到了来自其他Server的term大小相同的AppendEntries RPC  <strong>-&gt;</strong> 其他Server竞选成功，转换状态为Follower</li>
<li>直到election timer超时也未收到上述两个情况响应 <strong>-&gt;</strong> 进入下一轮选举</li>
</ol>
<p>如果不断的重复出现3，也就是<strong>split votes</strong>问题</p>
<ul>
<li>多个candidate争抢，导致每个candidate均无法达到过半的票数</li>
<li>解决方法：Raft使用随机选举超时机制（<strong>randomized election timeouts</strong>），错开不同的Follower成为Candidate的时机</li>
</ul>
<p>一系列操作最终保证 <strong>Election Safety</strong> : 一个term内最多存在一个Leader</p>
<ul>
<li>一个term内可以不存在Leader</li>
<li>系统同时可以存在多个leader，但每个leader一定是不同的term内选出的</li>
</ul>
<h3 id="Log-replication"><a href="#Log-replication" class="headerlink" title="Log replication"></a>Log replication</h3><p>选举Leader的最终目的还是为了保证log的一致性，保证log的一致性是为了保证所有Server上state machine按照相同顺序执行相同操作以达到备份效果,Raft保证以下性质:</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602155409902.png" class="" title="image-20220602155409902">
<p><strong>具体发送流程</strong>如下：</p>
<ol>
<li>Leader为每个Follower维护一个nextIndex，代表下一个AppendEntries RPC中要携带的log entry的index</li>
<li>AppendEntries RPC中不止携带当前要添加的log entry(nextIndex指向的entry),还包括上一个log entry的term和index</li>
<li>Follower判断当前的last entry是否与AppendEntries RPC中携带的上一个log entry的term和index（<strong>Consistent Check</strong>）<ul>
<li>一致 接受添加</li>
<li>不一致 拒绝添加</li>
</ul>
</li>
<li>Leader 根据 Follower的响应信息，进行下一步操作<ul>
<li>若Follower拒绝，将nextIndex - 1</li>
<li>若Follower接受，将nextIndex + 1</li>
</ul>
</li>
<li>Leader不断发送AppendEntries RPC， 直到Follower的nextIndex等于Leader的last log entry</li>
</ol>
<p><strong>commit时机</strong>：</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602193022746.png" class="" title="image-20220602193022746">
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602161725209.png" class="" title="image-20220602161725209">
<ol>
<li><p>Leader收到超半数接受信息后即commit当前log entry</p>
</li>
<li><p>Follower根据AppendEntries RPC中携带的leaderCommit号，更新自身的commitIndex，若leaderCommit &gt; commitIndex,将commitIndex目标值</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602191533241.png" class="" title="image-20220602191533241">
</li>
<li><p>当Follower检测到 lastApplied小于commitIndex,提交lastApplied的log,并自增lastApplied</p>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220602191623397.png" class="" title="image-20220602191623397">
</li>
<li><p>特殊情况：<strong>Raft 永远不会通过计算副本数目的方式来提交之前任期内的日志条目</strong></p>
<ul>
<li>非常难理解这么做的原因以及为什么能解决，<a href="https://www.zhihu.com/question/68287713">知乎回答</a> + 论文中的图8 结合理解</li>
<li>我的理解：Leader选举并不能严格保证新的Leader一定包含所有的<strong>多数派log</strong><ul>
<li>多数派log中存在提交也存在未提交，若不加上述限制，就会出现图8中的例子，在同步log时，由于新Leader<strong>不包括已提交的多数派log</strong>，导致该log被覆盖</li>
<li>添加上述约束后，保证了新选出的Leader一定包含所有<strong>已提交的多数派log</strong>(但还是不一定包含所有多数派log)<ul>
<li>若当前未提交log的term小于最新term，我先不能提交（图8中三个2），等当前Server成为Leader拿到最新term（term = 4），准备提交当时term的log时（图8中三个4），再提交当前log（图8中可能覆盖当前log的S5不可能被选上了，因为term = 3 小于当前 term = 4）</li>
<li>要么当前未提交log被覆盖（无伤大雅，因为并没有提交）</li>
</ul>
</li>
<li>换句话说，既然我（term=2）的决定（log）会被你（term=3）无视，那我就不提交，等到我的年龄比你大时的决定(term = 4)要执行了，我再把之前的决定一起执行了，你不可能无视我的决定了（term = 3 &lt; term = 4）</li>
<li>或者 等不到我长大你就把我的决定给磨灭了</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Cluster-membership-changes-成员修改"><a href="#Cluster-membership-changes-成员修改" class="headerlink" title="Cluster membership changes 成员修改"></a>Cluster membership changes 成员修改</h3><p>Raft支持动态修改配置（例如：增加，删除Server）,为了避免在配置切换过程中出现脑裂问题，Raft通过两段式提交实现配置切换</p>
<ol>
<li>首先由Leader创建包括新旧配置log entry的特殊 AE RPC：$C_{old_new}$, 向所有的Follower发送，超过半数同意后提交，实现 <strong>joint concensus</strong></li>
<li>实现后<strong>joint concensus</strong>，Leader创建 新配置log entry：$C_{new}$，按照一般添加log entry的流程执行，成功commit后，完成配置切换</li>
</ol>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220603152218579.png" class="" title="image-20220603152218579">
<p>在配置切换时，可能选举出多个leader的原因来自于：</p>
<ul>
<li>$C_{new}$的部分传播导致 <strong>持有$C_{new}$的server</strong> 和 <strong>持有 $C_{old}$的server</strong> 对于 投票时的<strong>majority</strong> 判断标准不同，两个server子集合在一个term内选举出了两个Leader</li>
<li>例如下图：新配置为系统添加了两个新server(4和5)，Server1 未收到新配置，在竞选Leader时收到了 自己和Server 2的投票，即认为过半，转换为状态为Leader;Server 5使用新配置，收到了自己、Server3、Server4的投票，同样认为过半，转换状态为Leader</li>
</ul>
<img src="/2022/06/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Raft/image-20220603151523710.png" class="" title="image-20220603151523710">
<p>Raft引入了以下几个规则避免了上述问题的出现</p>
<ol>
<li>Log entry 在所有配置的Server($C_{old}$ 和$C_{old_new}$)上均进行备份（避免切换过程中，未收到$C_{old_new}$的Server遗失Log entry）</li>
<li>此时的Majority要满足$C_{new}$ 和  $C_{old}$两个配置中的Majority（单依靠$C_{new}$ 选不出Leader）、</li>
<li>Server收到新配置立即生效，无论配置日志是否commit</li>
</ol>
<p>导致的结果（要么老配置生效，要么兼容老配置和新配置生效，不会出现新配置单独生效的问题）</p>
<ol>
<li>要么选出的leader带有$C_{old}$，根据一致性约束，将带有$C_{old_new}$的Server回退，相当于未发生配置切换</li>
<li>要么选出的leader只带有$C_{old_new}$，实现了joint concensus</li>
</ol>
<h3 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h3><p>当系统运行时间后，难以避免的会出现log过多，导致占用大量存储空间、Server的重启状态时间过长等问题，Raft采用快照机制实现log 压缩</p>
<ol>
<li>每个Server单独对已commit的log entry进行快照（降低单一快照+网络传递的通信成本）</li>
<li>Leader定期向Follower发送自己的快照，Follower根据快照情况修改本地log和快照（<strong>InstallSnapshot RPC</strong>）<ul>
<li>基本思路就是：快照里有的log entry,Follower直接删除, 直到快照和log完美衔接</li>
</ul>
</li>
</ol>
<p>既然为了避免通信开销已经让每个Server自己备份了，为什么还需要第二步骤？</p>
<ul>
<li>为了避免Follower落后Server过多，Server已经将某一个log快照以后删除，导致Follower永远收不到来自Leader的这个log</li>
</ul>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>客户端连接Server部分主要有三个逻辑：</p>
<ol>
<li><strong>客户端如何确定Leader是谁？</strong>随机选择Server，由Server返回Leader地址</li>
<li><strong>如何实现幂等？</strong><ul>
<li>Leader在Commit某操作后未返回结果直接崩溃，Client会尝试重发请求，这就需要系统支持幂等操作。</li>
<li>Raft在客户端为每个操作添加序列号，Leader维护每个Client已Commit的最新序列号，对已执行过的操作直接返回结果</li>
</ul>
</li>
<li><strong>对应Read-only  op，如何保证返回最新结果?</strong> 换句话说就是保证Raft的强一致性（Zookeeper中会详细讲什么是强一致性-<strong>Linearizability</strong>）<ul>
<li>Leader在每个term开始时，提交一个no-op entry，保证Leader得到所有的Commit Entry（由于Raft 永远不会通过计算副本数目的方式来提交之前任期内的日志条目，<strong>为了避免存在部分多数entry未提交的情况</strong>）</li>
<li>Leader每次响应只读操作前，首先通过心跳机制确定自己还是leader(以免已有另外的leader被选举，导致返回结果stale)</li>
</ul>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Raft说实话理解难度是比paxos降低了，但是细节和涉及到的分布式知识太多了，我目前只能说弄懂了部分细节，整体上理解还是欠缺，即做到了深入，但以我目前的水平还做不到浅出（<del>反正研究生不搞这个，能懂点面试吹吹nb即可</del>）</p>
]]></content>
      <categories>
        <category>分布式理论</category>
      </categories>
      <tags>
        <tag>共识算法</tag>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>链式复制论文总结</title>
    <url>/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E9%93%BE%E5%BC%8F%E5%A4%8D%E5%88%B6%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="链式复制及其改进"><a href="#链式复制及其改进" class="headerlink" title="链式复制及其改进"></a>链式复制及其改进</h2><p><em>写在前面：CRAQ还涉及到了服务器放置策略等内容，我目前阶段学习并不关心，所以没有深入了解</em></p>
<blockquote>
<p>论文：<a href="https://www.usenix.org/legacy/events/usenix09/tech/full_papers/terrace/terrace.pdf">Object Storage on CRAQ High-throughput chain replication for read-mostly workloads</a></p>
</blockquote>
<p>本文主要提出了一种区别于主从备份容错方式的链式复制容错方式，通过将备份服务器组织链结构，实现数据的冗余备份。本文中的CRAQ(Chain Replication with Apportioned Queries) 是在链式复制（Chain Replication）的基础上改进而来的，两者针对对象存储系统设计实现（object-based storage system），对象存储系统主要包括一下两个操作原语：</p>
<ol>
<li>write(objID, V)：更新某个obj关联的值</li>
<li>read(objID): 获取某个obj的值</li>
</ol>
<p>对象存储只需要考虑修改读取特定对象的请求顺序，而并不需要考虑整个数据库，降低了保证一致性的成本</p>
<span id="more"></span>
<h3 id="链式复制（CR-Chain-Replication）"><a href="#链式复制（CR-Chain-Replication）" class="headerlink" title="链式复制（CR:Chain Replication）"></a>链式复制（CR:Chain Replication）</h3><p>链式复制的原理容易理解，通过将多个存储数据副本的服务器组织成链式形式，在响应读取、更新请求时在链上进行传播处理，拓扑结构如下图所示</p>
<ol>
<li>所有的<strong>写请求wirte</strong> 由Head节点服务器处理，计算得到状态后，在链上传播直到tail节点提交后，向client返回ack完成写请求</li>
<li>所有<strong>读请求read</strong> 由Tail节点服务器处理，直接查询本地值返回client</li>
</ol>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E9%93%BE%E5%BC%8F%E5%A4%8D%E5%88%B6%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220705150739033.png" class="" title="image-20220705150739033">
<p>其中链式复制保证<strong>强一致性（strong consistency）</strong></p>
<ul>
<li>所有写请求只有在TAIL提交后才对client可见</li>
<li>所有的读请求均在TAIL节点处理，返回TAIL数据</li>
</ul>
<p>链式复制的特殊请求处理机制保证了所有请求按照其发出的顺序处理，所以实现了<strong>强一致性</strong>。</p>
<h4 id="请求重发"><a href="#请求重发" class="headerlink" title="请求重发"></a>请求重发</h4><blockquote>
<p>While it would be possible to ensure that each request reaching the storage service is guaranteed to be performed, the end-to-end argument suggests there is little point in doing so.</p>
</blockquote>
<p>论文中有意思的一点是认为由服务器保证接收到的请求一定被处理是”<strong>得不偿失</strong>“的</p>
<ul>
<li>由客户端在请求超时一段时间后，向服务器重新发送请求</li>
<li>链式复制容错实现机制中，可能会丢弃一部分服务器接收到但未处理的请求</li>
</ul>
<p>由客户端重发请求引出另外一个问题：如果请求超时是由于客户端未收到服务器处理成功响应，重新发送请求会导致重复执行操作，需要<strong>保证操作的幂等性（idempotent）</strong></p>
<ol>
<li>读操作：读操作不改变系统状态，是幂等的</li>
<li>写操作：论文中没有写怎么解决，只是说可以通过客户端查询判断是否更新已经在server执行，从而避免重发请求</li>
</ol>
<h4 id="应对失效"><a href="#应对失效" class="headerlink" title="应对失效"></a>应对失效</h4><p>要理解CR如何应对实现，首先要理解链上的server的下两个状态</p>
<ol>
<li>$Hist_{objID}$：当前副本已提交的状态更新列表（实际上的待处理写请求，所有server均维护自己的该状态），其中尾节点的$Hist^{tail}_{objID}$定义为<strong>全局已提交的写请求</strong></li>
<li>$Pending_{objID}$：<strong>待处理的读取请求列表</strong>，只有tail节点存储当前状态</li>
</ol>
<p>不同节点之间的hist状态满足以下<strong>Update Propagation Invariant性质</strong>：即后继节点的待提交状态更新是前驱节点的前缀子集（从读请求从头节点向后传播容易理解）</p>
<script type="math/tex; mode=display">
Hist^i_{objID} \preceq Hist^j_{objID},其中i ≤ j</script><p>针对不同节点的失效，CR分情况处理（CR假设了一个永不失效的master节点负责维护节点信息，处理失效情况。实际上master<br>是由paxos算法实现多主从容错）</p>
<ol>
<li>头节点失效: 后续节点取代它成为头节点</li>
<li>尾节点失效：前驱节点成为新的尾节点</li>
<li>中间节点失效：类似于从链表中删除节点操作，更新服务器拓扑结构</li>
</ol>
<p>其中情况2会导致尾节点的待处理请求丢失，然而这在系统中是允许的（把重传的职责交给client）。由于上述Update Propagation Invariant性质的保证，<strong>不会丢失写请求</strong>。</p>
<p>情况3会导致<strong>忘记更新传播</strong>的情况</p>
<ul>
<li>T-节点将更新传播给了T节点，T节点还未来得及传播给T+,T节点失效，导致T-认为已将更新向后传播，T+实际上未收到更新的情况</li>
<li>由master节点在维护链拓扑时，比较T-和T+的$Hist_{objID}$列表，找出两者缺失部分，提醒T-节点重传</li>
</ul>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ol>
<li>尾节点处理所有读请求，负载过大</li>
<li>写请求按照链式传播，导致写请求的延迟过高（理论上链越长，更新延迟越大，相当于增加了server反而降低了性能）</li>
</ol>
<h3 id="CRAQ（Chain-Replication-with-Apportioned"><a href="#CRAQ（Chain-Replication-with-Apportioned" class="headerlink" title="CRAQ（Chain Replication with Apportioned"></a>CRAQ（Chain Replication with Apportioned</h3><p>Queries）</p>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E9%93%BE%E5%BC%8F%E5%A4%8D%E5%88%B6%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220705160141244.png" class="" title="image-20220705160141244">
<p>CRAQ针对CR只能在尾节点处理读请求的问题进行了改进，实现了任意节点的读取，缓解了负载问题</p>
<ol>
<li><p>每个副本server为对象维护一个原子递增的版本号，同时存储多个版本的对象值，每个版本的对象值带上一个是否提交的标志（clean or dirty）</p>
</li>
<li><p>当副本server收到修改对象请求（还是从头向后传播），增加版本号大小并将更新值添加到版本值列表中</p>
<ul>
<li><p>若当前节点非TAIL，将当前值标记为dirty,向后继节点传播</p>
</li>
<li><p>当前节点为TAIL，标记当前节点为clean（完成更新提交），反向沿链传播ack，接收到ack的节点，更新值状态为clean，并删除存储的历史版本值</p>
<img src="/2022/07/13/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E9%93%BE%E5%BC%8F%E5%A4%8D%E5%88%B6%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/image-20220705161634798.png" class="" title="image-20220705161634798">
</li>
</ul>
</li>
<li><p>当副本server首先读取对象请求，根据最新版本对象值是否为clean执行不同操作</p>
<ul>
<li>clean：直接响应client请求</li>
<li>dirty：询问tail节点，获得最新version的clean值，响应client请求（反向ack还未传播完全）</li>
</ul>
</li>
</ol>
<h4 id="应对失效-1"><a href="#应对失效-1" class="headerlink" title="应对失效"></a>应对失效</h4><p>与CR一致，区别在于管理和容错的master节点不再自己实现（paxios），而是借由第三方分布式协调服务服务实现，如zookeeper等（<del>懒狗，不重复造轮子是吧</del>）</p>
<h4 id="相对于CR的改进"><a href="#相对于CR的改进" class="headerlink" title="相对于CR的改进"></a>相对于CR的改进</h4><p>首先多版本的对象值能够根据应用需求，实现不同的一致性保证（<del>不要更好的一致性，当然是为了更好的性能</del>）</p>
<ol>
<li>强一致性：论文中描述的即保证强一致性的操作，即只读clean数据</li>
<li>最终一致性：允许节点返回未提交的新数据，但是单个节点不能读到历史数据（在CRAQ中，即允许读取dirty数据）</li>
<li>带有最大不一致要求的最终一致性：允许节点返回未提交的新数据，但是需要满足一定约束，（例如单个客户端不能读到历史数据，即每次读取version必须单调递增）</li>
</ol>
<p>最后也是最重要的<strong>性能提升</strong></p>
<ol>
<li>Read-Mostly Workloads（读操作为主的负载）：读操作可以在所有节点执行，吞吐量随着server增加而增加</li>
<li>Write-Heavy Workloads（写操作为主的负载）：写操作过多，会导致大部分非tail节点的数据均为dirty，转而大部分查询请求询问尾节点，然而此情况仍然优于所有读请求由尾部处理的情况</li>
</ol>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p><strong>CR和CRAQ中为什么要使用master节点管理和监控链上节点状态？</strong></p>
<p>如果不使用外部节点，我们的只能通过前驱或者后继节点相互感知，当节点失效时，由其后继或者前驱替代的方式实现容错，然而这样会出现脑裂问题</p>
<ul>
<li>当tail与前驱节点出现网络分区（CAP中的P）问题时，显而易见此时前驱节点会认为TAIL失效，自己成为tail,此时出现了两个TAIL即<strong>脑裂问题</strong></li>
<li>头节点失效类似，也会出现脑裂问题</li>
</ul>
<p>所以必须采用外部的<strong>权威节点</strong>(共识算法：raft、paxos 或分布式协调服务：zookeeper)，来监控整体状态，决定谁是tail或者head</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>正如MIT6.824中所说的当我们使用多个服务器提供服务时，我们首先应该考虑使用N个服务器是否能够带来N倍的性能/吞吐量提升，或者线性提升，然而实际情况中受限于算法实现、一致性的保证、服务器拓扑，性能提升往往是低于预期的。</p>
<p>CRAQ通过简单的链式结构+符合直觉的错误恢复机制，实现了容错备份，但是性能部分有所取舍</p>
<ol>
<li>写入沿链传播，随着链长度的增加，写入延迟增加（增加服务器反而性能下降）</li>
<li>读取通过一系列优化，近似实现了任意节点的随机读取（增加服务器，近似线性提升处理性能）</li>
</ol>
<p>然而链式更新传播，相较于raft、zookeeper等的由master节点广播传播的方式，降低了master节点通信负载</p>
<ul>
<li>master节点广播形式需要传n-1个节点，链式传播每个节点只需要负责传播自己的后继节点</li>
</ul>
<p><del>zookeeper、CRAQ以及GFS的例子，告诉我们一个道理：三个和尚没水喝，如果没必要别搞分布式，费力不讨好</del></p>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>复制策略</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang并发控制总结</title>
    <url>/2022/09/06/Golang%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="Golang并发控制总结"><a href="#Golang并发控制总结" class="headerlink" title="Golang并发控制总结"></a>Golang并发控制总结</h2><blockquote>
<p>写在开头：最近用go做MIT6.824课程作业时，涉及到大量基于golang的并发控制，但是由于不熟悉golang语言以及相关并发控制手段，导致出现了大量的bug，影响了实现进程，因此产生了总结学习golang并发控制的想法</p>
</blockquote>
<p>目前大厂的后端开发大量的从java转向go，很大一部分原因是由于go所具备的高并发、高性能、容易开发等性质，可以说go并发控制是学习go内容中最为重要的一部分（<del>java并发我都没学会，直接学go，看出我的诚意了吧</del>），下面的总结学习主要基于golang官网的Effective Go的<a href="https://go.dev/doc/effective_go#concurrency">cocurrency章节</a>。</p>
<span id="more"></span>
<h3 id="何为并发控制？"><a href="#何为并发控制？" class="headerlink" title="何为并发控制？"></a>何为并发控制？</h3><blockquote>
<p>In <a href="https://en.wikipedia.org/wiki/Information_technology">information technology</a> and <a href="https://en.wikipedia.org/wiki/Computer_science">computer science</a>, especially in the fields of <a href="https://en.wikipedia.org/wiki/Computer_programming">computer programming</a>, <a href="https://en.wikipedia.org/wiki/Operating_systems">operating systems</a>, <a href="https://en.wikipedia.org/wiki/Multiprocessor">multiprocessors</a>, and <a href="https://en.wikipedia.org/wiki/Database">databases</a>, <strong>concurrency control</strong> ensures that correct results for <a href="https://en.wikipedia.org/wiki/Concurrent_computing">concurrent</a> operations are generated, while getting those results as quickly as possible. -wikipedia</p>
</blockquote>
<p>并发控制本质上是通过一定的手段保证多个并发进行操作最终产生正确的结果，并且尽可能的保证性能，所以学习并发控制主要从两个角度入手：</p>
<ul>
<li><p>如何实现并发？</p>
</li>
<li><p>有哪些控制并发的手段？</p>
</li>
</ul>
<p>编程语言层面的并发控制可以理解为通过一定手段保证多个操作共享变量的线程正确执行，并且保证性能，这里的两个角度为</p>
<ul>
<li>多线程实现并发：go中的Goroutines</li>
<li>多种控制并发的手段：mutex，channel，waitGroup等</li>
</ul>
<h3 id="golang并发控制"><a href="#golang并发控制" class="headerlink" title="golang并发控制"></a>golang并发控制</h3><p>golang并发控制基于：”Do not communicate by sharing memory; instead, share memory by communicating.” 的思想，即并发线程之间不通过共享内存进行通信，而是通过通信实现共享内存，对此我的理解是：</p>
<ul>
<li>传统的并发控制手段是共享资源+锁的形式，实现互斥访问</li>
<li>golang舍弃了上述思想，采用通信的方式，将共享资源的访问变为序列化处理的通信传递</li>
</ul>
<p>引用 <a href="https://go.dev/talks/2012/waza.slide#19">演讲：Concurrency is not parallelism</a> ppt中的例子(两个取书烧书线程，分别从书籍堆中取书运输到火堆烧毁)，第一种思路如下图：</p>
<ul>
<li><p>属于互斥资源，上锁两个线程互斥取书、</p>
</li>
<li><p>“火堆”属于互斥资源，双锁两个线程互斥烧书</p>
</li>
<li><p>共享资源（“书堆“）+锁实现并发控制</p>
<img src="/2022/09/06/Golang%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%80%BB%E7%BB%93/image-20220815104551093.png" class="" title="image-20220815104551093">
</li>
</ul>
<p>第二种并发控制思路如下图：</p>
<ul>
<li>三个线程：取书线程、运书线程、烧书线程</li>
<li>三个线程之间通过通信，实现并发控制</li>
</ul>
<img src="/2022/09/06/Golang%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%80%BB%E7%BB%93/image-20220815104637154.png" class="" title="image-20220815104637154">
<p>上述两种思路的区别可以总结为：</p>
<ol>
<li>传统思路属于并行的思路，一个活多个人干，人多效率就高，但问题是互斥问题会导致性能下降（纵向）</li>
<li>golang思路属于将一个任务拆解，分成不同阶段，多个人各司其职，避免了互斥资源访问的性能下降,问题是等待通信的延迟（横向）</li>
</ol>
<p>整合上述两种思想的细粒度并发+并行（双cpu）：</p>
<img src="/2022/09/06/Golang%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%80%BB%E7%BB%93/image-20220815105310603.png" class="" title="image-20220815105310603">
<h4 id="Goroutines"><a href="#Goroutines" class="headerlink" title="Goroutines"></a>Goroutines</h4><p>Go中类似于”线程“的概念并发调度单位定义为Goroutine：与其它 Go 协程并发运行在同一地址空间的函数。Goroutine于线程的区别点在于：</p>
<ol>
<li>Goroutine相当于”轻量级“线程，启动时只占用少量的栈空间（java线程在启动时会分配固定大小的占空间）</li>
<li>Goroutine与内核线程的数量对应关系是一对一或者多对一，Goroutine的调度由Go管理，避免了内核线程调度上下文切换的成本</li>
<li>Goroutine更像一个独立运行的函数、操作等，线程更像是一个单独运行的轻量级”进程“</li>
</ol>
<p>在调用前添加关键词 <code>go</code>即可启动一个Goroutine：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> list.Sort() </span><br><span class="line"><span class="comment">//匿名函数</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    time.Sleep(delay)\</span><br><span class="line">    fmt.Println(message)</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure>
<p>使用goroutine经常出现的一个错误如下：</p>
<ol>
<li>由于i为共享变量，Goroutine执行之前主程序可能已经进入下一轮循环，导致输出错误</li>
<li>解决方案为：传参 或者 赋值局部变量</li>
</ol>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">//错误代码</span></span><br><span class="line"><span class="keyword">for</span> i:=<span class="number">1</span>;i &lt; <span class="number">10</span>;i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        fmt.Println(i)</span><br><span class="line">    &#125;()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//正确代码</span></span><br><span class="line"><span class="keyword">for</span> i:=<span class="number">1</span>;i &lt; <span class="number">10</span>;i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(i)</span></span> &#123;</span><br><span class="line">        fmt.Println(number)</span><br><span class="line">    &#125;(number <span class="keyword">int</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i:=<span class="number">1</span>;i &lt; <span class="number">10</span>;i++ &#123;</span><br><span class="line">    number := i</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        fmt.Println(number)</span><br><span class="line">    &#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h4><p>Channel类似于Unix中的管道概念，提供不同Goroutine之间的通信，通过make函数初始化，其中Channel在初始化时执行</p>
<ul>
<li>在访问无缓冲管道和缓冲写入已满的管道时，访问Goroutine会阻塞</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">ci := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)            <span class="comment">// unbuffered channel of integers</span></span><br><span class="line">cj := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">0</span>)         <span class="comment">// unbuffered channel of integers</span></span><br><span class="line">cs := <span class="built_in">make</span>(<span class="keyword">chan</span> *os.File, <span class="number">100</span>)  <span class="comment">// buffered channel of pointers to Files</span></span><br><span class="line"><span class="comment">//写入管道</span></span><br><span class="line">ci &lt;- <span class="number">1</span></span><br><span class="line"><span class="comment">//读取管道</span></span><br><span class="line">i &lt;- ci</span><br></pre></td></tr></table></figure>
<p>通过Channel实现的最简单的同步例子如下：</p>
<ul>
<li>主线程调用排序Goroutine后等待读取管道</li>
<li>排序Goroutine排序完成后，写入管道</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">c := make(chan <span class="keyword">int</span>)  <span class="comment">// Allocate a channel.</span></span><br><span class="line"><span class="comment">// Start the sort in a goroutine; when it completes, signal on the channel.</span></span><br><span class="line"><span class="function">go <span class="title">func</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    list.Sort()</span><br><span class="line">    c &lt;- <span class="number">1</span>  <span class="comment">// Send a signal; value does not matter.</span></span><br><span class="line">&#125;()</span><br><span class="line">doSomethingForAWhile()</span><br><span class="line">&lt;-c   <span class="comment">// Wait for sort to finish; discard sent value.</span></span><br></pre></td></tr></table></figure>
<p>结合select可实现异步阻塞通信同步功能：</p>
<ul>
<li>监听case管道，读取到内容，则执行相关操作</li>
<li>无default时，阻塞直到读到内容；有default，执行default，继续向下执行</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fibonacci</span><span class="params">(c, quit <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	x, y := <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> c &lt;- x:</span><br><span class="line">			x, y = y, x+y</span><br><span class="line">		<span class="keyword">case</span> &lt;-quit:</span><br><span class="line">			fmt.Println(<span class="string">&quot;quit&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">	quit := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">			fmt.Println(&lt;-c)</span><br><span class="line">		&#125;</span><br><span class="line">		quit &lt;- <span class="number">0</span></span><br><span class="line">	&#125;()</span><br><span class="line">	fibonacci(c, quit)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发送者可以主动调用<code>close()</code>关闭管道，接收端for循环读取会终止：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fibonacci</span><span class="params">(n <span class="keyword">int</span>, c <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">	x, y := <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">		c &lt;- x</span><br><span class="line">		x, y = y, x+y</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">close</span>(c)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">10</span>)</span><br><span class="line">	<span class="keyword">go</span> fibonacci(<span class="built_in">cap</span>(c), c)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> c &#123;</span><br><span class="line">		fmt.Println(i)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="sync"><a href="#sync" class="headerlink" title="sync"></a>sync</h4><p>sync包提供了包含锁在内的一系列并发控制手段，包括sync.Mutex、sync.RWMutex、sync.Cond、sync.WaitGroup等</p>
<h5 id="sync-Mutex"><a href="#sync-Mutex" class="headerlink" title="sync.Mutex"></a>sync.Mutex</h5><p>golang中的锁，提供上锁、解锁等操作方法</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Mutex)</span> <span class="title">Lock</span><span class="params">()</span> 			//上锁</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Mutex)</span> <span class="title">TryLock</span><span class="params">()</span> <span class="title">bool</span>  //尝试上锁</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *Mutex)</span> <span class="title">Unlock</span><span class="params">()</span>		//解锁</span></span><br></pre></td></tr></table></figure>
<h5 id="sync-RWMutex"><a href="#sync-RWMutex" class="headerlink" title="sync.RWMutex"></a>sync.RWMutex</h5><p>读写互斥锁，在普通锁接口上提供了“读”锁上锁解锁操作</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rw *RWMutex)</span> <span class="title">RLock</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rw *RWMutex)</span> <span class="title">RUnlock</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<h5 id="sync-Once"><a href="#sync-Once" class="headerlink" title="sync.Once"></a>sync.Once</h5><p>确保函数只执行一次的接口（例如初始化），调用对应Do方法，传入调用的函数</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> once Once					<span class="comment">//初始化</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(o *Once)</span> <span class="title">Do</span><span class="params">(f <span class="keyword">func</span>()</span>)		//执行<span class="title">f</span>函数（保证只执行一次）</span></span><br></pre></td></tr></table></figure>
<h5 id="sync-WaitGroup"><a href="#sync-WaitGroup" class="headerlink" title="sync.WaitGroup"></a>sync.WaitGroup</h5><p>该方法实现等待一系列的Goroutines的退出，基本接口如下:</p>
<ul>
<li>通过add()方法增加WaitGroup counter数量，done()方法表明Goroutine之一完成，减少WaitGroup counter数量</li>
<li>wait()方法等待 WaitGroup counter为0</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(wg *WaitGroup)</span> <span class="title">Add</span><span class="params">(delta <span class="keyword">int</span>)</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(wg *WaitGroup)</span> <span class="title">Done</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(wg *WaitGroup)</span> <span class="title">Wait</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<p>具体的使用例子：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	<span class="keyword">var</span> urls = []<span class="keyword">string</span>&#123;</span><br><span class="line">		<span class="string">&quot;http://www.golang.org/&quot;</span>,</span><br><span class="line">		<span class="string">&quot;http://www.google.com/&quot;</span>,</span><br><span class="line">		<span class="string">&quot;http://www.example.com/&quot;</span>,</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> _, url := <span class="keyword">range</span> urls &#123;</span><br><span class="line">		<span class="comment">// Increment the WaitGroup counter.</span></span><br><span class="line">		wg.Add(<span class="number">1</span>)</span><br><span class="line">		<span class="comment">// Launch a goroutine to fetch the URL.</span></span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(url <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">			<span class="comment">// Decrement the counter when the goroutine completes.</span></span><br><span class="line">			<span class="keyword">defer</span> wg.Done()</span><br><span class="line">			<span class="comment">// Fetch the URL.</span></span><br><span class="line">			http.Get(url)</span><br><span class="line">		&#125;(url)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// Wait for all HTTP fetches to complete.</span></span><br><span class="line">	wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="sync-Cond"><a href="#sync-Cond" class="headerlink" title="sync.Cond"></a>sync.Cond</h5><p>条件变量实现（golang建议能够通过Channel实现同步，尽量避免使用条件变量），需要与Locker配合使用：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewCond</span><span class="params">(l Locker)</span> *<span class="title">Cond</span>	//返回一个使用锁<span class="title">l</span>的条件变量</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cond)</span> <span class="title">Broadcast</span><span class="params">()</span>		//唤醒等待条件变量的所有<span class="title">Goroutine</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cond)</span> <span class="title">Signal</span><span class="params">()</span>			//唤醒一个等待条件变量的<span class="title">Goroutine</span></span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cond)</span> <span class="title">Wait</span><span class="params">()</span>			//等待条件变量</span></span><br></pre></td></tr></table></figure>
<p>基本的使用方法为：</p>
<ul>
<li>在修改条件时需要上锁，调用Broadcast()或Signal()不必须上锁</li>
<li>调用wait()时首先上锁，wait()方法会将当前Goroutine添加到唤醒列表，释放锁阻塞当前Goroutine等待条件变量（Broadcast或Signal），上锁退出wait()方法</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cond)</span> <span class="title">Wait</span><span class="params">()</span></span> &#123;</span><br><span class="line">	c.checker.check()</span><br><span class="line">	t := runtime_notifyListAdd(&amp;c.notify)</span><br><span class="line">	c.L.Unlock() 							<span class="comment">//上面上锁的原因是并发添加等待Goroutine需要互斥执行</span></span><br><span class="line">	runtime_notifyListWait(&amp;c.notify, t)	<span class="comment">//释放锁后，等待条件变量</span></span><br><span class="line">	c.L.Lock() 								<span class="comment">//重新上锁，目的是与修改条件操作互斥</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第一次学的时候没搞明白为什么要有锁，深入思考下发现，本质是为了<strong>保证条件变更和根据条件进行操作的Goroutine的互斥</strong>，避免操作时条件发生变更，不满足操作条件，此方法带来两个问题：</p>
<ol>
<li>等待线程被唤醒后，条件可能发生该改变（因为等待时释放了锁），所以需要循环判断</li>
<li>同时只有一个等待Goroutine能在Wait()唤醒后进行执行</li>
</ol>
<p>所以wait()方法的使用方式为：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">c.L.Lock()</span><br><span class="line"><span class="keyword">for</span> !condition() &#123;</span><br><span class="line">    c.Wait()</span><br><span class="line">&#125;</span><br><span class="line">... <span class="built_in">make</span> use of condition ...</span><br><span class="line">c.L.Unlock()</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>golang并发控制学起来并不复杂，主要是理解其并发控制思路+学习常用的并发控制接口，结合官方文档以及官网提供的一些学习资料学下来并不难（<del>别看csdn</del>）</p>
]]></content>
      <categories>
        <category>Golang编程</category>
      </categories>
      <tags>
        <tag>编程总结</tag>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>Spanner：“真”分布式数据库</title>
    <url>/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spanner%EF%BC%9A%E2%80%9C%E7%9C%9F%E2%80%9D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h2 id="Spanner：“真”分布式数据库"><a href="#Spanner：“真”分布式数据库" class="headerlink" title="Spanner：“真”分布式数据库"></a>Spanner：“真”分布式数据库</h2><blockquote>
<p><a href="https://dl.acm.org/doi/abs/10.1145/2491245">Spanner: Google’s Globally Distributed Database</a></p>
</blockquote>
<p>Spanner作为Google开发的全球分布式数据系统，具备外部一致性、支持分布式事务、多副本容错等特性，相较于Aurora，更具“分布式”特征。</p>
<h4 id="从何而来？"><a href="#从何而来？" class="headerlink" title="从何而来？"></a>从何而来？</h4><p>论文的intro介绍Spanner是从类似于MegaStore的基于BigTable的kv存储系统演化而来的，MegaStore虽然能够很好得解决大部分客户的数据存储需求，但还存在一部分问题</p>
<ol>
<li>对于关系模型的支持较差，难以支持复杂的、经常变化的模型</li>
<li>无法在使用大范围副本的同时保证强一致性，并且支持分布式事务</li>
</ol>
<p>针对以上问题，一个支持更强关系模式的多时间版本的数据库-Spanner诞生了。</p>
<span id="more"></span>
<h4 id="基本架构与存储设计"><a href="#基本架构与存储设计" class="headerlink" title="基本架构与存储设计"></a>基本架构与存储设计</h4><p>类似于Aurora,Spanner同样采用了多数据中心+多server的架构模式，一个Spanner部署称为一个universe，一个universe跨越不同的数据中心(Zone)，每个Zone内部有多个span server，其中架构中不同职责角色如下图</p>
<ul>
<li>universe maseter：管理所有的zone信息</li>
<li>palcament driver：负责跨zone的数据移动</li>
<li>zone master：管理当前Zone的所有span server</li>
<li>location proxy：通知客户端访问数据所在的spanserver位置</li>
<li>span server：存储并为客户端提供数据</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spanner%EF%BC%9A%E2%80%9C%E7%9C%9F%E2%80%9D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220719155057293.png" class="" title="image-20220719155057293">
<p>每个span server的内部组成如下图所示，自下而上进行分析：</p>
<ul>
<li><p>底层数据存储在Colossus（基于GFS改进的文件系统）上</p>
</li>
<li><p>底层数据以类似于bigtable中<strong>tablet</strong>的数据结构为单位进行存储</p>
<script type="math/tex; mode=display">(key:string, timestamp:int64) -> string</script></li>
<li><p>每个server存储100-1000个tablet，每个tablet实现一个基于Paxos的状态机，用来维持副本的一致性，一个tablet的所有副本组成一个<strong>Paxos Group</strong>（意味着同步单位为tablet）</p>
</li>
<li><p>每个span server维护一个<strong>lock table</strong>，维护基于两阶段锁实现的并发控制锁信息</p>
</li>
<li><p>对于每个Paxos Group中被选为leader的span server，在lock table上层同时会实现一个transaction manager，用来协调和管理分布式事务</p>
</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spanner%EF%BC%9A%E2%80%9C%E7%9C%9F%E2%80%9D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220719160204168.png" class="" title="image-20220719160204168">
<h4 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h4><p>Spanner的数据库模型来自于BigTable的数据模型，区别关系型数据模型，论文中称为Directory Table（<strong>directory-bucketed key-value mappings</strong>），一种类似于关系模型的kv存储模型</p>
<ul>
<li>Directory是一系列key的集合（bulk），是系统放置和同步备份的基本单位</li>
<li>每个table的列为key，行为key对应value(这点是关系模型的特征)，每个key必须定义name</li>
<li>每个表由主键+非主键定义，一张表可以理解为是<strong>主键-&gt;非主键的映射关系</strong>(这点是kv模型的特征)</li>
</ul>
<p>如下图所示，创建了Users和Albums表，其中Albums表是Users表的子表</p>
<ul>
<li>从图中可知，表项按照类似目录的形式进行<strong>交错存储</strong></li>
<li>交错存储考虑到了不同表之间关系，在分布式存储环境下访问具备<strong>locality</strong>性质（我理解的是通常有关系的表要一起访问，不如就交错存储在一起，论文中一部分出发点是为了magastore对于跨行事务支持较差的问题）</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spanner%EF%BC%9A%E2%80%9C%E7%9C%9F%E2%80%9D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220719163022272.png" class="" title="image-20220719163022272">
<h4 id="分布式事务实现"><a href="#分布式事务实现" class="headerlink" title="分布式事务实现"></a>分布式事务实现</h4><p>Spanner中最难理解的一部分内容就在这一点，通过TrueTime API+分布式锁+Paxios的方式实现了满足强一致性的分布式事务支持，其中设计细节和实现细节较多，理解不到位，仅仅整理一下理解到的内容。</p>
<p><strong>True Time API</strong></p>
<p>Spanner通过True Time API为分布式系统提供全局时间戳，在全局时间戳的基础上实现了分布式事务的线性一致性（linearizability）。其中True Time API提供如下图的几个接口：</p>
<ol>
<li>TT.now()：获取一个当前的时间范围，保证当前时间一定在范围内</li>
<li>TT.after(t)：判断时间t是否已经过去</li>
<li>TT.before(t)：判断时间t是否还未到来</li>
</ol>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spanner%EF%BC%9A%E2%80%9C%E7%9C%9F%E2%80%9D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220720142153487.png" class="" title="image-20220720142153487">
<p><strong>分布式事务</strong></p>
<p>Spanner分布式事务基于两阶段提交的思想，并结合全局时间戳分配+锁实现分布式事务的并发控制，基本的阶段提交过程如下：</p>
<ol>
<li>首先由客户端选择一个Coordinator Group(主块)，将提交信息(以及选择的Coordinator Group)和写入内容发送给所有的Participant Group中的leader（简单描述，首先选一个主group，然后告诉所有group我要提交了，且选的主group是他）</li>
<li>所有的non-coordinator-participant leader首先获取写锁，并生成一个<strong>大于先前所有事务时间戳</strong>的<strong>prepare timestamp</strong>，写入到Paxios日志中后，通知coordinator-participant leader。coordinator-participant leader同时也要获得写锁，但是不生成prepare timestamp</li>
<li>由coordinator-participant leader根据接收到的prepare timestamp，确定一个commit timestamp后，将commit信息写入Paxios日志中<ul>
<li>该commit timestamp确保大于所有的准备时间戳且大于coordinator-participant leader收到客户端发送的提交信息时<strong>TT.now().latest</strong>时间（保证事务时间戳单增，且事务开始时间一定大于事务发起时间）</li>
</ul>
</li>
<li>coordinator-participant leader等待直到TT.after(commit timestamp)为true后，发送commit信息给所有的non-coordinator-participant leader，执行提交操作，并将提交信息记录到Paxios日志中，释放锁资源</li>
</ol>
<p>上述描述过于复杂，从两阶段提交的角度简单理解为：</p>
<ol>
<li>准备阶段：主leader联系所有的协作leader，准备提交事务，获取所有的准备时间戳</li>
<li>提交阶段：主leader确定提交时间戳后，等到时间过了确定的时间戳后，发送提交信息，完成提交</li>
</ol>
<p><strong>考虑时间戳的两阶段提交</strong></p>
<p>相较于普通的两阶段提交，Spanner的实现中考虑了大量的时间戳分配关系，通过时间戳的分配，保证<strong>性质</strong>：<strong>若事务T2开始于T1提交以后，则其提交时间戳必须小于T1提交时间戳</strong>，该性质由以下两个性质保证</p>
<ol>
<li>start：事务开始时间戳不会小于事务到达系统时调用<strong>TT.now().latest</strong>的时间（事务打上开始时间戳时，对应时间保证已经过去）</li>
<li>commit wait：事务的真正提交（或者说提交结果为客户可见）的时间为TT.after(事务结束时间戳)为true以后（事务真实提交时，保证提交时间戳对应的真实事件已经过去）</li>
</ol>
<ul>
<li>“已经过去”指的是TT.after(t)为True</li>
</ul>
<p>简单理解就是</p>
<ol>
<li>start性质保证：事物的提交时间戳不会早于开始时间戳</li>
<li>commit wait性质保证：后续发生事务的开始时间戳不可能小于用户已将看到提交事务的提交的时间戳</li>
</ol>
<p>通过以上两个执行保证了<strong>外部一致性</strong></p>
<p><strong>只读事务的一致性保证</strong></p>
<p>只读事务保证一致性实际上就是保证在某个时间点上的读读到了当前时间点的最新数据，在Spanner中这一点同样是通过时间戳实现，基本思路如下：</p>
<ol>
<li>为只读事务分配时间戳（快照读相当于自带时间戳的只读事务）：若只读事务只涉及一个Paxios Group，则直接由Group leader为其分配时间戳；涉及多个Paxios Group，直接将时间戳设置为最新即TT.now().latest</li>
<li>根据时间戳查找对应新旧程度的副本，保证读取副本的最新时间戳($t_{safe}$)大于等于当前时间戳（如果没有就需要阻塞更新副本）</li>
</ol>
<p>由于以上根据时间戳进行读的特性，RO事务不需要上锁（lock-free），这极大的降低了只读事务的处理速度，同时避免了只读事务影响其他写事务的进行</p>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spanner%EF%BC%9A%E2%80%9C%E7%9C%9F%E2%80%9D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220720155852284.png" class="" title="image-20220720155852284">
<h4 id="其他实现细节"><a href="#其他实现细节" class="headerlink" title="其他实现细节"></a>其他实现细节</h4><p><strong>选主过程中的时间戳分配问题</strong></p>
<p>每个Paxios leader带有一个超时时长为10s的lease，由于leader需要维护大量的状态信息（锁表、时间戳等），leader短时间交换的成本得不偿失，Spanner设计的Paxios leader机制在我看来更像是一个长期leader，可通过以下两种方式延长lease:</p>
<ol>
<li>每次执行写入事务时，延长lease</li>
<li>在lease快过期时，leader主动向其他server发送请求延长lease</li>
</ol>
<p>由于每个leader维护一个当前最大时间戳，在leader切换时Spanner保证新leader的时间戳与此时间戳重叠</p>
<ul>
<li>老Leader在退位之前，必须等待TT.after(最大时间戳)为True，即等到True Time Api不会生成小于等于老Leader维护时间戳的时候，老Leader再进行退位操作</li>
</ul>
<h3 id="Spanner-vs-Aurora-vs-Frangampani"><a href="#Spanner-vs-Aurora-vs-Frangampani" class="headerlink" title="Spanner vs Aurora vs Frangampani"></a>Spanner vs Aurora vs Frangampani</h3><p>Spanner最难理解一点是通过True Time API实现的外部一致性，在于Aurora对比思考过程中，发现两个系统均实现了强一致性保证，可Aurora并没有用到Spanner用到的True TIme API也没用到分布式事务涉及到的两阶段提交、分布式锁，这点让我想了很久才明白具体区别点在哪。</p>
<p>首先还是要明白Linearizability和 Serializability的区别与联系（已经看了多少次了，总是忘记）</p>
<ul>
<li>Linearizability（线性一致性）：分布式系统中的概念，强调的是能为分布式系统中的发生事务安排全局认可的一个合理的顺序，因为分布式系统并没有类似单机系统全局时钟等的决定发生在不同机器上的事务的顺序，对应分布式系统CAP中的C。</li>
<li>Serializability（可序列化）：单机系统中的概念，指的是一系列并发事务之间通过并发控制，使得并发的事务按照一定的顺序（这个顺序是随机的，却决于锁和事务实现机制），执行结果满足数据库约束。</li>
</ul>
<p>为什么分布式系统中一点要确定一个合理的执行顺序？分布式系统中如果没有全局顺序，不同机器副本上由于网络延迟、宕机等问题，会导致不同副本上操作执行顺序不一致，访问时可能看到不一致的结果（看到过期数据、看到错误数据等）。</p>
<p>通过上述定义，我们可以明白两个性质实际上是两个不同的问题，同样也对应着不同的解决方案</p>
<ol>
<li>Linearizability（线性一致性）：通过Spanner类似的全局时钟或者Aurora类似的自增日志号，实现分布式事务操作顺序的判断</li>
<li>Serializability（可序列化）：单机数据库往往通过锁机制实现并发控制，从而实现一定程度的可序列化</li>
</ol>
<p>当单机数据库迁移到分布式环境中时，需要解决上述两个问题</p>
<ol>
<li>spanner：采用了 全局时钟 + 分布式锁实现</li>
<li>Aurora：采用全局自增编号解决了Linearizability问题，但是并没有其他机制实现并发控制问题，这是为什么？</li>
<li>Frangapani：采用了分布式锁实现解决了并发控制问题，但是没有机制实现Linearizability的问题，这是为什么？</li>
</ol>
<p>原因就在于:</p>
<ol>
<li>Aurora相较于Spanner采用的“伪分布式”，写操作只通过一个server执行，通过log自增即解决了并发控制的问题；</li>
<li>Frangapani同样是“伪分布式”，虽然写可以分布于不同的server，但是底层存储抽象相当于单机磁盘存储，不涉及多副本同步，所以只控制并发即可</li>
<li>Spaner的写操作分布于不同的机器之上，是真“分布式”，即“写分布”+“存储分布”，所以即需要分布式控制也需要单机并发控制。</li>
</ol>
<h4 id="全局顺序-vs-并发控制"><a href="#全局顺序-vs-并发控制" class="headerlink" title="全局顺序 vs 并发控制"></a>全局顺序 vs 并发控制</h4><p>通过上面总结我们可以得出两种一致性的区别实际上就是全局顺序和并发控制的区别</p>
<ul>
<li>相同点：两者的相同点均是为了确定一系列事务的发生顺序</li>
<li>不同点：全局顺序是为了让分布式环境中不同副本均认可事务的发生顺序（认可的顺序不一定是真正的发生顺序，因为每个副本的时钟不可能同步），并发控制是为了让一系列有“同时发生”的事务按照一定的顺序执行</li>
</ul>
<p>其中如果不需要多个副本认可即不需要全局顺序（Frangapani），如果通过全局顺序能够间接实现并发控制（Aurora）即不需要采用类似锁的机制进行并发控制，这两个系统都通过部分<strong>“非分布式”</strong>降低了所谓的<strong>一致性实现</strong>难度</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>数据库知识对于目前阶段的我来说还是有点心有余而力不足，尽力而为。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://en.wikipedia.org/wiki/Serializability">wikipedia Serializability</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/57579023">知乎：Transaction management：可串行性（serializability）</a></li>
</ol>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>分布式数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务总结</title>
    <url>/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="分布式事务总结"><a href="#分布式事务总结" class="headerlink" title="分布式事务总结"></a>分布式事务总结</h2><p>要理解分布式事务首先要明白事务是什么，从单机事务的理解迁移到分布式事务，下面从两个角度总结单机和分布式事务</p>
<ol>
<li>单机事务 vs 分布式事务</li>
<li>如何通过并发控制保证单机分布式事务的隔离性</li>
</ol>
<h3 id="单机-分布式事务"><a href="#单机-分布式事务" class="headerlink" title="单机/分布式事务"></a>单机/分布式事务</h3><p>事务作为数据库系统读写操作的高层抽象，代表了数据库的基本操作。一个正常提供服务的数据库系统，其事务必须满足ACID四个性质，其中CI两个性质相互关联，是后续课程研究的重点。</p>
<ol>
<li>Atomic（原子性）：每个事务被看作一个不可分割的单元，要么完全成功要么完全失败，不存在两者的中间状态。数据库系统必须保证任意时刻下事务的原子性</li>
<li>Consistency（一致性）：一致性是指数据库满足某种预先定义的约束，任何数据库的操作都必须满足一致性，即从一个满足一致性的状态转移到另一个满足一致性的状态（例如：转账事务要满足转出和转入账户总金额不变）</li>
<li>Isolation（隔离性）：一系列并发进程的执行导致数据库的状态改变和按照某种线性顺序执行的状态改变相同（实际上这是serializability的定义）</li>
<li>Durable（持久性）：事务一旦提交，其对数据状态的改变不会因为意外事件的发生而丢失</li>
</ol>
<p>分布式事务可以看作事务+分布式环境，即一个执行范围跨越多个通过网络连接的不同主机的事务，分布式事务既然是事务，同样要满足ACID性质，但是由于分布式环境的复杂性，原有的事务性质保证手段在分布式环境下需要进行调整和新的设计。</p>
<span id="more"></span>
<h3 id="ACID实现"><a href="#ACID实现" class="headerlink" title="ACID实现"></a>ACID实现</h3><p>Atomic（原子性）和 Durable（持久性）两个性质逻辑上较为相似，即数据库保证事务要么完全不提交，要么完全提交后永不丢失，两条性质通常通过“WAL（Write-ahead-log）” 机制实现</p>
<ul>
<li>WAL（Write-ahead-log）：在事务操作真正影响数据之前，首先将操作写入日志中，日志持久化以后才在合适的时机进行修改操作的实际执行，在事务回退（保证A）或者恢复事务结果（保证D）时，通过日志中记录的操作恢复到对应状态</li>
<li>在单机和分布式事务中，均采用WAL机制+复制的方式保证以上性质<ol>
<li>MySQL：通过redo、undo log实现了WAL的机制</li>
<li>Amazon Aurora：分布式环境中基于redo log的WAL机制</li>
<li>Spanner：事务中所有的操作执行前，首先写入Paxios日志（基于Paxios的分布式WAL）</li>
</ol>
</li>
</ul>
<p>Consistency（一致性）和 Isolation（隔离性）在逻辑上具有关联关系，除去静态的一致性保证外（如外键约束），一致性的破坏往往是由于多个事务并发执行未保证“隔离性”，导致的前后状态不一致性，通过保证“隔离性”，可以间接的保证数据库的一致性，“隔离性”的保证涉及到并发事务的控制，即并发控制。</p>
<h3 id="一致性and隔离性"><a href="#一致性and隔离性" class="headerlink" title="一致性and隔离性"></a>一致性and隔离性</h3><p>以来自于wikipedia的转账事务为例，阐述当事务并发执行时，由于”隔离性“的控制程度的不同，带来的几个不同程度”不一致性“</p>
<ul>
<li>数据库存储两个年龄分别为20、25的用户记录  <img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93/image-20220730105034565.png" class="" title="image-20220730105034565.png">
</li>
</ul>
<ol>
<li><p>脏读（dirty read）</p>
<p>脏读指一个事务能够读到另一个未提交并发执行事务的执行结果，如下图所示。</p>
<ul>
<li>事务1查询Id=1用户的年龄，同时事务2将用户1年龄修改为21</li>
<li><p>事务1在事务2提交之前查询到其修改结果21，之后事务2回滚，用户1年龄回滚为20</p>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93/image-20220730105404765.png" class="" title="image-20220730105404765">
</li>
</ul>
</li>
<li><p>不可重复读（Non-repeatable reads)</p>
<p>不可重复读指一个事务连续两次读取一个对象时，前后状态不一致，即对象值被其他事务修改，如下图所示。</p>
 <img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93/image-20220730110701020.png" class="" title="image-20220730110701020">
</li>
<li><p>幻读（Phantom reads）</p>
<p>幻读与重复读类似，只是不再是某个对象的状态前后不一致，而是数据库表多新数据/少老数据，如下图所示</p>
<ul>
<li>事务1两次查询年龄区间之间，事务2插入了一个表项<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93/image-20220730111152975.png" class="" title="image-20220730111152975">
</li>
</ul>
</li>
</ol>
<p>针对以上的并发一致性问题，定义了不同程度的隔离性</p>
<ol>
<li><p>可串行化 Serializable</p>
<p>最强的隔离级别，保证并发事务按照特定顺序逐个执行，能够避免所有以上的问题，但是实现可串行化性质，会大幅降低数据库性能</p>
</li>
<li><p>可重复读 Repeatable reads</p>
<p>可重复读，解决脏读、不可重复读问题的隔离级别，但是会出现幻读</p>
</li>
<li><p>读已提交 Read committed</p>
<p>保证事务结果只有在提交以后才能对其他事务可见，能够解决脏读问题</p>
</li>
<li><p>读未提交 Read uncommitted</p>
<p>可以读取未提交的事务的执行结果，最低的隔离级别，无法解决脏读问题</p>
</li>
</ol>
<h3 id="并发控制（concurrency-control）"><a href="#并发控制（concurrency-control）" class="headerlink" title="并发控制（concurrency control）"></a>并发控制（concurrency control）</h3><p>上面简单介绍了Isolation的性质特点，数据库要保证上述性质必须通过并发控制实现，并发控制本质上就是对多个访问相同资源的操作/事务等进行协调，并发控制主要有以下三种策略：</p>
<ol>
<li><strong>optimistic</strong>（乐观）：允许多个并发操作同时操作数据库，当用户想要修改数据时，由数据库判断是否满足一致性和隔离性要求，若不满足则拒绝执行操作（不阻塞，在发生冲突时撤销操作）</li>
<li>pessimistic（悲观）：阻塞所有相同对象的操作（即使不会发生冲突），同一时间一个对象上只有一个事务执行</li>
<li><strong>Semi-optimistic</strong>（半乐观）：结合上述两种思想</li>
<li>乐观锁理论上阻塞更少，并发性能更高，实际上由于冲突回滚，在部分情况（写多读少？）性能不如悲观机制。也就是两种机制都有自己适应的场景</li>
</ol>
<p>主要的手段</p>
<ol>
<li>锁（locking）：为资源设置锁，通过锁控制并发操作<ul>
<li>simple locking：每一个事务需要为每一个共享变量在执行读或写之前请求锁，只有在事务完成或者终止时，才释放锁。</li>
<li>Two-Phase Locking（两阶段锁）：事务可以在执行的过程中不断申请锁，但是一旦释放锁就不能再申请锁<ul>
<li>Growing Phase：不断地根据数据，申请写锁和读锁，shrinking Phase：不断地释放锁，直到事务结束</li>
</ul>
</li>
</ul>
</li>
<li>Serialization graph checking：检验串行化图中是否存在环</li>
<li>Timestamp ordering：通过时间戳对事务执行顺序排序（分布式系统中常用来保证一致性）</li>
<li>Commitment ordering: 为Commit排序</li>
<li>Multiversion concurrency control] (MVCC) ：基于版本快照的并发隔离控制</li>
</ol>
<p>通过以上并发控制策略，保证了数据库的CI性质，如果我们要将对应问题迁移到分布式环境上问题有何不同？解决方案又有何不同？</p>
<h4 id="来到分布式事务（主要介绍两阶段提交）"><a href="#来到分布式事务（主要介绍两阶段提交）" class="headerlink" title="来到分布式事务（主要介绍两阶段提交）"></a>来到分布式事务（主要介绍两阶段提交）</h4><p>从单机到分布式事务，我们首先要找到这个改变带来了哪些新问题？</p>
<ol>
<li>计算节点分布于不同的服务器，单个事务的提交涉及到不同服务器的”子事务“的分别提交</li>
<li>多节点、节点直接通过网络通信等导致系统可能出现更多类型的错误（消息丢失、网络延迟、节点崩溃等等）</li>
</ol>
<p>既然问题发生了改变，单机并发控制的方法并不能简单的迁移到分布式环境中，提出了新的思路-<strong>Two-Phase Commit</strong></p>
<ul>
<li>引入协调者（Coorrdinator），管理事务涉及到的不同子服务器”子事务“提交，由协调者与所有参与事务服务通信判断是否满足事务提交条件</li>
<li>事务的提交过程如下所示，分为两个阶段<ol>
<li>准备阶段：协调者向所有的参与者发送准备消息，若worker可提交本地”子事务“，返回ok，否则返回not ok。协调者只有在收到所有参与者ok信息后才认为事务可以提交，进入第二阶段。（参与者在此阶段准备如锁等的提交事务的资源）</li>
<li>提交阶段：协调者向所有参与者发送提交消息，参与者收到消息后，提交事务，返回成功消息。</li>
</ol>
</li>
<li>两阶段提交存在<strong>单点失效、同步阻塞</strong>等问题</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%80%BB%E7%BB%93/image-20220715162741486.png" class="" title="image-20220715162741486">
<p>2PC故障恢复问题：</p>
<ol>
<li>协调者故障：若协调者故障不会影响正确性，提交的事务不会丢失，未提交的事务不会提交。</li>
<li>参与者/网络故障：若参与者在准备阶段发送ok之前实现或者ok信息丢失，则协调者需要设置超时机制，超时放弃事务；若参与者在发送ok之后失效，若此时协调者收到了所有ok信息，发送了commit信息，协调者必须等待失效参与者上线、失效参与者也必须能够继续执行提交，否则就会出现部分提交的问题</li>
</ol>
<p>其他分布式事务实现机制进行深入研究</p>
<h3 id="分布式中的一致性"><a href="#分布式中的一致性" class="headerlink" title="分布式中的一致性"></a>分布式中的一致性</h3><p>分布式中的一致性与数据库事务中的概念不同，主要考虑的是多副本之间状态的一致性，其实概念上更加接近ACID中的I，按照一致性从强到弱分为以下集中不同的一致性模型</p>
<ol>
<li>线性一致性（Linearizability）：又被称为Strong consistency or Atomic consistency，所有事务全局有序，使得所有的”读“都能读到最近的”写“，使得分布式系统外部看起来就像一个单机系统。（前提是需要建立一个全局时钟或者顺序确定机制）</li>
<li>顺序一致性（Sequential consistency）：放宽了线性一致性的全局性顺序要求，将一致性的要求分为以下两个方面，<strong>放宽了不同机器之间操作的执行顺序先后</strong>（zookeeper）<ul>
<li>从单机角度看，其读写操作的执行严格按照发出的顺序</li>
<li>从全局角度看，全局只有一个执行顺序</li>
</ul>
</li>
<li>因果一致性（<strong>Causal consistency</strong>）：对顺序一致性的进一步放宽，只要求保证具有因果关系操作的先后顺序关系（全局认可），其他不具备因果关系的操作的先后顺序在不同节点实际执行顺序可能不同<ul>
<li>通过本地执行顺序先后、写后的读等确定因果关系</li>
</ul>
</li>
<li>最终一致性（<strong>Eventually Consistency</strong>）：从出现网络分区时，分布式系统无法同时保证可用性和一致性，因此定义最终一致性这一概念，在执行某个操作后系统的状态可以是不一致的，但是能够保证的是过一段时间系统的状态最终会达到一致性<ul>
<li>由于最终一致性的系统不同部分会出现状态不一致的情况，需要特定机制进行状态同步<ul>
<li>在不同副本之间通信交换更新和状态更变，得到一个一致的最终状态</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>分布式系统中往往通过<strong>共识算法+ 并发控制</strong>实现一致性的保证</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单的整理了一下目前对于单机事务和分布式事务(<strong>单机并发，分布式并行</strong>)的理解，分布事务概念本身其实与单机事务相差不大，只是分布式事务的实现机制更加的复杂，仅仅了解了两阶段提交，还有其他许多实现方法等待继续学习</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/57315959">知乎：分布式系统一致性 - 总结</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/57579023">知乎：Transaction management：可串行性（serializability）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/504106272">知乎：分布式事务综述</a></li>
<li><a href="https://en.wikipedia.org/wiki/Distributed_transaction">wikipedia:Distributed transaction</a></li>
<li>DDIA第七章-事务</li>
</ol>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title>FaRM:无妥协的强一致性分布式数据库</title>
    <url>/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E6%97%A0%E5%A6%A5%E5%8D%8F%E7%9A%84%E5%BC%BA%E4%B8%80%E8%87%B4%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h2 id="FaRM-无妥协的强一致性分布式数据库"><a href="#FaRM-无妥协的强一致性分布式数据库" class="headerlink" title="FaRM: 无妥协的强一致性分布式数据库"></a>FaRM: 无妥协的强一致性分布式数据库</h2><blockquote>
<p><a href="https://dl.acm.org/doi/10.1145/2815400.2815425">No compromises: distributed transactions with consistency, availability, and performance</a></p>
</blockquote>
<p>从论文的名字就能看出微软对于自己这套分布式数据库系统的自信程度，强调自己在实现强一致性的同时，并不会妥协可用性和性能，然而深入论文就会发现，虽然确实实现了题目中的性质，但是很多机制局限于其实现条件，另外由于时间和能力有限，<strong>未能看懂论文中对于错误恢复部分的阐述</strong>，未来涉及到相关内容时再重新学习。</p>
<h3 id="构建系统动机"><a href="#构建系统动机" class="headerlink" title="构建系统动机"></a>构建系统动机</h3><p>FaRM的构建动机来自于目前数据中心内部硬件发展的两个趋势：</p>
<ol>
<li>基于RDMA（Remote Direct Memory Access）的快速网络通信技术：server之间进行通信时，不经过CPU，直接将数据写入到目标server存储区/拉取到本地存储区</li>
<li>低成本非易失DRAM存储技术：直接将数据存储在DRAM中，通过单独供电，在断电时备份到SSD中实现非易失</li>
</ol>
<p>在我看来，FaRM的高性能大部分原因来自于上部分阐述的硬件优势，除去优势以外，以上设计同样为FaRM带来了一定限制</p>
<ul>
<li>无法实现跨数据中心分布</li>
<li>增加了分布式事务和消息传递实现的复杂性（<del>这难道就是我看不懂错误恢复的原因？</del>）</li>
</ul>
<span id="more"></span>
<h3 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h3><p>如下图所示，FaRM架构基于1管理+N存储的方式，由一个配置管理服务器+多个存储服务器实现：</p>
<ul>
<li>Configuration Manager（CM）：负责分布式事务处理、容错恢复、配置管理等服务</li>
<li>普通存储服务器：存储数据+事务日志</li>
<li>ZooKeeper：仅仅作为辅助CM实现配置管理的协调服务</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E6%97%A0%E5%A6%A5%E5%8D%8F%E7%9A%84%E5%BC%BA%E4%B8%80%E8%87%B4%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220723160335830.png" class="" title="image-20220723160335830">
<p>其中数据以Region为单位在不同存储服务服务上分布和管理</p>
<ul>
<li>每个Region为2GB大小的存储块，存储一个primary和f个backup</li>
<li>由CM负责Region的开辟、管理Region分布和映射</li>
</ul>
<p>事务日志（Tx log）存储在基于环状缓冲实现的FIFO队列中，其中Region和Tx log的备份容错基于主从复制机制，一个primary+多个backup server，当primary server失效后，选取新的back up成为新的primary server</p>
<h4 id="分布式事务的实现"><a href="#分布式事务的实现" class="headerlink" title="分布式事务的实现"></a>分布式事务的实现</h4><p>与Spanner从Participant Group中选取一个作为协作者这种纯分布式事务实现方式不同，FaRM通过CM集中管理分布式事务</p>
<ul>
<li>由于FaRM的消息传递不经过CPU，FaRM分布式事务无法采用两阶段提交<strong>？</strong>。采用了如下图所示的更多阶段、复杂的提交方式。</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/%E6%97%A0%E5%A6%A5%E5%8D%8F%E7%9A%84%E5%BC%BA%E4%B8%80%E8%87%B4%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/image-20220723170854197.png" class="" title="image-20220723170854197">
<p>FaRM的事务提交分为五个阶段：</p>
<ul>
<li>执行阶段：首先在CM执行事务，并将事务执行结果缓存在CM本地（乐观并发控制）</li>
</ul>
<ol>
<li>Lock(上锁阶段)：CM将事务所需要的锁记录写入到参与事务的primary服务器上（无法直接响应，不经过CPU），primary在处理记录时，尝试根据记录版本号获取对应锁，如果版本号变更或者锁已被获取，返回失败，CM终止事务；否则在CM收到所有成功信息后，进入下一阶段（通过version+锁实现的<strong>乐观并发控制</strong>）、</li>
<li>Validate(验证阶段)：CM在通过one-sided RDMA读取验证所有涉及到的对象的版本号，若版本号出现不一致，则终止事务，否则进入下一阶段（<strong>读不需要锁</strong>，所以会有这一步，因为<strong>读之后事务执行完成之前可能会有其他事务获取锁</strong>）</li>
<li>Commit Backup(备份服务器上提交)：CM向所有的backup服务器发送（one-sided RDMA）Commit backup 信息，当收到所有ACK时，进入下一阶段，否则终止事务</li>
<li>Commit Primary（主服务器上提交）：CM向所有的primary服务器发送（one-sided RDMA）Commit primary信息，primary收到信息后进行修改+版本变更后，释放对应资源锁，事务结果对客户端可见</li>
<li>Truncate（日志截断）：CM在收到某条日志的所有ACK后，在下次消息传递时，通过携带截断信息，截断primary和backup对应日志信息，backup在截断日志时真正的执行修改操作</li>
</ol>
<p>综上所述，可以总结FaRM分布式事务实现区别点如下：</p>
<ol>
<li><strong>乐观并发控制</strong>：由于one-sided RDMA不经过CPU</li>
<li><strong>两阶段提交</strong>：（Lock+Validate）上锁验证截断 +（Commit backup+Commit Primary）主从提交阶段</li>
<li><strong>不保留日志</strong>：由于底层基于非易失存储（或者说论文中假设底层非易失），对于已经提交日志，无需保留</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总觉得FaRM虽然在保证一致性的前提下同时保持了高性能，由于其硬件约束和复杂的分布式事务和容错机制，很难在实际生产场景中应用，其基于乐观并发控制实现的分布式事务思路是读这篇论文的最大收获。</p>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>分布式数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark：分布式容错的内存计算框架</title>
    <url>/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spark%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%B9%E9%94%99%E7%9A%84%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<h2 id="Spark-分布式容错的内存计算框架"><a href="#Spark-分布式容错的内存计算框架" class="headerlink" title="Spark:分布式容错的内存计算框架"></a>Spark:分布式容错的内存计算框架</h2><blockquote>
<p><a href="https://www.usenix.org/conference/nsdi12/technical-sessions/presentation/zaharia">Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing</a></p>
</blockquote>
<p>Spark是目前大数据领域较为火热的批处理框架之一（也支持流处理），经过论文阅读，不难发现Spark的核心原理并不复杂，通过简单的抽象，有效的解决了内存计算问题，我想这就是Spark流行起来的原因之一，如果要理解Spark，最关键一步的是理解RDD这一抽象内存模型。</p>
<h3 id="RDDs（Resilient-Distributed-Datasets）"><a href="#RDDs（Resilient-Distributed-Datasets）" class="headerlink" title="RDDs（Resilient Distributed Datasets）"></a>RDDs（Resilient Distributed Datasets）</h3><p>Spark中将计算操作的基本内存数据单元抽象为一个只读、分区的数据集-弹性分布数据集（RDD），将一次Spark任务定义为RDD经过一系列操作不断变换状态的过程，如下图所示：</p>
<ul>
<li>每一步操作将一个RDD转化为另一个逻辑上的RDD（例如map、filter、join等）</li>
<li>不同RDD之间通过操作链接起来，形成一个RDD转换父子关系链</li>
<li>Spark通过记录RDD转化的父子关系以及操作类型，实现容错（在RDD丢失后，根据计算链重新计算）</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spark%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%B9%E9%94%99%E7%9A%84%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/image-20220726150407285.png" class="" title="image-20220726150407285">
<p>系统中通过五个元信息定义一个RDD：一系列分区、一系列父RDD依赖、转化操作、元数据（分区放置、分区信息），依赖关系如下图，分为一对一（narrow）和多对一（wide）。</p>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spark%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%B9%E9%94%99%E7%9A%84%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/image-20220726153152468.png" class="" title="image-20220726153152468">
<span id="more"></span>
<p>与其他分布式内存数据存储（kv数据库）的区别在于：</p>
<ul>
<li>RDD在状态变更逻辑上更加”粗“（<strong>Coarse-grained</strong>），执行的操作一般是对于RDD中所有元素执行的统一操作（如：过滤特定单词、计数）</li>
<li>如KV内存数据库等状态变更逻辑上粒度更加”细“（<strong>Fine-grained</strong>），执行操作一般是修改某一个表项或者某一个键值</li>
</ul>
<p>RDD的“粗”来自于批处理任务的特点，也为Spark带来了许多优势：</p>
<ul>
<li>批处理实际上就是一批数据执行某种操作到另一种批数据的过程，这与RDD变换的逻辑是一致的</li>
<li>RDD理论上不需要checkpoint机制进行容错，可以通过记录RDD变换操作，在特定RDD丢失后，直接重新计算获得丢失RDD</li>
<li>另外由于RDD的隔离性（计算并不修改RDD，而是生成RDD），可以通过复制RDD到其他机器解决“stragglers”问题</li>
</ul>
<p>在了解过RDD以后，心里不由自如的冒出这么个想法：在批处理环境下内存编程模型就应该是这样，简单且有效；然而想出从批处理-&gt;抽象模型这一步是真的太难。</p>
<h3 id="Spark实现"><a href="#Spark实现" class="headerlink" title="Spark实现"></a>Spark实现</h3><p>论文中简单介绍了基于RDD模型实现的Spark框架，省略了许多实现细节，且由于论文发表较早，其描述的实现机制肯定与目前Spark内部细节还是有较大差异，简单理解即可，基本框架图如下：</p>
<ul>
<li>对于每个Spark程序，采用一个Driver进程+多个Worker进程的实现方式。</li>
<li>Driver负责追踪RDD计算链（RDDs’ lineage）</li>
<li>Worker负责执行计算、在内存中存储RDD</li>
</ul>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spark%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%B9%E9%94%99%E7%9A%84%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/image-20220726152248126.png" class="" title="image-20220726152248126">
<p>RDD被实现为由元素类型决定的静态类型对象（如RDD[int]），支持的一系列transformation和action操作：</p>
<ul>
<li>transformation操作包括map、reduceByKey等，采用“懒执行”机制，即不真正执行，只是记录操作、定义新RDD</li>
<li>action操作包括count、collect等，直接执行，返回给用户结果</li>
</ul>
<p>Spark中任务的执行通过一个中心调度器（scheduler），进行任务分配和RDD分区</p>
<ol>
<li>当执行action类型操作时，scheduler构建DAG图，并划分stage</li>
<li>按照传输计算不传输数据的元组，尽量按照数据分布分配计算任务（例如具有依赖关系的父子RDD partition分布在一台机器上）</li>
</ol>
<img src="/2022/07/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/Spark%EF%BC%9A%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%B9%E9%94%99%E7%9A%84%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/image-20220726154038748.png" class="" title="image-20220726154038748">
<h3 id="Checkpointing-wide-dependency容错"><a href="#Checkpointing-wide-dependency容错" class="headerlink" title="Checkpointing-wide dependency容错"></a>Checkpointing-wide dependency容错</h3><p>当存在wide dependency的子RDD失效时（例如Page Rank中distinct() rdd结果丢失），由于其依赖于所有的上层RDD，所以需要重新在所有依赖的父RDD上重新执行相同操作，此类型错误恢复执行的成本过高。</p>
<p>Spark提供API<strong>支持Checkpointing机制</strong>持久化RDD,但是Spark将持久化的时机交给用户决定，由用户主动调用持久化API进行Checkpointing</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spark实际上就是将maprudce模型迁移到内存中，降低了任务中间结果输入输出的IO成本，其适用于例如pagerank、逻辑回归等的需要进行迭代计算的任务（中间结果不重要），如果将类似任务在mapreduce做，每一次迭代相当于一个mapreduce任务。Spark使用的RDD模型同样存在以下局限：</p>
<ol>
<li>不合适处理数据状态局部更新的应用（web site interactions, 增量采集数据的网络爬虫）</li>
<li>不支持处理流式数据</li>
</ol>
]]></content>
      <categories>
        <category>大数据理论</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT6.824实验总结</title>
    <url>/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="MIT6-824实验总结-基于Raft的分布式Sharded-KV数据库"><a href="#MIT6-824实验总结-基于Raft的分布式Sharded-KV数据库" class="headerlink" title="MIT6.824实验总结:基于Raft的分布式Sharded KV数据库"></a>MIT6.824实验总结:基于Raft的分布式Sharded KV数据库</h1><p>MIT6.824中共设计了四个实验，主要内容是一个分布式kv数据库。</p>
<ol>
<li>mapreduce分布式实现</li>
<li>raft实现</li>
<li>基于raft的kv数据库实现</li>
<li>Sharded KV数据库实现</li>
</ol>
<h2 id="Lab1-MapReduce分布式实现"><a href="#Lab1-MapReduce分布式实现" class="headerlink" title="Lab1:MapReduce分布式实现"></a>Lab1:MapReduce分布式实现</h2><p>实现架构按照论文中描述的实现方式：</p>
<ol>
<li>coordinator（master）：一个协作服务器，负责任务的分配+任务运行状态的监控</li>
<li>worker：多个worker，负责map和reduce任务的执行</li>
</ol>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220801085644561.png" class="" title="image-20220801085644561">
<p>整个系统的实现逻辑为（worker主动发送请求，coordinator被动响应请求）：</p>
<ol>
<li>coordinator启动，初始化任务信息；同时多个worker启动，开始向coordinator发送rpc请求，请求分配任务</li>
<li>coordinator根据“FIFO”原则，将map和任务分配给请求地worker，并记录任务状态和分配worker</li>
<li>coordinator每收到一个worker完成任务的rpc请求，修改待完成任务数量，当map任务完成进入reduce阶段，当reduce任务完成，结束执行</li>
</ol>
<p>coordinator主要实现逻辑即为map和reduce任务的分配，以map任务分配的<strong>关键代码</strong>为例：</p>
<ol>
<li><p>首先判断是否存在未分配的map任务，若存在则进行任务分配</p>
</li>
<li><p>传入workerId，分配任务（记录workerId，修改任务数量，修改任务状态）</p>
</li>
<li><p>启动10秒的监控线程，休眠十秒后，如果此时任务状态不为已完成，认为worker执行任务出现问题，将任务状态重新修改为空闲待处理</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> c.numMap != <span class="number">0</span> &#123;</span><br><span class="line">	allocateNumber, allocateFile := c.AllocateMapJob(args.WorkerId)</span><br><span class="line">	<span class="keyword">if</span> allocateNumber != <span class="number">-1</span> &#123;</span><br><span class="line">		reply.JobType = JOBTYPEMAP</span><br><span class="line">		reply.FileList = []<span class="keyword">string</span>&#123;allocateFile&#125;</span><br><span class="line">		reply.JobNumber = allocateNumber</span><br><span class="line">		<span class="comment">//启动线程，10秒种后若结果没有返回,将任务重置为未分配状态</span></span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			time.Sleep(<span class="number">10</span> * time.Second)</span><br><span class="line">			<span class="keyword">if</span> c.mapJobStatus[allocateFile][<span class="number">1</span>] != JOBCOMPLETED &#123;</span><br><span class="line">				c.mapJobLocks[allocateFile].Lock()</span><br><span class="line">				<span class="keyword">defer</span> c.mapJobLocks[allocateFile].Unlock()</span><br><span class="line">				<span class="keyword">if</span> c.mapJobStatus[allocateFile][<span class="number">1</span>] != JOBCOMPLETED &#123;</span><br><span class="line">					c.mapJobStatus[allocateFile][<span class="number">1</span>] = JOBIDLE</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>worker的主要实现逻辑为不断地向coordinator申请任务，<strong>关键代码</strong>为：</p>
<ol>
<li><p>启动时首先向coordinator发送注册rpc请求，获得workerid</p>
</li>
<li><p>循环发送申请任务请求，终止条件为：收到任务结束标志或rpc请求失败</p>
<ul>
<li>根据获得任务类型（map/reduce），调用对应处理方法，返回处理结果</li>
<li>当返回失败时（执行超时/rpc失败），删除任务输出结果</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">func Worker(mapf func(string, string) []KeyValue,</span><br><span class="line">	reducef func(string, []string) string) &#123;</span><br><span class="line">	ok, workerId, reduceNumber := ReigsiterWorker()</span><br><span class="line">	if ok &#123;</span><br><span class="line">		for taskEndFlag := false; !taskEndFlag; &#123;</span><br><span class="line">			ok, workInfo := CallForJob(workerId)</span><br><span class="line">			if ok &#123;</span><br><span class="line">				if workInfo.IsOver &#123;</span><br><span class="line">					taskEndFlag = true</span><br><span class="line">				&#125; else &#123;</span><br><span class="line">					switch workInfo.JobType &#123;</span><br><span class="line">					case JOBTYPEMAP:</span><br><span class="line">						ok, intermediate_file_names := doMapWork(workInfo.JobNumber, workInfo.FileList[0], reduceNumber, workerId, mapf)</span><br><span class="line">						if ok &#123;</span><br><span class="line">							ok = CallForMapJobAccomplished(workInfo.FileList[0], workerId, intermediate_file_names)</span><br><span class="line">						&#125;</span><br><span class="line">						if !ok &#123;</span><br><span class="line">							RemoveAllFiles(intermediate_file_names)</span><br><span class="line">						&#125;</span><br><span class="line">					case JOBTYPEREDUCE:</span><br><span class="line">					//省略...................</span><br><span class="line">					default:</span><br><span class="line">						log.Printf(&quot;none job recieved, waiting to next call\n&quot;)</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				log.Printf(&quot;failed to request a task, retry 2 seconds later&quot;)</span><br><span class="line">			&#125;</span><br><span class="line">			time.Sleep(2 * time.Second)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>测试用例完全通过</strong></p>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220801100606914.png" class="" title="image-20220801100606914">
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Lab1实现还是比较简单的，主要涉及的技术包括：</p>
<ol>
<li>通过锁控制共享变量的访问</li>
<li>通过gorutine实现多线程并发编程</li>
<li>通过RPC进行进程间相互通信</li>
</ol>
<h2 id="Lab2-Raft共识算法实现"><a href="#Lab2-Raft共识算法实现" class="headerlink" title="Lab2:Raft共识算法实现"></a>Lab2:Raft共识算法实现</h2><p>实验二主要任务是实现一个不包括成员切换功能的Raft共识算法，主要实现的功能部分如下</p>
<ol>
<li>Leader Election(选主)：实现raft算法的选主功能</li>
<li>Log Replication(日志复制)：实现日志添加和多副本备份功能</li>
<li>Persistence(持久化)：按照raft论文中持久化要求，实现对应参数的持久化</li>
<li>Snapshot/Log Compaction（快照）：raft层实现日志压缩，从而实现上层应用的快照需求</li>
</ol>
<h3 id="功能实现"><a href="#功能实现" class="headerlink" title="功能实现"></a>功能实现</h3><p>上述四个功能的实现主要参照论文中的figure2以及课程的相关资料，还有一部分存在疑问的地方也参考了其他人的实现思路，涉及到的参考均在文章末尾列出。</p>
<h4 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h4><p>选主首先要解决是raft结点的状态变更问题（即<strong>何时进入选举</strong>），按照论文中的思路如下（<strong>关键代码为ticker()函数</strong>）：</p>
<ul>
<li><p>为避免选主的争抢问题，随机设置超时时间为250-400ms</p>
</li>
<li><p>采用sleep的方式实现超时检测，而不是timer+事件处理的方式</p>
</li>
<li>更新超时时间的时机为收到有效的“RPC”消息：<ol>
<li>为某个 <strong>RequestVoteRPC</strong>(投票请求) 投出一票</li>
<li>收到 <strong>AppendEntryRPC</strong>(添加日志请求) 且该rpc是有效的</li>
<li>收到主节点的 <strong>InstallSnapshotRPC</strong>(更新快照请求)</li>
</ol>
</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">ticker</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> !rf.killed() &#123;</span><br><span class="line">		time.Sleep(time.Duration(rf.election_timeout-time.Now().UnixMilli()) * time.Millisecond)</span><br><span class="line">		rf.mu.Lock()</span><br><span class="line">		<span class="keyword">if</span> !rf.killed() &amp;&amp; rf.peer_status != STATUS_LEADER &amp;&amp; rf.election_timeout&lt;=time.Now().UnixMilli() &#123;</span><br><span class="line">			<span class="keyword">if</span> rf.election_timeout &lt;= time.Now().UnixMilli() &#123;</span><br><span class="line">                <span class="comment">//省略：修改状态，发起选举</span></span><br><span class="line">			&#125;</span><br><span class="line">            <span class="comment">//省略。。。。。。。</span></span><br><span class="line">		&#125;</span><br><span class="line">		rf.mu.Unlock()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第二个要解决的是leader端的选举判断逻辑（即<strong>如何进行选举</strong>），基本思路如下（<strong>关键代码为startElection()函数</strong>）：</p>
<ol>
<li>主进程为每个其他的raft结点启动一个发送线程，发送请求投票请求</li>
<li>主进程启动完毕之后，等待到“条件成熟”(主线程使用自旋锁，不断判断)，判断是否成功选为leader</li>
<li>选为leader执行初始化操作，否则进入下一轮选举</li>
</ol>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">startElection</span><span class="params">(election_timeout <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(rf.peers); i++ &#123;</span><br><span class="line">		<span class="keyword">if</span> i != rf.me &#123;</span><br><span class="line">			<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(aimServer <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">				<span class="comment">//省略：发送投票请求，判断是否同意票</span></span><br><span class="line">			&#125;(i)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//主线程不断判断是否满足条件（自旋锁）</span></span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="comment">//所有发送线程退出/投票数达到要求</span></span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">int</span>(finished_number) == <span class="built_in">len</span>(rf.peers) || <span class="keyword">int</span>(vote_number) &gt; <span class="built_in">len</span>(rf.peers)/<span class="number">2</span> &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">		rf.mu.Lock()</span><br><span class="line">		<span class="comment">//超时或者状态变更</span></span><br><span class="line">		<span class="keyword">if</span> time.Now().UnixMilli() &gt;= election_timeout || rf.currentTerm != vote_requst.CandidateTerm &#123;</span><br><span class="line">			rf.mu.Unlock()</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">		rf.mu.Unlock()</span><br><span class="line">		<span class="comment">//休息10毫秒</span></span><br><span class="line">		time.Sleep(time.Millisecond * <span class="number">10</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//省略：判断是否能够成为leader，能够成为即转化状态，否则退出，等待下一轮选举</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h5><p>主要涉及到的思路包括以下四点：</p>
<ol>
<li>超时状态转换：采用sleep()+election_timeout的机制，不断有”事件“更新election_timeout时间点，检测线程不断的休眠到这个时间点，直到某次“起晚了”</li>
<li>选举判断：采用<strong>主线程判断+多个从线程（对应结点）发送</strong>的模式，主线程自旋等待条件满足，从线程执行完发送判断即退出</li>
<li>维持选主状态：通过定时发送heartbeat消息实现（与下部分重叠，在下部分阐述）</li>
<li>接收端判断投票逻辑：完全按照论文中实现</li>
</ol>
<h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><h5 id="日志发送"><a href="#日志发送" class="headerlink" title="日志发送"></a>日志发送</h5><p>日志复制主要为leader结点的日志发送+follower结点的日志接收，实现之前我想到了两种思路：</p>
<ol>
<li>leader为每个follower设置一个发送线程</li>
<li>leader采用广播形式采用单个发送线程同时向多个follower发送</li>
</ol>
<p>逻辑上日志是采用广播形式，即leader每次发送日志会发送到所有的follower结点，另外heatbeart在此逻辑下同样是采用广播形式，然而论文中的如下描述与广播的逻辑相悖（单个结点发送失败不需要重新给其他结点法）</p>
<blockquote>
<p>If followers crash or run slowly, or if network packets are lost, the leader retries Append- Entries RPCs indefinitely (even after it has responded to the client) until all followers eventually store all log entries.</p>
<p>当followers失效或者运行缓慢，导致发送失败，leader应该无限重试直到所有follower存储所有日志</p>
</blockquote>
<p>仔细思考所谓的”retries Append- Entries RPCs indefinitely“会发现存在以下问题：</p>
<ol>
<li>若在重试过程中leader需要发送另外一个日志，重试是否应该携带新日志，或者停止重试，重新发送，如果不停止一个，就会出现<strong>新旧消息同时发送</strong>的情况，然而如何停止无法实现</li>
<li>无限的重试导致heartbeat需要针对每个结点单独判断，单独发送</li>
</ol>
<p>经过以上思考，最终确定采用广播的形式实现日志发送和heartbeat，基本思路如下：</p>
<ol>
<li>统一发送日志和heartbeat使用一个广播接口，发送日志调用广播接口，heartbeat周期性调用广播接口</li>
<li>广播时每个follower根据nextIndex发送需要的log(不断地广播相当于实现了<strong>无限重试</strong>，只是将重试的逻辑转移到了下一次广播)</li>
<li>由于heartbeat的周期性发送，即使没有外部日志发送请求，其效果也相当于”无限重试”的效果</li>
</ol>
<p>广播关键代码如下（<strong>broadcastAppendEntry()</strong>）：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">broadcastAppendEntry</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略：判断状态函数</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(rf.peers); i++ &#123;</span><br><span class="line">		<span class="keyword">if</span> i != rf.me &#123;</span><br><span class="line">			rf.mu.Lock()</span><br><span class="line">			<span class="comment">//判断perlogIndex是否已经存储在日志中（小于伪头entryindex）</span></span><br><span class="line">			<span class="keyword">if</span> rf.nextIndex[i]<span class="number">-1</span> &lt; rf.log[<span class="number">0</span>].Index &#123;</span><br><span class="line">				<span class="comment">//省略：发送快照方法</span></span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//根据结点缺失的日志情况，发送日志</span></span><br><span class="line">				args := AppendEntryArgs&#123;LeaderId: rf.me, Entries: rf.log[rf.nextIndex[i]-rf.log[<span class="number">0</span>].Index:], Term: rf.currentTerm,</span><br><span class="line">					PreLogIndex: rf.nextIndex[i] - <span class="number">1</span>, PreLogTerm: rf.log[rf.nextIndex[i]-rf.log[<span class="number">0</span>].Index<span class="number">-1</span>].Term, LeaderCommit: rf.commitIndex + rf.log[<span class="number">0</span>].Index&#125;</span><br><span class="line">				reply := AppendEntryReply&#123;&#125;</span><br><span class="line">				<span class="keyword">go</span> rf.sendAppendEntry(i, &amp;args, &amp;reply)</span><br><span class="line">			&#125;</span><br><span class="line">			rf.mu.Unlock()</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//更新发送时间</span></span><br><span class="line">	rf.lastSendTime = time.Now().UnixMilli()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用broadcastAppendEntry的时机有以下两种：</p>
<ul>
<li><p>每当leader接收到一个添加日志请求时，调用broadcastAppendEntry() </p>
</li>
<li><p>heartbeat采用类似election_timout的机制实现周期性调用broadcastAppendEntry() </p>
</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">Start</span><span class="params">(command <span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(<span class="keyword">int</span>, <span class="keyword">int</span>, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。</span></span><br><span class="line">	<span class="keyword">if</span> rf.peer_status == STATUS_LEADER &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。</span></span><br><span class="line">		<span class="keyword">go</span> rf.broadcastAppendEntry(<span class="literal">false</span>)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//省略。。。。。</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">heartsbeats</span><span class="params">()</span></span> &#123;</span><br><span class="line">	rf.lastSendTime = time.Now().UnixMilli() - IDLE_INTERVAL_TIME</span><br><span class="line">	<span class="keyword">for</span> !rf.killed() &#123;</span><br><span class="line">		<span class="comment">//省略验证状态代码</span></span><br><span class="line">		<span class="keyword">if</span> time.Now().UnixMilli()-rf.lastSendTime &gt;= IDLE_INTERVAL_TIME &#123;</span><br><span class="line">			rf.broadcastAppendEntry()</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//休眠到超时（未触发，休息到触发，否则休息一个interval）</span></span><br><span class="line">		time.Sleep(time.Duration(math.Min(IDLE_INTERVAL_TIME, <span class="keyword">float64</span>(IDLE_INTERVAL_TIME+rf.lastSendTime-time.Now().UnixMilli()))) * time.Millisecond)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="日志提交"><a href="#日志提交" class="headerlink" title="日志提交"></a>日志提交</h5><p>日志提交逻辑按照论文中的逻辑，其中实现思路为：</p>
<ol>
<li>提交日志到应用：每个raft结点启动时，启动applyEntry线程，等待lastapplied &lt; commitIndex，进行提交</li>
<li>推进commitIndex：当leader选举成功时，leader启动checkCommit线程，不断推进commitIndex</li>
</ol>
<ul>
<li>两个同步方式均采用golang的条件变量：rf.applyCond 和 rf.leaderCond</li>
</ul>
<p>以<strong>关键代码如下</strong>为例：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1.启动raft进程时，启动applyEntry（）进程</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Make</span><span class="params">(peers []*labrpc.ClientEnd, me <span class="keyword">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	persister *Persister, applyCh <span class="keyword">chan</span> ApplyMsg)</span> *<span class="title">Raft</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。。。。。。。。。。。。。。</span></span><br><span class="line">	<span class="keyword">go</span> rf.checkCommit()</span><br><span class="line">	<span class="keyword">go</span> rf.applyEntry()</span><br><span class="line">	<span class="comment">//省略。。。。。。。。。。。。。。。。。。。。。</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//2.applyEntry等待条件变量</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">applyEntry</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> !rf.killed() &#123;</span><br><span class="line">		rf.applyCond.L.Lock()</span><br><span class="line">		rf.applyCond.Wait()</span><br><span class="line">		rf.applyCond.L.Unlock()</span><br><span class="line">        <span class="comment">//省略：提交代码</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//3.当commitIndex修改时（），唤醒条件变量</span></span><br><span class="line"><span class="comment">//	1. follower收到appenEntries时，有可能修改commitIndex</span></span><br><span class="line"><span class="comment">//	2. leader checkCommit时，有可能修改commitIndex</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">AppendEntries</span><span class="params">(args *AppendEntryArgs, reply *AppendEntryReply)</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。。。。。。。。。。。。。。。。。。</span></span><br><span class="line">	<span class="keyword">if</span> rf.lastApplied &lt; rf.commitIndex &#123;</span><br><span class="line">		rf.applyCond.L.Lock()</span><br><span class="line">		rf.applyCond.Signal()</span><br><span class="line">		rf.applyCond.L.Unlock()</span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">//checkCommit方法不需要等待条件变量，周期性检查</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">checkCommit</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> !rf.killed() &#123;</span><br><span class="line">        <span class="comment">//等待成为leader</span></span><br><span class="line">		rf.leaderCond.L.Lock()</span><br><span class="line">		rf.leaderCond.Wait()</span><br><span class="line">		rf.leaderCond.L.Unlock()</span><br><span class="line">		<span class="comment">//开始周期性检查，是否能增加commitIndex</span></span><br><span class="line">		<span class="keyword">for</span> !rf.killed() &#123;</span><br><span class="line">			time.Sleep(LEADER_COMMIT_CHECK_INTERVAL * time.Millisecond)</span><br><span class="line">			<span class="keyword">if</span> rf.lastApplied &lt; rf.commitIndex &#123;</span><br><span class="line">				rf.applyCond.L.Lock()</span><br><span class="line">				rf.applyCond.Signal()</span><br><span class="line">				rf.applyCond.L.Unlock()</span><br><span class="line">			&#125;</span><br><span class="line">			rf.mu.Unlock()</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h5><p>日志复制部分要实现的逻辑比较多，也比较复杂，难点主要在于设计好整个发送接收以及提交框架，具体的日志验证、nextIndex维护按照论文中的描述即可</p>
<ol>
<li>日志发送+heartbeat：统一广播接口，heartbeat周期性调用，日志发送响应外部请求调用</li>
<li>日志提交：leader的checkCommit线程推进commitIndex，所有raft结点的applyEntry推进lastapplied</li>
<li>其他实现逻辑：严格按照论文逻辑实现</li>
</ol>
<h4 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h4><p>持久化思路比较简单，在任何修改涉及到持久化属性时，调用持久化方法即可：</p>
<ol>
<li><strong>修改term</strong>:任意RPC请求收到Term大于自己的Term响应时;收到任意RPC请求Term大于自己的Term时</li>
<li><strong>修改log</strong>:AppenEntriesRPC涉及到修改自身log时;Leader被调用start()方法，添加日志时；快照、接收到installsnapshot时</li>
<li><strong>修改voteFor</strong>:收到RequestVoteRPC，并同意投票时;超时切换为Candidate状态时</li>
</ol>
<h4 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h4><p>快照的难点不在于快照本身，而是在于快照导致的<strong>log的index不等于log在LogEntries中的index</strong>，如下图所示，经过快照日志的日志压缩后，raft结点的LogEntries长度从7变为3，导致index为5、6、7的三个日志项在LogEntriesz中的index为1、2、3</p>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220811144251911.png" class="" title="image-20220811144251911">
<p>针对以上问题以及raft的性质，进行以下设计:</p>
<ol>
<li><strong>本地用伪index</strong>，包括：leader维护的nextIndex和matchIndex、commitIndex和lastApplied</li>
<li><strong>传输转化为真Index</strong>，包括：appenEntry请求和返回index，requestVote请求和返回Index，installSnpshot请求和返回Index</li>
</ol>
<p>确定以上index设计思路后，修改部分原始代码：</p>
<ol>
<li>AppendEntries()中接收到leader的commitIndex（真index）确定commitIndex时,需要转化为logEntries中的index</li>
<li>Snapshot()中接收到leader的commitIndex和lastApplied减去日志压缩的数量</li>
<li>InstallSnapshot()中接收快照<ul>
<li>若commitIndex/lastApplied小于快照的LastIncludedIndex，应直接将commitIndex和lastApplied设置为0</li>
</ul>
</li>
</ol>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1. 情况1</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">AppendEntries</span><span class="params">(args *AppendEntryArgs, reply *AppendEntryReply)</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">    <span class="comment">//更新commitIndex(涉及到index转换)</span></span><br><span class="line">	<span class="keyword">if</span> args.LeaderCommit-rf.log[<span class="number">0</span>].Index &gt; rf.commitIndex &#123;</span><br><span class="line">		rf.commitIndex = args.LeaderCommit - rf.log[<span class="number">0</span>].Index</span><br><span class="line">		<span class="keyword">if</span> rf.commitIndex &gt; <span class="built_in">len</span>(rf.log)<span class="number">-1</span> &#123;</span><br><span class="line">			rf.commitIndex = <span class="built_in">len</span>(rf.log) - <span class="number">1</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">//省略。。。。。。。。</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//2.情况2</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">Snapshot</span><span class="params">(index <span class="keyword">int</span>, snapshot []<span class="keyword">byte</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">	rf.lastApplied -= index - rf.log[<span class="number">0</span>].Index</span><br><span class="line">	rf.commitIndex -= index - rf.log[<span class="number">0</span>].Index</span><br><span class="line">	<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">  	<span class="comment">//若为leader</span></span><br><span class="line">	<span class="keyword">if</span> rf.peer_status == STATUS_LEADER &#123;</span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(rf.peers); i++ &#123;</span><br><span class="line">			<span class="keyword">if</span> i != rf.me &#123;</span><br><span class="line">                <span class="comment">//nextIndex移动</span></span><br><span class="line">				rf.nextIndex[i] -= index - rf.log[<span class="number">0</span>].Index</span><br><span class="line">				rf.mathchIndex[i] = rf.nextIndex[i] - <span class="number">1</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">InstallSnapShot</span><span class="params">(args *InstallSnapshotArgs, reply *InstallSnapshotReply)</span></span> &#123;&#123;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">	<span class="comment">//如果lastApplied 或者 commitIndex 小于 args.LastIncludedIndex</span></span><br><span class="line">	<span class="keyword">if</span> rf.commitIndex+rf.log[<span class="number">0</span>].Index &lt; args.LastIncludedIndex </span><br><span class="line">		rf.commitIndex = <span class="number">0</span></span><br><span class="line">		rf.lastApplied = <span class="number">0</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> rf.lastApplied+rf.log[<span class="number">0</span>].Index &lt; args.LastIncludedIndex &#123;</span><br><span class="line">		rf.lastApplied = <span class="number">0</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>快照相关的方法在确定index的转化后，实现难度并不大，关键代码如下：</p>
<ul>
<li>在broadcastAppendEntry中增加判断,当prelogIndex指向日志在主节点中不存在时，发送InstallSnapshotRPC</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">broadcastAppendEntry</span><span class="params">(isHeartbeat <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(rf.peers); i++ &#123;</span><br><span class="line">		<span class="keyword">if</span> i != rf.me &#123;</span><br><span class="line">			<span class="comment">//省略。。。。。。。。</span></span><br><span class="line">			<span class="comment">//判断perlogIndex是否已经存储在日志中（小于伪头entryindex）</span></span><br><span class="line">			<span class="keyword">if</span> rf.nextIndex[i] &lt;= <span class="number">0</span> &#123;</span><br><span class="line">				<span class="comment">//调用发送快照接口</span></span><br><span class="line">				args := InstallSnapshotArgs&#123;Term: rf.currentTerm, LeaderId: rf.me,</span><br><span class="line">					LastIncludedIndex: rf.log[<span class="number">0</span>].Index, LastIncludedTerm: rf.log[<span class="number">0</span>].Term, Data: rf.persister.snapshot&#125;</span><br><span class="line">				reply := InstallSnapshotReply&#123;&#125;</span><br><span class="line">				<span class="keyword">go</span> rf.sendSnapShot(i, &amp;args, &amp;reply)</span><br><span class="line">				</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="comment">//省略发送日志代码</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//更新发送时间</span></span><br><span class="line">	rf.lastSendTime = time.Now().UnixMilli()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h5><p>快照和持久化类似，代码的实现量并不大，关键在于修改历史代码使得兼容当前操作，这几个index的关系和转化折磨了我很久的时间，有时候debug很久才发现，不是逻辑问题，只是index没有考虑到的问题</p>
<h3 id="遇到的实现问题"><a href="#遇到的实现问题" class="headerlink" title="遇到的实现问题"></a>遇到的实现问题</h3><h5 id="1-不要在占有锁的时候进行通信"><a href="#1-不要在占有锁的时候进行通信" class="headerlink" title="1. 不要在占有锁的时候进行通信"></a>1. 不要在占有锁的时候进行通信</h5><p>通信（RPC,管道等）前应该首先释放锁，因为通信是不可靠的，可能存在延迟返回导致长时间占有锁，系统停顿的问题，两种解决方案</p>
<ol>
<li>先释放锁，再进行通信，或者通信完成再获取锁</li>
<li>启动单独的线程机型通信，主线程继续执行</li>
</ol>
<p>情况1应用较为广泛，如下应用日志的关键代码：</p>
<ul>
<li>修改之前遇到了死锁bug：当前线程占有锁，向管道(applyCh)中写入，但是由于管道已满导致阻塞，测试代码中管道的消费者消费上一条消息调用Snapshot方法要获取锁，两者构成了占有且等待的条件，构成死锁（<del>这个bug折磨死我了，测试几十次出现一次</del>）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">func (rf *Raft) applyEntry() &#123;</span><br><span class="line">	//省略：。。。。。。。。。。。。。。。</span><br><span class="line">	for !rf.killed() &#123;</span><br><span class="line">		rf.mu.Lock()</span><br><span class="line">		//省略：获取发送所需资源</span><br><span class="line">		rf.mu.Unlock()</span><br><span class="line">		//log.Printf(&quot;peer:%v try to applyEntry，释放锁&quot;, rf.me)</span><br><span class="line">		//再发送信息</span><br><span class="line">		for i := 0; i &lt; len(applyEntries); i++ &#123;</span><br><span class="line">			rf.applyCh &lt;- ApplyMsg&#123;CommandValid: true, SnapshotValid: false, Command: applyEntries[i].Command, CommandIndex: applyEntries[i].Index&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		//log.Printf(&quot;peer:%v try to applyEntry，完成发送&quot;, rf.me)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-在收到比自己更新（Term更大）的请求-响应时，应立即修改状态，返回请求"><a href="#2-在收到比自己更新（Term更大）的请求-响应时，应立即修改状态，返回请求" class="headerlink" title="2. 在收到比自己更新（Term更大）的请求/响应时，应立即修改状态，返回请求"></a>2. 在收到比自己更新（Term更大）的请求/响应时，应立即修改状态，返回请求</h5><p>上述机制保证了过期的raft结点不会落后太多，如果在某些地方少考虑了这一要求，会出现意想不到的bug</p>
<h5 id="3-Leader只能提交自己任期内的日志（重点）"><a href="#3-Leader只能提交自己任期内的日志（重点）" class="headerlink" title="3. Leader只能提交自己任期内的日志（重点）"></a>3. Leader只能提交自己任期内的日志（重点）</h5><p>这一点在看论文的时候有点难理解，导致在实现过程中容易忘记这一点，如果不按照这一点实现，测试时会出现日志不一致的情况</p>
<h5 id="4-nextIndex会回退，matchIndex不会回退"><a href="#4-nextIndex会回退，matchIndex不会回退" class="headerlink" title="4. nextIndex会回退，matchIndex不会回退"></a>4. nextIndex会回退，matchIndex不会回退</h5><p>这一点结合课程guidance思考了很久才想到，导致了之前一直存在的bug<strong>appendEntries发送端当prelogIndex冲突时只用改nextIndex，不用改matchIndex</strong></p>
<ul>
<li>matchIndex指向已经成功写入log，nextIndex回退不可能小于等于matchIndex</li>
<li>发送appendEnties是之所以会发生prelogIndex冲突，是由于Leader初始化时将nextIndex设置为自己的日志长度</li>
</ul>
<h5 id="5-日志复制请求由于网络问题会存在先发送后到达的情况"><a href="#5-日志复制请求由于网络问题会存在先发送后到达的情况" class="headerlink" title="5.日志复制请求由于网络问题会存在先发送后到达的情况"></a>5.日志复制请求由于网络问题会存在先发送后到达的情况</h5><p>在做实验3时测试发现了这个bug，Leader向follower先发送的日志复制请求反而后到，导致nextIndex不是因为日志冲突回退，而是因为历史请求延迟返回错误回退，之前没有考虑到这个情况</p>
<ul>
<li>例如：连续发送两个prelogIndex=12的appendEntry请求,第一个请求返回成功推进，第二个请求延迟，此时Leader发送prelogIndex=19的appendEntry请求，成功将nextIndex推进到29后，第二个请求返回，又将nextIndex回退到19</li>
<li>上述情况在不不使用快照的情况下不会影响正确性，只会影响系统性能；使用快照后，client在收到prelogIndex=19的appendEntry后第二个情况返回之前可能会进行快照，结果导致<strong>client认为日志提交到了29以后，将29之前的日志均快照压缩，Leader由于延迟请求将nextIndex回退到了19，下次发送perlogIndex=19的日志复制请求时，client端已经不包含perlogIndex=19的日志</strong>。</li>
</ul>
<p>针对以上<strong>历史请求定义为</strong>：存在比当前请求后发送，但是先被接收到/返回的请求。对此解决方案为:</p>
<ol>
<li><p>在follower接收端过滤历史请求</p>
<ul>
<li>无法全部过滤，因为follower无法判断请求是否为历史的，只能通过第一个index过滤一部分</li>
<li>执行历史请求在follower端是不影响正确性的，所以没有采用commitIndex等的更加复杂的判断逻辑</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">//判断是否过时，如果过时直接返回</span></span><br><span class="line"><span class="keyword">if</span> args.Term &lt; rf.currentTerm || args.PreLogIndex &lt; rf.log[<span class="number">0</span>].Index &#123;</span><br><span class="line">	<span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在leader端发送请求返回处理时，过滤历史请求</p>
<ul>
<li>判断term和nextIndex是否为发送时的值，term不同说明发生了重新选举，nextIndex不同说明当前请求返回前，有其他后发出的请求返回，两种情况都应丢弃当前返回结果</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> rf.currentTerm == args.Term &amp;&amp; rf.nextIndex[server]<span class="number">-1</span> &gt;= <span class="number">0</span> &amp;&amp; args.PreLogIndex == rf.log[rf.nextIndex[server]<span class="number">-1</span>].Index &#123;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li>能够直接过滤历史请求的原因，在于新请求的成功执行代表了老请求+新信息的共同成功执行，即<strong>新请求包括了老请求的所有信息</strong></li>
</ul>
<h3 id="测试和总结"><a href="#测试和总结" class="headerlink" title="测试和总结"></a>测试和总结</h3><p>实现不保证不存在bug，在完成代码之后，运行了400次测试用例，全部pass，可以证明整体上的逻辑没有大问题，实验中我得到的收获有以下几点：</p>
<ol>
<li>并发控制很好玩，就是死锁太磨人</li>
<li>解决问题的成就感是遭受折磨的最大回报（<del>如果实验室的项目能给我带来这种成就感，我可能就不会骂他垃圾了，或者说我的水平不足以坚持到能够给我提供成就感的时候</del>）</li>
</ol>
<p><img src="MIT6.824实验总结/image-20220821150706818.png" alt="image-20220821150706818" style="zoom:67%;" /></p>
<h2 id="Lab3-基于Raft的KV数据库实现"><a href="#Lab3-基于Raft的KV数据库实现" class="headerlink" title="Lab3:基于Raft的KV数据库实现"></a>Lab3:基于Raft的KV数据库实现</h2><p>实验三的任务是实现一个基于Raft的多副本kv数据库，在能够保证Raft实现正确性的情况下，实现KV数据库不算太难，在实际的调试中，大部分问题来自于Raft之前实现的小bug，说明ab2的测试还是不够完善，经过修改和重新测试后，通过了lab2和lab3的所有测试。</p>
<h3 id="实现架构"><a href="#实现架构" class="headerlink" title="实现架构"></a>实现架构</h3><p>该KV数据库满足典型的客户端-服务器的CS实现架构，客户通过Client向发出读写请求，Server接收并执行Client请求，Raft负责实现副本之间操作顺序的共识，client/server/raft之间的具体结构以及交互关系如<a href="https://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf">MIT6.824课程资料中的raft_diagram.pdf</a>所示:</p>
<ol>
<li>多个Client，每个Client内部请求逐个发送，即单个Client内不会出现操作并发的情况（这一点很重要，一定程度降低了实现难度）</li>
<li>多个KV Server，每个Server对应一个Raft peer，不同Server存储相同内容，互为备份，通过Raft实现一致状态保证</li>
</ol>
<p>一个典型的写操作流程，可以定义为如下流程：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    Client-&gt;&gt;Leader Server: 1.发送写请求</span><br><span class="line">    Leader Server-&gt;&gt;Leader Raft: 2.生成操作日志，发送到Raft层</span><br><span class="line">    Leader Raft -&gt;&gt; Leader Raft: 3.在Raft节点群内备份日志，达到多数后提交日志</span><br><span class="line">    Leader Raft -&gt;&gt; Leader Server: 5.提交日之后，通知server应用操作，修改状态</span><br><span class="line">    Leader Server -&gt;&gt; Client: 5.返回操作执行结果</span><br></pre></td></tr></table></figure>
<p>其中<strong>每个server对应一个raft peer</strong>，<strong>Leader Raft对应Leader Server</strong>:</p>
<h3 id="线性一致性和容错"><a href="#线性一致性和容错" class="headerlink" title="线性一致性和容错"></a>线性一致性和容错</h3><h4 id="读线性一致性"><a href="#读线性一致性" class="headerlink" title="读线性一致性"></a>读线性一致性</h4><p>基于Raft的WAL机制下，写请求自然是满足线性一致性的，但是对于读请求，如果不进行特殊处理，可能会读到过期数据</p>
<ul>
<li><p>例如：当发生网络分区，Client发送请求到了旧Leader，此时新Leader已经执行了部分更新操作，导致旧Leader返回过期数据，导致不满足读写的线性一致性</p>
</li>
<li><p>对于此问题，Raft论文中提出了在响应只读请求之前，与大部分raft peer交互同步，确实自己状态是否已经过期。</p>
<blockquote>
<p>Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding<br>to read-only requests.</p>
</blockquote>
</li>
</ul>
<p>对于raft读操作线性一致性保证，存在其他的效率更高的实现方式（以后进行总结）：</p>
<ol>
<li>Read Index</li>
<li>Lease Read</li>
</ol>
<p>同步的方法性能较差，但是实现起来较为简单，结合以上思路系统读写操作实现为：<strong>所有的读写操作均通过leader进行，在应用到本地状态机之前首先提交Raft日志，日志提交后才进行状态变更</strong></p>
<h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><blockquote>
<p>To achieve linearizability in Raft, servers must filter out duplicate requests. The basic idea is that servers save the results of client operations and use them to skip executing the same request multiple times. To implement this, each client is given a unique identifier, and clients assign unique serial numbers to every command. Each server’s state machine maintains a session for each client. The session tracks the latest serial number processed for the client, along with the associated response. If a server receives a command whose serial number has already been executed, it responds immediately without re-executing the request.  - raft论文中容错思路</p>
</blockquote>
<p>由于KV层状态机状态以及状态变更基于Raft容错，所以可认为是可靠的，此时需要解决的容错问题其实仅限于请求响应的丢失，即请求成功执行但是客户端未收到响应，针对此问题的容错方案为：</p>
<ol>
<li>Client在未收到正确的响应之前，不断重试发送请求</li>
<li>Server需要对成功执行的请求进行缓存，应对Client的请求重发（Server并不知道一个成功的请求响应是否被Client收到，必须记录）</li>
</ol>
<p>由于每个Client的请求串行执行，上述容错方案可以实现为：</p>
<ol>
<li>每个Client为每个操作编号，一个操作可以通过 Client号+Operation号唯一标识</li>
<li>Server为每个Client缓存最新操作的执行结果，接收到操作时通过缓存判断是否为已执行过操作</li>
</ol>
<p>上述机制存在一个漏洞即某操作对应Raft日志成功提交，但是可能由于Raft共识达成过于缓慢，在应用到状态机之前，Client认为请求执行超时，重新发送请求，此时同一个操作在Raft中对应两条日志项，针对此中情况增加过滤：</p>
<ul>
<li><strong>一条操作可以有多条日志，但是只有一条日志操作会应用到状态机上</strong>了，应用到状态机以后即缓存操作结果</li>
<li>在应用日志时，通过缓存判断是否为已执行过操作</li>
</ul>
<p><strong>小总结：缓存+双重过滤实现了响应丢失的容错，同时避免了重复执行一个相同操作破坏线性一致性</strong></p>
<p>另外由于实验中Client串行发送请求，导致Server只需要存储每个Client最新操作执行结果，如果Client能够并发发送操作请求，则缓存需要基于滑动窗口的方式(来自<a href="https://www.zhihu.com/question/278551592">知乎回答</a>),简单总结加深印象：</p>
<ul>
<li>Server为每个Client缓存可能需要的请求结果窗口:[op_uncheck1,op_uncheck2,……op_latest]</li>
<li>Client请求会携带其确认已经接收最大操作号，导致请求结果窗口左边界推进</li>
<li>Client新请求导致请求结果窗口右边界推进</li>
</ul>
<h3 id="功能实现-1"><a href="#功能实现-1" class="headerlink" title="功能实现"></a>功能实现</h3><p>功能实现部分主要分为两部分进行总结：</p>
<ol>
<li>KV Client 请求发送逻辑</li>
<li>KV Server 请求处理逻辑</li>
</ol>
<h4 id="KV-Client-请求发送逻辑"><a href="#KV-Client-请求发送逻辑" class="headerlink" title="KV Client 请求发送逻辑"></a>KV Client 请求发送逻辑</h4><p>Client由于请求串行执行，请求处理逻辑较为简单，主要是请求结果处理以及请求初始，以PutAppend操作代码为例：</p>
<ul>
<li>初始化请求体是设置操作编号，操作执行成功后才进行操作编号自增</li>
<li>请求server初始随机访问，按照轮询的方式寻找leader，直到操作成功执行</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ck *Clerk)</span> <span class="title">PutAppend</span><span class="params">(key <span class="keyword">string</span>, value <span class="keyword">string</span>, op <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// You will have to modify this function.</span></span><br><span class="line">	args := PutAppendArgs&#123;ClientStamp: ck.clentStamp, OpStamp: ck.opStamp, Key: key, Value: value, Op: op&#125;</span><br><span class="line">	<span class="keyword">for</span> i := ck.leaderServer; ; i = (i + <span class="number">1</span>) % <span class="built_in">len</span>(ck.servers) &#123;</span><br><span class="line">		reply := PutAppendReply&#123;&#125;</span><br><span class="line">		ok := ck.servers[i].Call(<span class="string">&quot;KVServer.PutAppend&quot;</span>, &amp;args, &amp;reply)</span><br><span class="line">		<span class="keyword">if</span> ok &#123;</span><br><span class="line">			<span class="keyword">if</span> reply.Err == ErrTimeOut &#123;</span><br><span class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span> reply.Err == ErrWrongLeader &#123;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="keyword">if</span> reply.Err == ErrNoKey &#123;</span><br><span class="line">					<span class="keyword">break</span></span><br><span class="line">				&#125;</span><br><span class="line">				<span class="comment">//修改leaderServer</span></span><br><span class="line">				ck.leaderServer = i</span><br><span class="line">				<span class="keyword">break</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125; </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//最后操作符加一</span></span><br><span class="line">	ck.opStamp++</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Client在初始化随机设置clientId:</p>
<ul>
<li>采用实验代码中提供的nrand()函数，由于随机数范围较大，出现重叠的概率较小</li>
<li>常用的分布式全局不重复ID生成方法为：DB自增、时间戳、snowflake算法（需要进一步学习）</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MakeClerk</span><span class="params">(servers []*labrpc.ClientEnd)</span> *<span class="title">Clerk</span></span> &#123;</span><br><span class="line">	ck := <span class="built_in">new</span>(Clerk)</span><br><span class="line">	ck.servers = servers</span><br><span class="line">	<span class="comment">// You&#x27;ll have to add code here.</span></span><br><span class="line">	ck.clentStamp = nrand() <span class="comment">//随机生成当前client编号</span></span><br><span class="line">	ck.opStamp = <span class="number">0</span>          <span class="comment">//操作编号初始化为0</span></span><br><span class="line">	bigx, _ := rand.Int(rand.Reader, big.NewInt(<span class="keyword">int64</span>(<span class="built_in">len</span>(servers))))</span><br><span class="line">	ck.leaderServer = <span class="keyword">int</span>(bigx.Int64()) <span class="comment">//随机初始化当前leader，server</span></span><br><span class="line">	<span class="keyword">return</span> ck</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="KV-Server-处理逻辑"><a href="#KV-Server-处理逻辑" class="headerlink" title="KV Server 处理逻辑"></a>KV Server 处理逻辑</h4><p>Server端在接收请求，应用请求变更、返回请求结果之前，首先写入Raft日志：</p>
<ul>
<li>基本流程：缓存去重-&gt;提交日志-&gt;等待chan通知 <strong>或</strong> 超时-&gt;返回结果</li>
<li>其中接收到chan通知后，需要判断此时操作缓存中操作号是否为当前操作号<ul>
<li>原因：在我的实现中<strong>允许非leader向用户</strong>返回结果，即只要日志提交，且当前server有client在等待返回结果，即通知client</li>
<li>如此设计会导致一个bug：如果一个日志提交后，旧leader返回结果给client后崩溃，新leader此时上线，client向新leader发送新请求，建立通知通道，此时新leader执行历史请求，向新请求通知通道通知，导致<strong>执行历史请求通知了新请求的返回</strong></li>
<li>如何排除此错误：请求返回处理程度接收到通知后，判断缓存中操作是否为历史操作结果，<strong>若为历史操作继续循环等待通知</strong></li>
</ul>
</li>
<li><strong>总结</strong>：是否返回操作结果由<strong>日志是否在超时时间内提交</strong>决定，与leader节点状态是否变化无关（此操作规避了leader变换导致的相同操作日志重复提交问题）</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *KVServer)</span> <span class="title">processOperation</span><span class="params">(op Op)</span> <span class="params">(Err, <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> resultError Err</span><br><span class="line">	resultValue := <span class="string">&quot;&quot;</span></span><br><span class="line">	kv.mu.RLock()</span><br><span class="line">	opRes, ok := kv.opResStore[op.ClientStamp]</span><br><span class="line">	<span class="keyword">if</span> ok &amp;&amp; opRes.OpStamp == op.OpStamp &#123;</span><br><span class="line">		resultError, resultValue = opRes.Err, opRes.Value</span><br><span class="line">		kv.mu.RUnlock()</span><br><span class="line">		<span class="keyword">return</span> resultError, resultValue</span><br><span class="line">	&#125;</span><br><span class="line">	kv.mu.RUnlock()</span><br><span class="line">	kv.mu.Lock()</span><br><span class="line">	_, _, isLeader := kv.rf.Start(op)</span><br><span class="line">	<span class="keyword">if</span> !isLeader &#123;</span><br><span class="line">		kv.mu.Unlock()</span><br><span class="line">		resultError = ErrWrongLeader</span><br><span class="line">		<span class="keyword">return</span> resultError, resultValue</span><br><span class="line">	&#125;</span><br><span class="line">	notifyChan := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">1</span>)</span><br><span class="line">	kv.notifyChanStore[op.ClientStamp] = notifyChan</span><br><span class="line">	kv.mu.Unlock()</span><br><span class="line">	timeout := time.Now().UnixMilli() + MaxWaitTime</span><br><span class="line">	<span class="keyword">for</span> time.Now().UnixMilli() &lt; timeout &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> opRes := &lt;-notifyChan:</span><br><span class="line">			<span class="keyword">if</span> opRes.OpStamp == op.OpStamp &#123;</span><br><span class="line">				kv.mu.Lock()</span><br><span class="line">				kv.notifyChanStore[op.ClientStamp] = <span class="literal">nil</span></span><br><span class="line">				kv.mu.Unlock()</span><br><span class="line">				resultError = opRes.Err</span><br><span class="line">				resultValue = opRes.Value</span><br><span class="line">				<span class="keyword">return</span> resultError, resultValue</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="comment">//休眠10微妙</span></span><br><span class="line">			time.Sleep(<span class="number">10</span> * time.Millisecond)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	resultError = ErrTimeOut</span><br><span class="line">	kv.mu.Lock()</span><br><span class="line">	kv.notifyChanStore[op.ClientStamp] = <span class="literal">nil</span></span><br><span class="line">	kv.mu.Unlock()</span><br><span class="line">	<span class="keyword">return</span> resultError, resultValue</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Server在初始化时，启动一个读取提交信息的线程，负责在日志提交后将操作应用到状态机上：</p>
<ul>
<li>log应用也<strong>需要过滤重复操作的原因</strong>：在一致性和容错部分描述过，即一条操作可能会有多条日志，但是只有一条日志操作会应用到状态机上</li>
<li><strong>进行快照时机</strong>：每次应用日志时，判断此时raft日志大小是否达到上限</li>
<li><strong>切换快照的时机</strong>：一旦接收到切换快照日志，即进行快照切换（2021版本实验需要用到CondInstallSnapshot函数，而2022版本里推荐不实现该函数，直接返回OK，其中涉及到的同步问题<strong>在raft层解决</strong>，见注意事项<a id="snapshotProblem">1</a>）</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *KVServer)</span> <span class="title">applyCommitLog</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> m := <span class="keyword">range</span> kv.applyCh &#123;</span><br><span class="line">		<span class="keyword">if</span> m.CommandValid &#123;</span><br><span class="line">			opCommand := m.Command.(Op)</span><br><span class="line">			kv.mu.Lock()</span><br><span class="line">			kv.lastAppliedIndex = m.CommandIndex</span><br><span class="line">			opRes, ok := kv.opResStore[opCommand.ClientStamp]</span><br><span class="line">			<span class="keyword">if</span> !ok || opRes.OpStamp != opCommand.OpStamp &#123;</span><br><span class="line">				notifyChan := kv.notifyChanStore[opCommand.ClientStamp]</span><br><span class="line">				kv.mu.Unlock()</span><br><span class="line">				<span class="keyword">if</span> notifyChan != <span class="literal">nil</span> &#123;</span><br><span class="line">					kv.notifyChanStore[opCommand.ClientStamp] = <span class="literal">nil</span></span><br><span class="line">					notifyChan &lt;- <span class="number">1</span></span><br><span class="line">				&#125;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				kv.mu.Unlock()</span><br><span class="line">            &#125;</span><br><span class="line">			<span class="keyword">if</span> kv.maxraftstate != <span class="number">-1</span> &amp;&amp; kv.rf.GetLogSize() &gt; kv.maxraftstate &#123;</span><br><span class="line">				kv.snapshotStatus()</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> m.SnapshotValid &#123;</span><br><span class="line">			kv.loadSnapshot(m.SnapshotIndex, m.Snapshot)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="遇到的实现问题-1"><a href="#遇到的实现问题-1" class="headerlink" title="遇到的实现问题"></a>遇到的实现问题</h3><h5 id="1-InstallSnapshot引发的上层快照切换时机同步问题"><a href="#1-InstallSnapshot引发的上层快照切换时机同步问题" class="headerlink" title="1.InstallSnapshot引发的上层快照切换时机同步问题"></a><a href="#snapshotProblem">1</a>.InstallSnapshot引发的上层快照切换时机同步问题</h5><p>做lab4在测试多并发时遇到了这个问题，发现自己并没有仔细思考CondInstallSnapshot这个函数存在的意义，简单的认为2022版本丢弃后，直接返回true不做其他处理即可，导致了kv层切换快照和应用日志的不同步引发的系统不满足线性一致性问题</p>
<p><strong>切换日志同步问题</strong>：调用installSnapshot唤醒上层进行快照切换时，由于将快照切换消息发送到kv层时不占有锁，同时日志commit也在向kv层发送，两者存在争抢问题，即可能由于并发导致顺序出现错误，如下图所示例子</p>
<ol>
<li>正确顺序为raft发送Snapshot:10日志后，发送后续Command:11和12日志</li>
<li>错误情况1：raft层截断日志之后，发送Snapshot:10日志之前，提交日志进程读取新日志，抢先发送Command:11日志</li>
<li>错误情况2：raft层截断日志之前，提交日志进程正在准备发送Command:9-10的日志，此时raft接收到InstallSnapshot，截断日志，抢在提交日志进程发送之前，发送Snapshot:10日志</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	subgraph 错误顺序2:不需要日志发送</span><br><span class="line">    7[Snapshot:10] --&gt; 8[/Command:9/]--&gt; 9[/Command:10/]</span><br><span class="line">    end</span><br><span class="line">	subgraph 错误顺序1:未来日志提前发</span><br><span class="line">    4[/Command:11/] --&gt; 5[Snapshot:10]--&gt; 6[/Command:12/]</span><br><span class="line">    end</span><br><span class="line">	subgraph 正确顺序:</span><br><span class="line">    1[Snapshot:10] --&gt; 2[/Command:11/]--&gt; 3[/Command:12/]</span><br><span class="line">    end</span><br></pre></td></tr></table></figure>
<p>切换日志同步问题并不一定会导致上层kv层出现状态不一致的问题，分情况讨论：</p>
<ul>
<li><p>错误情况1：会导致过期Snapshot和kv层跳过执行某些日志两种错误</p>
<ol>
<li><p>过期snapshot问题：该问题通过在kv层比较最后应用日志index和快照index来过滤过期快照</p>
</li>
<li><p>kv层跳过执行日志问题：按照上图，raft集群提交到了log:11，然而raft节点由于一定原因只执行到了log:8,此时raft leader向peer节点发送installsnapshot，然而发生了上图情况二，导致peer对应kv层直接从log:8跳到执行log:11，并且在1问题解决措施下，认为Snapshot:10过期并过滤，从而导致kv层漏执行log:9和log10，可能导致<strong>不一致问题</strong></p>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220904105055292.png" class="" title="image-20220904105055292">
</li>
</ol>
</li>
<li><p>错误情况2：导致kv层收到其认为执行过的历史日志</p>
<ul>
<li><p>通过比较日志应用index和raft层传入日志，过滤由于snapshot导致的“历史日志”</p>
</li>
<li><p>例如上图：在Snapshot:10日志读取后，更新日志应用index到10，之后接收到Command:9-10均认为过期，直接丢弃</p>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220904104626216.png" class="" title="image-20220904104626216">
</li>
</ul>
</li>
</ul>
<p>综上所属，错误1情况的<strong>跳过执行日志问题</strong>无法在kv层解决，需要在raft层避免情况1的出现，针对此设计一下同步思路：</p>
<ol>
<li><p>installSnapshot在释放锁之前，sendSnapshot标记+1，完成发送后sendSnapshot标记-1</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">//写入applych</span></span><br><span class="line">rf.startSendingSnapshot()</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    rf.applyCh &lt;- ApplyMsg&#123;CommandValid: <span class="literal">false</span>, SnapshotValid: <span class="literal">true</span>, Snapshot: args.Data,</span><br><span class="line">			SnapshotIndex: args.LastIncludedIndex, SnapshotTerm: args.LastIncludedTerm&#125;</span><br><span class="line">	rf.finishSendingSnapshot()</span><br><span class="line">&#125;()</span><br><span class="line">kv.mu.Unlock()</span><br></pre></td></tr></table></figure>
</li>
<li><p>日志应用端，发送日志之前等待sendSnapshot为0</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> rf.isSendingSnapshot() &#123;</span><br><span class="line">    time.Sleep(<span class="number">5</span> * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(applyEntries); i++ &#123;</span><br><span class="line">    rf.applyCh &lt;- ApplyMsg&#123;CommandValid: <span class="literal">true</span>, SnapshotValid: <span class="literal">false</span>, Command: applyEntries[i].Command, CommandIndex: applyEntries[i].Index&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>标记采用原子性操作的整数（没必要使用锁）</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">isSendingSnapshot</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">	z := atomic.LoadInt32(&amp;rf.snapshotMsgSending)</span><br><span class="line">	<span class="keyword">return</span> z == <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">startSendingSnapshot</span><span class="params">()</span></span> &#123;</span><br><span class="line">	atomic.AddInt32(&amp;rf.snapshotMsgSending, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span> <span class="title">finishSendingSnapshot</span><span class="params">()</span></span> &#123;</span><br><span class="line">	atomic.AddInt32(&amp;rf.snapshotMsgSending, <span class="number">-1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>上述不基于锁实现的同步机制，保证了日志应用端在<strong>确定发送日志之前</strong>执行的InstallSnapshot消息<strong>均能够发送</strong>，问题是<strong>有可能后发生的InstallSnapshot会阻碍与其无关之前日志应用端日志发送</strong>，由于installsnapshot调用频率较低，且执行较快，所以该问题影响不大</p>
<h3 id="测试和总结-1"><a href="#测试和总结-1" class="headerlink" title="测试和总结"></a>测试和总结</h3><p>由于Raft底层保证+单个Client串行执行操作，实现kv服务的难度并不大，主要难点在于请求去重和遗留bug处理，经过三天时间终于写完并且测试通过代码（测试一百轮）。</p>
<p><img src="MIT6.824实验总结/image-20220822155923816.png" alt="image-20220822155923816" style="zoom:67%;" /></p>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220822160313514.png" class="" title="image-20220822160313514">
<h2 id="Lab4-基于Raft的Sharded-KV-数据库实现"><a href="#Lab4-基于Raft的Sharded-KV-数据库实现" class="headerlink" title="Lab4:基于Raft的Sharded KV 数据库实现"></a>Lab4:基于Raft的Sharded KV 数据库实现</h2><p>lab4主要是在原来的kvServer基础上，添加分片(Shard)机制，从而实现一个真正的分布式容错高性能KV数据库，实现过程中的主要难点在于Shard在不同replicate group之间的交互过程。首先系统主要的功能点可以总结为：</p>
<ol>
<li>提供包括<code>put(key, value), append(key, value), get(key)</code>的基本kv数据库功能</li>
<li>基于Raft共识算法的多服务器备份，实现一致性备份存储，实现了系统容错功能</li>
<li>基于Raft日志的WAL机制以及系统快照机制，允许系统在失效后通过日志重新执行、加载快照等，快速恢复数据</li>
<li>通过数据分片和多复制服务器组存储方式，实现了系统的高并发访问性能</li>
<li>支持存储服务器的动态配置，即可以动态的增加删除存储服务器</li>
</ol>
<h3 id="基本实现架构"><a href="#基本实现架构" class="headerlink" title="基本实现架构"></a>基本实现架构</h3><p>如下图所示，系统按照标准的CS架构实现，其中Server端包括一个配置管理集群（Shard Manager）以及多个数据片存储管理集群（KV Server Group）；Client端包括两种类型身份的Client：一种为发送KV数据操作请求的客户端（KV Client）,一种为管理分片信息以及数据片存储集群的客户端（Shard Manage Client）</p>
<ul>
<li>Shard Manager Server负责kv server group、数据分片以及分片到kv server映射信息等系统元数据的管理（类似于HDFS Master）</li>
<li>KV Server Group负责按照分片配置存储对应分片数据以及执行和响应KV客户端操作</li>
</ul>
<p><img src="MIT6.824实验总结/image-20220904152037470.png" alt="image-20220904152037470" style="zoom: 50%;" /></p>
<p>其中<strong>Shard Manager</strong>和每个<strong>KV Server Group</strong>，通过多服务器备份的方式实现数据的可靠性，具体实现架构如下图所示（以KV Server Group为例）：</p>
<ul>
<li>每个KV Server Group以及ShardManager内包括三个服务器实例，互为备份服务器</li>
<li>通过基于Raft日志的WAL机制，保证不同副本之间的状态一致性以及错误恢复（KV Server中状态机为存储数据片、Shard Manager中状态机为系统shard元数据）</li>
</ul>
<p><img src="MIT6.824实验总结/image-20220904161454555.png" alt="image-20220904161454555" style="zoom:50%;" /></p>
<h3 id="分片以及分片分配-sharding"><a href="#分片以及分片分配-sharding" class="headerlink" title="分片以及分片分配(sharding)"></a>分片以及分片分配(sharding)</h3><p>kv数据库中的每个key对相当于关系数据库中表中的条目，且value为单值，区别于关系型数据库条目由多个属性组成，采用Horiziontal Partitioning策略，基于hash的方法对数据进行分片，分片方式如下：</p>
<ul>
<li>shardNum为配置的固定分片数量，确定后即不会改变</li>
</ul>
<script type="math/tex; mode=display">
shardId := hash(key) \% shardNum</script><ul>
<li>确定分片后，根据KV Server Group数量将shard<strong>均匀分配</strong>到KV Server Gruop上，由Shard Manager维护映射关系<script type="math/tex; mode=display">
shadId->GruopId</script></li>
</ul>
<p>上述方法可以总结为：<strong>固定分片策略，动态分配方法</strong>相，优缺点为：</p>
<ul>
<li>优点：当KV Server Group配置改变时，涉及到数据迁移时，以shard为单位进行迁移，较于以key直接映射KV Serve Group(如下公式)，降低了涉及到的数据迁移通信量</li>
<li>缺点：根据key分布进行划分，当key分布不均有或者某些热点key访问量较高时，无法保证不同KV Serve Group之间的负载均衡</li>
</ul>
<script type="math/tex; mode=display">
shardId := hash(key) \% Server Group Num</script><p>未来可以优化的点：</p>
<ul>
<li>采用复合划分Composite partitioning策略即：首先基于哈希方法划分，在根据key的分布规律和请求访问，进行基于列表划分（List Partitionning）的二次细粒度划分</li>
<li>可以基于一致性哈希实现shard-&gt;KV Serve Group的映射管理，降低由于KV Serve Group的增加或者减少shard重分配导致的数据迁移</li>
</ul>
<h4 id="分片分配机制"><a href="#分片分配机制" class="headerlink" title="分片分配机制"></a>分片分配机制</h4><p>Shard Manager作为<script type="math/tex">key->kvServerGroup</script>的配置管理查询服务，支持动态增加/删除存储服务器，相关接口如下</p>
<ul>
<li><code>Join(servers)</code>：批量增加存储服务器组</li>
<li><code>Leave(gruopIds)</code>：批量删除存储服务器组</li>
</ul>
<p>当kvServerGroup配置发生改变时，Shard Manager会重新在剩余可用Gruop进行shard重分配，基本原则如下：</p>
<ul>
<li>保证shard在所有server Group上的<strong>均匀分配</strong>：一部分存储平均数个shard，一部分存储平均数+1个shard</li>
<li>尽量<strong>减少shard迁移</strong>：重新计算平均数，存储shard大于平均数的group移动到小于平均数的group</li>
</ul>
<p>重分配关键代码如下所示：</p>
<ul>
<li>根据group数量，计算平均值<code>averagerShard</code>和余数<code>remindShard</code>，<strong>最终分配结果为</strong>：<code>remindShard</code>个server存储<code>averagerShard + 1</code>个shard，其余group存储<code>averagerShard</code>个shard</li>
<li>分为统计重分配shard和重新分配两个步骤，两步骤思路基本相同</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">//首先统计当前gruop数量</span></span><br><span class="line"><span class="keyword">for</span> key, _ := <span class="keyword">range</span> newConfig.Groups &#123;</span><br><span class="line">	groupShardNumMap[key] = <span class="number">0</span></span><br><span class="line">	allGroupId = <span class="built_in">append</span>(allGroupId, key)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//将shard超过average的日志重新分配</span></span><br><span class="line">reallocateShards := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">0</span>)</span><br><span class="line">averageShard := <span class="built_in">len</span>(newConfig.Shards) / <span class="built_in">len</span>(allGroupId)</span><br><span class="line">remindShard := <span class="built_in">len</span>(newConfig.Shards) % <span class="built_in">len</span>(allGroupId)</span><br><span class="line"><span class="keyword">for</span> shard, group := <span class="keyword">range</span> newConfig.Shards &#123;</span><br><span class="line">	_, ok := newConfig.Groups[group]</span><br><span class="line">	<span class="keyword">if</span> !ok &#123;</span><br><span class="line">		<span class="comment">//shard所属gruop被删除的情况</span></span><br><span class="line">		reallocateShards = <span class="built_in">append</span>(reallocateShards, shard)</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		numShard := groupShardNumMap[group]</span><br><span class="line">		<span class="comment">//如何判断一个group是否超量（关键）：管理shard数量 &gt; averageShard 或者 管理shard数量 == averageShard 且此时可以管理averageShard + 1个shard的机会已经用尽</span></span><br><span class="line">		<span class="keyword">if</span> numShard &gt; averageShard || (numShard == averageShard &amp;&amp; remindShard == <span class="number">0</span>) &#123;</span><br><span class="line">			reallocateShards = <span class="built_in">append</span>(reallocateShards, shard)</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">//如果当前group管理shard数量为averageShard，再分配一个shard，当前group管理了averageShard + 1个shard，则需要占用一个管理averageShard + 1的名额</span></span><br><span class="line">			<span class="keyword">if</span> numShard == averageShard &#123;</span><br><span class="line">				remindShard--</span><br><span class="line">			&#125;</span><br><span class="line">			groupShardNumMap[group] += <span class="number">1</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//开始重新分配</span></span><br><span class="line"><span class="comment">//。。。。。。省略重新分配代码，和上部分差异不大</span></span><br></pre></td></tr></table></figure>
<h3 id="分片迁移实现"><a href="#分片迁移实现" class="headerlink" title="分片迁移实现"></a>分片迁移实现</h3><p>当系统发生Server Gruop的增加或者删除时，会触发shard在不同server之间的变更，虽然整体上思考较为复杂，但是从单个shard迁移的角度考虑，可以将变更过程定义为：多个同时进行的<strong>shard从一个server group 到 另一个server group</strong>的过程，如下图所示：</p>
<ul>
<li>对于每个server group来说，在每个配置变更期，要么有一定量移出的shard，要么有一定量等待移入的shard，要么shard不变</li>
</ul>
<p><img src="MIT6.824实验总结/image-20220905112323707.png" alt="image-20220905112323707" style="zoom:50%;" /></p>
<p>在shard迁移过程中，我们必须保证一下几点：</p>
<ol>
<li>shard不能丢失：需要迁出shard的server group只有在确保对方成功接收对应shard后，才能安全删除</li>
<li>shard一旦迁出，不能再提供服务：server group在迁出shard后，不能再服务shard上的数据操作（client端可能为获取到最新配置，导致该问题的出现）</li>
<li>在配置切换过程中，系统能够继续提供服务</li>
</ol>
<p>针对上述问题，为shard定义以下几个状态，迁入迁出过程可以通过状态变更实现：</p>
<ul>
<li><code>Normal</code>：默认正常状态（<strong>正常访问操作</strong>）</li>
<li><code>WaitIn</code>：等待迁入状态（无法访问操作）</li>
<li><code>In</code>：已经迁入，但还向发送端确认状态（<strong>正常访问操作</strong>）</li>
<li><code>out</code>：等待迁出状态（无法访问操作）</li>
<li><code>Delelte</code>：迁出完毕状态，可以进行垃圾回收（无法访问操作）</li>
</ul>
<p>如下图以一个shard迁移过程中的状态变更为例，分析变更流程：</p>
<ul>
<li>shard接收端读取到新配置后，创建空shard，并设置状态为 <code>WaitIn</code></li>
<li>不断地向发送端，拉取shard(<strong>由发送端推也一样，只是选择实现了拉</strong>)，不断重试，直到获取到shard，修改状态： <code>WaitIn -&gt; In</code></li>
<li>完成状态转换后，向发动端发送确认收到RPC，发动端修改shard状态： <code>Out -&gt; Delete</code></li>
<li>接收端不断地发送确认收到RPC，直到RPC请求返回，携带有发送端已经将对应shard状态变更为<code>Delete</code>或者删除的信息后，停止发送，修改状态：<code>In -&gt; Normal</code></li>
<li>当server Group的所有shard状态变为<code>Normal</code>或者<code>Delete</code>时，<strong>完成配置变更</strong></li>
<li>上述所有状态变更操作均首先提交到raft，在<strong>操作日志成功提交后</strong>，执行对应状态变更</li>
</ul>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220905145204954.png" class="" title="image-20220905145204954">
<p>上述设计思路的原因：</p>
<ol>
<li><p>为什么需要确认消息，才能将对应shard状态变更<code>Out -&gt; Delete</code></p>
<ul>
<li>由于发送端是被拉取方，在接收端发送确认收到消息后，发送端才能保证shard已经发送到接收端且成功存储可以<strong>删除</strong></li>
</ul>
</li>
<li><p>为什么确认收到消息，返回需要携带发动端是否将对应shard状态变更为delete</p>
<ul>
<li>接受端发送确认消息的目的是为了通知发送端自己确认收到shard，接收端需要<strong>保证</strong>发送端收到并且成功记录的自己的确认消息，当发送端shard状态变为delete时，接收端可以确定自己的确认消息成功执行</li>
<li><p>若不按照上述方式执行，可能存在第一次消息确认成功返回，接收端停止发送，但是发送端由于leader切换等，消息确认操作log未成功提交，导致发送端<strong>无限期等待接收端的确认消息</strong></p>
</li>
<li><p>上述设计来源于假设：即使请求成功返回，对应操作不一定成功执行，只有操作结果出现（raft保证操作结果不丢失），才能保证操作执行</p>
</li>
</ul>
</li>
</ol>
<ul>
<li><strong>简单总结</strong>：发送端需要保证接收端接收到才能删除shard-&gt;接收端需要通知发送端自己收到了-&gt;接收端需要保证接收端知道了自己成功接收，才能停止通知</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>在具体设计实现过程中，并未采用状态变更与通信绑定的操作，即一个线程执行了状态变更后，进行对应发送请求，具体考虑如下：</p>
<ul>
<li>通信可能失败，需要不断重试，状态变更线程不应等待通信，应该继续执行其他操作</li>
<li>状态变更线程由于互斥需要，往往需要持有锁，由于通信的不确定性（延迟、失败），持有锁时进行RPC通信，可能导致系统性能大幅下降</li>
</ul>
<p>综合考虑上述设计问题，采用了状态变更线程+周期性状态检测线程的思路</p>
<ul>
<li>状态变更线程：负责读取raft日志，根据日志中操作变更shard状态</li>
<li>周期性状态检测线程：周期性遍历shard，根据shard状态按照上述交互图，发送消息</li>
</ul>
<p><strong>状态变更线程</strong>代码如下所示：</p>
<ul>
<li>只负责根据日志操作进行状态变更，不负责状态变更后的操作</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *ShardKV)</span> <span class="title">processConfigOp</span><span class="params">(commandInterface <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> opCommand := commandInterface.(<span class="keyword">type</span>) &#123;</span><br><span class="line">	<span class="keyword">case</span> ConfigOp:</span><br><span class="line">		<span class="comment">//过滤重复的修改配置操作（因为从写入日志到日志提交存在时间差，可能重复提交日志）</span></span><br><span class="line">		<span class="keyword">if</span> opCommand.Config.Num &gt; kv.config.Num &#123;</span><br><span class="line">            <span class="comment">//省略根据配置信息修改shard状态代码</span></span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> InShardOp:</span><br><span class="line">		<span class="keyword">if</span> opCommand.ConfigNum == kv.config.Num &#123;</span><br><span class="line">			<span class="comment">//省略添加shard(去重)</span></span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> DelShardOp:</span><br><span class="line">		<span class="keyword">if</span> opCommand.ConfigNum == kv.config.Num &#123;</span><br><span class="line">			<span class="comment">//省略修改shard状态为out-&gt;delete(需要去重)</span></span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">case</span> AckShardOp:</span><br><span class="line">		<span class="keyword">if</span> opCommand.ConfigNum == kv.config.Num &#123;</span><br><span class="line">			<span class="comment">//省略从in状态修改为normal状态(需要去重)</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>周期性检测线程</strong>代码如下所示：</p>
<ul>
<li>遍历所有shard，启动单独线程负责通信，主线程等待所有通信线程退出</li>
<li>所有通信线程推出后，主线程遍历所有shard，判断是否退出配置切换状态</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *ShardKV)</span> <span class="title">updateShardState</span><span class="params">(updateFunc <span class="keyword">func</span>(<span class="keyword">int</span>, <span class="keyword">int</span>, []<span class="keyword">string</span>)</span>, <span class="title">chaeckStatus</span> <span class="title">string</span>)</span> &#123;</span><br><span class="line">	kv.mu.RLock()</span><br><span class="line">	_, isLeader := kv.rf.GetState()</span><br><span class="line">	<span class="comment">//如果在配置</span></span><br><span class="line">	<span class="keyword">if</span> kv.isConfiging() &amp;&amp; isLeader &#123;</span><br><span class="line">		<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">        <span class="comment">//遍历所有shard，根据状态执行对应操作（如：WaitIn状态发起拉取RPC请求，In状态发起确认RPC）</span></span><br><span class="line">		<span class="keyword">for</span> shardId, shard := <span class="keyword">range</span> kv.allShards &#123;</span><br><span class="line">			<span class="keyword">if</span> shard.ShardStatus == chaeckStatus &#123;</span><br><span class="line">				wg.Add(<span class="number">1</span>)</span><br><span class="line">				<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(shardId <span class="keyword">int</span>, configNum <span class="keyword">int</span>, allServers []<span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">					<span class="keyword">defer</span> wg.Done()</span><br><span class="line">					updateFunc(shardId, configNum, allServers)</span><br><span class="line">				&#125;(shardId, kv.config.Num, kv.preConfig.Groups[kv.preConfig.Shards[shardId]])</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//释放锁，并等待</span></span><br><span class="line">		kv.mu.RUnlock()</span><br><span class="line">		wg.Wait()</span><br><span class="line">        <span class="comment">//上锁，判断当前状态是否可以退出配置状态</span></span><br><span class="line">		kv.mu.RLock()</span><br><span class="line">		completeFlag := <span class="literal">true</span></span><br><span class="line">		<span class="keyword">for</span> _, shard := <span class="keyword">range</span> kv.allShards &#123;</span><br><span class="line">			<span class="keyword">if</span> shard.ShardStatus != ShardNormal &amp;&amp; shard.ShardStatus != ShardDelete &#123;</span><br><span class="line">				completeFlag = <span class="literal">false</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		kv.mu.RUnlock()</span><br><span class="line">		<span class="keyword">if</span> completeFlag &#123;</span><br><span class="line">			kv.changeConfigState(<span class="literal">false</span>)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		kv.mu.RUnlock()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于后台存在多个周期性运行函数（状态检测、垃圾回收），抽取一个<strong>公用的周期循环</strong>方法：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *ShardKV)</span> <span class="title">backRoutine</span><span class="params">(operation <span class="keyword">func</span>()</span>, <span class="title">interval</span> <span class="title">int</span>)</span> &#123;</span><br><span class="line">	<span class="keyword">for</span> !kv.killed() &#123;</span><br><span class="line">		<span class="comment">//执行具体操作</span></span><br><span class="line">		operation()</span><br><span class="line">		time.Sleep(time.Duration(interval) * time.Millisecond)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//传入需要周期运行的方法</span></span><br><span class="line"><span class="keyword">go</span> kv.backRoutine(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; kv.updateShardState(kv.callMigrateShard, ShardWaitIn) &#125;, UpdateShardInterval)</span><br><span class="line"><span class="comment">//启动确认收到对应shard的线程</span></span><br><span class="line"><span class="keyword">go</span> kv.backRoutine(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; kv.updateShardState(kv.callMigrateShardAck, ShardIn) &#125;, UpdateShardInterval)</span><br></pre></td></tr></table></figure>
<h4 id="垃圾回收实现"><a href="#垃圾回收实现" class="headerlink" title="垃圾回收实现"></a>垃圾回收实现</h4><p>根据分片迁移实现部分逻辑，仅仅需要回收状态为delete状态的shard，实现逻辑较为简单，采用周期性回收线程的方式，关键代码如下：</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *ShardKV)</span> <span class="title">garbageCollect</span><span class="params">()</span></span> &#123;</span><br><span class="line">	kv.mu.Lock()</span><br><span class="line">	<span class="keyword">for</span> shardId, shard := <span class="keyword">range</span> kv.allShards &#123;</span><br><span class="line">		<span class="keyword">if</span> shard.ShardStatus == ShardDelete &#123;</span><br><span class="line">			<span class="comment">//删除对应状态的shard</span></span><br><span class="line">			<span class="built_in">delete</span>(kv.allShards, shardId)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	kv.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//启动垃圾回收线程</span></span><br><span class="line"><span class="keyword">go</span> kv.backRoutine(kv.garbageCollect, GCInterval)</span><br></pre></td></tr></table></figure>
<h3 id="遇到的实现问题-2"><a href="#遇到的实现问题-2" class="headerlink" title="遇到的实现问题"></a>遇到的实现问题</h3><h5 id="1-同一个类型中的RPC请求-结构体中，由于条件不同请求参数不同，导致大量无用参数"><a href="#1-同一个类型中的RPC请求-结构体中，由于条件不同请求参数不同，导致大量无用参数" class="headerlink" title="1.同一个类型中的RPC请求/结构体中，由于条件不同请求参数不同，导致大量无用参数"></a>1.同一个类型中的RPC请求/结构体中，由于条件不同请求参数不同，导致大量无用参数</h5><p>在实现过程中遇到了一个操作请求对应多种不同操作的情况，不同操作需要携带不同的操作参数，如下代码所示：</p>
<ul>
<li>一种操作对应四种类型的操作，传输其他操作时需要占用其他三种操作参数的空间</li>
</ul>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ShardOp <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">//公共参数</span></span><br><span class="line">	OpType    <span class="keyword">string</span></span><br><span class="line">	ConfigNum <span class="keyword">int</span></span><br><span class="line">	<span class="comment">//修改配置操作参数</span></span><br><span class="line">	Config shardctrler.Config</span><br><span class="line">	<span class="comment">//添加shard操作参数</span></span><br><span class="line">	AddShard <span class="keyword">int</span></span><br><span class="line">	Shard    ShardData</span><br><span class="line">	<span class="comment">//删除操作参数</span></span><br><span class="line">	DelShard <span class="keyword">int</span></span><br><span class="line">	<span class="comment">//确认shard操作参数</span></span><br><span class="line">	AckShard <span class="keyword">int</span> <span class="comment">//迁移进入shard的参数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>针对以上情况，想出了三种解决方案</p>
<ol>
<li><p>发送不特殊处理，接收端根据opType进行处理（不做处理），缺点是：多余参数占用空间</p>
</li>
<li><p>修改结构体，使用byte[]存储编码后的参数，发送端编码，接收端根据OpType进行解码，缺点：编解码浪费时间，发送接收端需要确定编码顺序</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ShardOp <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">//公共参数</span></span><br><span class="line">	OpType    <span class="keyword">string</span></span><br><span class="line">	ConfigNum <span class="keyword">int</span></span><br><span class="line">	<span class="comment">//修改配置操作参数</span></span><br><span class="line">	parameters []<span class="keyword">byte</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>将结构体拆分，传输不同的结构体，在接收端基于golang反射进行操作，缺点：反射的运行效率较低，影响系统运行效率</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> DelShardOp <span class="keyword">struct</span> &#123;</span><br><span class="line">	ConfigNum <span class="keyword">int</span> <span class="comment">//非切换配置需要使用的去重参数</span></span><br><span class="line">	DelShard  <span class="keyword">int</span> <span class="comment">//迁移出删除shard的参数</span></span><br><span class="line"></span><br><span class="line">	AddShard <span class="keyword">int</span>       <span class="comment">//迁移进入shard的参数</span></span><br><span class="line">	Shard    ShardData <span class="comment">//迁移进入shard的参数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> InShardOp <span class="keyword">struct</span> &#123;</span><br><span class="line">	ConfigNum <span class="keyword">int</span>       <span class="comment">//非切换配置需要使用的去重参数</span></span><br><span class="line">	AddShard  <span class="keyword">int</span>       <span class="comment">//迁移进入shard的参数</span></span><br><span class="line">	Shard     ShardData <span class="comment">//迁移进入shard的参数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> AckShardOp <span class="keyword">struct</span> &#123;</span><br><span class="line">	ConfigNum <span class="keyword">int</span> <span class="comment">//非切换配置需要使用的去重参数</span></span><br><span class="line">	AckShard  <span class="keyword">int</span> <span class="comment">//迁移进入shard的参数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//接收端执行操作</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *ShardKV)</span> <span class="title">processConfigOp</span><span class="params">(commandInterface <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> opCommand := commandInterface.(<span class="keyword">type</span>) &#123;</span><br><span class="line">	<span class="keyword">case</span> ConfigOp:</span><br><span class="line">	<span class="keyword">case</span> InShardOp:</span><br><span class="line">	<span class="keyword">case</span> DelShardOp:</span><br><span class="line">	<span class="keyword">case</span> AckShardOp:</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>最后综合考虑<strong>采用第三种方法</strong>，虽然执行效率低，但是实现逻辑上更加清晰，相较于第一种方式减少了空间浪费，降低了网络通信代价</p>
<h3 id="测试与总结"><a href="#测试与总结" class="headerlink" title="测试与总结"></a>测试与总结</h3><p>测试过程按照以下方式进行：</p>
<ul>
<li><p>执行测试脚本，测试200次，每次输出结果写入到文件中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for ((i = 0; i &lt; 200; i++)); do echo $i; (go test) &gt; ./res/$i; grep -nr &quot;FAIL.*&quot; res;  done</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行完毕，统计通过数量</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">grep -nr <span class="string">&quot;PASS&quot;</span> res |wc -l</span><br></pre></td></tr></table></figure>
</li>
<li><p>重复执行三轮，共计测试600次</p>
</li>
</ul>
<p>测试结果为：</p>
<ul>
<li>测试所有轮次均通过</li>
</ul>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220905161251235.png" class="" title="image-20220905161251235">
<ul>
<li>其中一次的测试输出为：</li>
</ul>
<img src="/2022/09/06/MIT6.824%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/image-20220905161743796.png" class="" title="image-20220905161743796">
<h5 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h5><p>终于经过了一个多月的视频学习和接近一个月的实验实现，终于完成MIT6.824的学习，现在回看自己的收获可以总结为以下几点：</p>
<ol>
<li>对于分布式系统概念以及涉及到的知识点，有了广泛但不一定深入的了解</li>
<li>掌握了基本golang开发和调试的能力，对于golang的特性和语法有了一定程度的理解</li>
<li>对于并发编程，RPC通信，线程和进程有了更深的理解</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>在实现过程中，由于存在部分知识点理解不够透彻，漏看某些实验条件和实验约束，导致部分实验卡壳，实现过程中参考了部分其他实现方案，具体参考如下：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/463146544">知乎：MIT6.824-2021 Lab4 : MultiRaft</a> 主要参考了shard封装和状态的思路，并从博主其他博客中了解到了其他可用来帮助加深理解Raft等算法的资料</li>
<li><a href="https://www.cnblogs.com/sun-lingyu/p/14591757.html">博客园：MIT6.824 spring21 Lab2D总结记录</a> 根据博客中快照同步的讲解理解了为什么会需要快照同步，不进行快照同步可能带来的bug</li>
<li><a href="">知乎：MIT6.824_2021_labs</a> 主要和他实现性能进行对比(因为只有他放了结果截图)，基本所有lab实现测试时间小于他的水平（<del>达到心理的满足</del>）</li>
</ol>
<p>除此之外，参考其他的大多是golang相关的问题，四个实验从设计到实现<strong>基本上独立完成</strong>，参考较少，没有进行过代码copy。</p>
]]></content>
  </entry>
</search>
