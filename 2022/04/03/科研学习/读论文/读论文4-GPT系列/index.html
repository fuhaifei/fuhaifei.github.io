<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">

<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fuhaifei.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"appID":"Z5NZZSJS0C","apiKey":"15b03f0f88d2c13ed04694ae0ca74f79","indexName":"blog_search_api","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="GPTGPT作为NLP预训练语言模型的基石之一，从gpt1,gpt2到gpt3，不断扩大模型规模，将问题从fine-tuning拓展到zero-shot,试图解决更基础，但是更困难的无监督学习问题，三篇论文中的模型结构相同，不同的是试图解决的问题。 GPT1 Improving Language Understanding by Generative Pre-Training  要解决的问题NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="读论文4-GPT系列">
<meta property="og:url" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/index.html">
<meta property="og:site_name" content="光与影的个人博客">
<meta property="og:description" content="GPTGPT作为NLP预训练语言模型的基石之一，从gpt1,gpt2到gpt3，不断扩大模型规模，将问题从fine-tuning拓展到zero-shot,试图解决更基础，但是更困难的无监督学习问题，三篇论文中的模型结构相同，不同的是试图解决的问题。 GPT1 Improving Language Understanding by Generative Pre-Training  要解决的问题NLP">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328083725904.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084046552.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084332027.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084506127.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084857519.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328101903526.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328143447270.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328143917773.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328144755337.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328151023322.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328151832377.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154323252.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154359207.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154433953.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154640571.png">
<meta property="og:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154729495.png">
<meta property="article:published_time" content="2022-04-03T11:10:41.000Z">
<meta property="article:modified_time" content="2023-02-09T12:10:26.657Z">
<meta property="article:author" content="NEU-FHF">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328083725904.png">

<link rel="canonical" href="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>读论文4-GPT系列 | 光与影的个人博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">光与影的个人博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">NEUCoder</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fuhaifei.github.io/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/post_head.jpg">
      <meta itemprop="name" content="NEU-FHF">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="光与影的个人博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          读论文4-GPT系列
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-03 19:10:41" itemprop="dateCreated datePublished" datetime="2022-04-03T19:10:41+08:00">2022-04-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-09 20:10:26" itemprop="dateModified" datetime="2023-02-09T20:10:26+08:00">2023-02-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">科研学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/" itemprop="url" rel="index"><span itemprop="name">读论文</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h2><p>GPT作为NLP预训练语言模型的基石之一，从gpt1,gpt2到gpt3，不断扩大模型规模，将问题从fine-tuning拓展到zero-shot,试图解决更基础，但是更困难的无监督学习问题，三篇论文中的模型结构相同，不同的是试图解决的问题。</p>
<h3 id="GPT1"><a href="#GPT1" class="headerlink" title="GPT1"></a>GPT1</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></p>
</blockquote>
<h4 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h4><p>NLP中有监督训练数据较少，存在大量的无标签文本数据，如何使用这些数据解决NLP领域中各类问题？GPT提出了 <strong>自监督预训练+fine tuning</strong> 的方式，主要解决两个问题</p>
<ol>
<li>预训练的<strong>训练目标是什么</strong>？损失函数是什么？</li>
<li>预训练得到的特征表示<strong>如何迁移</strong>到下游任务中？</li>
</ol>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>使用语言模型作为预训练的目标，在下游任务上做有监督的fine tuning</p>
<span id="more"></span>
<p><strong>预训练</strong></p>
<p>预训练使用无标签语料作为输入，以语言模型的最大似然函数为训练目标（给定前n-1个token，预测第n个token的条件概率）</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328083725904.png" class="" title="image-20220328083725904">
<p>模型使用transformer-decoder结构，最后一层通过softmax计算预测词的概率</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084046552.png" class="" title="image-20220328084046552">
<p><strong>下游任务-fine tuning</strong></p>
<p>fine-tuning 使用下游任务的有标签语料，增加一个全连接sfotmax输出层，预测对应标签，损失函数为所有训练数据的log最大似然</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084332027.png" class="" title="image-20220328084332027">
<p>另外增加了一个辅助训练目标，在下游任务上训练语言模型，使用两个损失函数求和作为<strong>最终的训练目标</strong>（$\lambda$ 为控制辅助训练目标对结果影响程度的参数）</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084506127.png" class="" title="image-20220328084506127">
<p>针对不任务，仅仅使用softmax预测概率无法满足任务要求（如句子相似度衡量，需要输入两个句子，判断两个句子之间的相似度），gpt针对不同任务设计了不同类型的输入（<strong>Task-specific input transformations</strong>）</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328084857519.png" class="" title="image-20220328084857519">
<h4 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h4><p>模型细节</p>
<ol>
<li>12层的transformer-decoder，768隐藏层维度+12注意力头数，去掉了与encoder输出共同计算的注意力层（或者说<strong>使用 masked Multi Self Attention的encoder</strong>）</li>
<li>使用GLUE作为激活函数</li>
<li>使用 bytepair encoding (BPE) 词典，包含4000词</li>
<li>使用<strong>模型学习position encoding</strong>，而不是transformer论文中的三角函数计算</li>
</ol>
<p>训练细节</p>
<ol>
<li>训练数据集为 BooksCorpus dataset（contains over 7,000 unique unpublished books）</li>
<li>预训练：优化器为Adam，最大学习率为 $2.5*10^{-4}$，dropout=0.1，在batchsize=64,seq_length=512的条件下，训练100个epoch</li>
<li>微调：lr = 6.25e-5 , batchsize = 32, dropout = 0.1，训练3个epoch</li>
</ol>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本文主要针对两个问题提出了解决方案，并在不同NLP上验证，得到了不错的效果</p>
<ol>
<li><p>预训练的<strong>训练目标是什么</strong>？</p>
<p>使用<strong>语言模型</strong>作为与训练目标（predict next token）</p>
</li>
<li><p>预训练得到的特征表示<strong>如何迁移</strong>到下游任务中？</p>
<p><strong>Task-specific input transformations + softmax predict层</strong> 在下游任务微调</p>
</li>
</ol>
<h3 id="GPT2"><a href="#GPT2" class="headerlink" title="GPT2"></a>GPT2</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">Language Models are Unsupervised Multitask Learners</a></p>
</blockquote>
<p>在BERT刷榜之后，GPT2带着更大的模型、更多的训练数据卷土重来，不再将关注点聚焦于 预训练+微调，转而研究语言模型在无监督多任务学习上的可能性</p>
<h4 id="要解决的问题-1"><a href="#要解决的问题-1" class="headerlink" title="要解决的问题"></a>要解决的问题</h4><p>论文中提出目前NLP领域主流的 <strong>预训练+微调</strong> 存在问题，即该方法仍需要监督学习，需要下游任务的大量有标签训练数据。本文将NLP的一般任务和特定任务定义为两种条件分布</p>
<ol>
<li>一般任务为 $p(output|input)$ 给定输入，对应输出的条件分布</li>
<li>特定任务  $p(output|input,task)$ 在特定任务上，输出不仅取决于输入，还取决于任务类型</li>
</ol>
<p>传统的预训练+fine-tuning方式</p>
<ol>
<li>预训练即模拟 $p(output|input)$条件分布</li>
<li>fine-tuning 通过在不同任务上<strong>调整模型架构、参数</strong>等，模拟  $p(output|input,task)$条件分布</li>
</ol>
<p>gpt2想要<strong>避免监督学习过程</strong>，即不在下游任务上做微调，引出了两个问题</p>
<ol>
<li>如何预训练能使得预训练过程中学到下游任务的信息？（原文中的句子：<strong>the global minimum of the unsupervised objective</strong><br><strong>is also the global minimum of the supervised objective.</strong> 全局非监督的收敛 等价于 全局监督学习的收敛）<ul>
<li>举个例子：像人学英语一样，背单词+看文章看看多了，就算从来没刷过题，题目也能做得效果不错</li>
</ul>
</li>
<li>如何<strong>不调整模型参数或者架构</strong>，<strong>实现从  $p(output|input)$ 到  $p(output|input,task)$</strong> 转变，以适应下游任务？</li>
</ol>
<h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>基本思路和GPT1区别不大，预训练语言模型+下游任务输入调整，不进行微调训练，个人觉得他的第二章Approach 前面关于理论来源的部分写的非常好，我读完感觉非常科学（也可能是我知识比较薄，看不出问题），分问题阐述一遍</p>
<p><strong>如何预训练能使得预训练过程中学到下游任务的信息</strong></p>
<blockquote>
<p>Preliminary experiments confirmed that sufficiently large <strong>language models are able to perform multitask learning</strong> in this toy-ish setup but learning is much slower than in explicitly supervised approaches.</p>
</blockquote>
<p>从两个角度解决该问题：</p>
<ol>
<li><p><strong>训练具备多任务学习能力的模型</strong>：语言模型 </p>
<ul>
<li>通过论文证明，语言模型具备多任务学习的能力，缺点是训练速度较慢</li>
</ul>
</li>
<li><p><strong>输入包含多任务信息的数据</strong>：WebText 数据集</p>
<ul>
<li><p>本文认为网络文本信息量巨大，包括各种下游任务中需要的数据信息，使用大量网络文本训练，能够使得模型学到不同任务的信息（multi task learning）</p>
</li>
<li><p>本文构造了一个WebText数据集，作者举了一些包含下游任务(NMT)数据的例子</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328101903526.png" class="" title="image-20220328101903526">
</li>
</ul>
</li>
</ol>
<p><strong>如何不调整模型参数或者架构，就能适应下游任务</strong></p>
<p>延续了GPT中的一些思路，通过修改输入表达方式，实现对下游任务的适应，以从英文到法文的机器翻译任务为例，在输入源句子的同时，以”english sentence = french sentence”为条件合并输入模型（文中成为 task hint）</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328143447270.png" class="" title="image-20220328143447270">
<p>在摘要任务中，论文尝试剔除了这种 <strong>”task hint“</strong>，发现任务指标下降了6.4个点，作者认为这证明了 使用自然语言提示模型针对任务改变的可行性</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328143917773.png" class="" title="image-20220328143917773">
<h4 id="顺带探讨的问题"><a href="#顺带探讨的问题" class="headerlink" title="顺带探讨的问题"></a>顺带探讨的问题</h4><p>在研究论文主要问题时，还顺带提了一下<strong>数据污染</strong>问题，即训练数据集和测试数据集之间重叠的问题，作者推荐在构建划分新的NLP数据训练集和测试集时，使用基于n-gram重叠的方法验证是否存在该问题</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328144755337.png" class="" title="image-20220328144755337">
<h4 id="实现细节-1"><a href="#实现细节-1" class="headerlink" title="实现细节"></a>实现细节</h4><p>模型细节</p>
<ol>
<li><p>使用<strong>BPE构建子词字典</strong>，为了避免无意义单词出现（”dog.“,”dog?”），限制不同类型字符共同出现，<strong>字典大小为 50257</strong></p>
</li>
<li><p>将transformer檐式结构结构中的 Post-LN 修改为了 Pre-LN(即把layer normalization移动到每个子层的前面，输入做归一化，输出不做)</p>
<ul>
<li>图片来自 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2002.04745v2.pdf">On Layer Normalization in the Transformer Architecture</a></li>
</ul>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328151023322.png" class="" title="image-20220328151023322">
</li>
</ol>
<p>训练细节</p>
<ol>
<li><p>batchsize=512，seq_length=1024</p>
</li>
<li><p>共有四个模型大小，最小的和gpt一一致，第二个与bert_large一致，最大的为GPT2</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220328151832377.png" class="" title="image-20220328151832377">
</li>
</ol>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>本文使用更大的模型尝试证明语言模型在zero-shot上的可行性，在许多任务上取得不错的成绩。</p>
<h3 id="GPT3"><a href="#GPT3" class="headerlink" title="GPT3"></a>GPT3</h3><p>GPT3是对GPT2在zero shot learning上的进一步推进，GPT2效果没有达到预期，就在GPT3上继续增加模型和训练数据规模，提升效果，在完全预训练模型上继续推广，提出了三种将预训练应用到下游任务的非预训练方式（所谓的 <strong>in-context learning</strong>）</p>
<ol>
<li><p>Few-Shot 解决下游任务时，在输入中提供几个任务样例</p>
<ul>
<li><p>一个任务提示</p>
</li>
<li><p>几个任务样例（prompt）</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154323252.png" class="" title="image-20220329154323252">
</li>
</ul>
</li>
<li><p>One-shot</p>
<ul>
<li><p>只给一个任务提示</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154359207.png" class="" title="image-20220329154359207">
</li>
</ul>
</li>
<li><p>Zero-shot 完全不给任务提示，只告诉任务是什么</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154433953.png" class="" title="image-20220329154433953">
</li>
</ol>
<p>GPT3将模型规模增大到原来的1000倍</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154640571.png" class="" title="image-20220329154640571">
<p>又构建了一个集合以往各种文本数据的巨大数据集</p>
<img src="/2022/04/03/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/%E8%AF%BB%E8%AE%BA%E6%96%87/%E8%AF%BB%E8%AE%BA%E6%96%874-GPT%E7%B3%BB%E5%88%97/image-20220329154729495.png" class="" title="image-20220329154729495">
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>GPT3文章太长，我只粗略地读了一遍，总体思路还是企图证明大规模预训练语言模型，在下游任务中，即使没有经过预训练，也能实现不错的效果，相较于前两篇论文没有太多新的东西</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/27/AI%E5%AD%A6%E4%B9%A0/DL%E7%90%86%E8%AE%BA%E5%AD%A6%E4%B9%A0/%E6%9D%82%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/BPE&wordpiece/" rel="prev" title="Subword分词:BPE&word-piece">
      <i class="fa fa-chevron-left"></i> Subword分词:BPE&word-piece
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/04/10/%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84%E6%95%B4%E7%90%86/" rel="next" title="树状数组整理">
      树状数组整理 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#GPT"><span class="nav-number">1.</span> <span class="nav-text">GPT</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPT1"><span class="nav-number">1.1.</span> <span class="nav-text">GPT1</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.1.</span> <span class="nav-text">要解决的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">1.1.2.</span> <span class="nav-text">解决方案</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="nav-number">1.1.3.</span> <span class="nav-text">实现细节</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.1.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPT2"><span class="nav-number">1.2.</span> <span class="nav-text">GPT2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">要解决的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-1"><span class="nav-number">1.2.2.</span> <span class="nav-text">解决方案</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A1%BA%E5%B8%A6%E6%8E%A2%E8%AE%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">1.2.3.</span> <span class="nav-text">顺带探讨的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82-1"><span class="nav-number">1.2.4.</span> <span class="nav-text">实现细节</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">1.2.5.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPT3"><span class="nav-number">1.3.</span> <span class="nav-text">GPT3</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-2"><span class="nav-number">1.3.1.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="NEU-FHF"
      src="/images/post_head.jpg">
  <p class="site-author-name" itemprop="name">NEU-FHF</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">84</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fuhaifei" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fuhaifei" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/fu-hai-fei" title="zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;fu-hai-fei" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:793515331@qq.com" title="邮件 → mailto:793515331@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>邮件</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/1799821187/profile" title="weibo → https:&#x2F;&#x2F;weibo.com&#x2F;1799821187&#x2F;profile" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>weibo</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      世外桃源
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://zhangxuzone.com/" title="http:&#x2F;&#x2F;zhangxuzone.com&#x2F;" rel="noopener" target="_blank">XuGodの后花园</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">NEU-FHF</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      已有<span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人访问
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      总访问<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次
    </span>
  
</div>









      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '7286e7dc83cf6478eb9b',
      clientSecret: '9874f53101e01e8a47a1520a91ccd73743e974c7',
      repo        : 'MyBlogComment',
      owner       : 'fuhaifei',
      admin       : ['fuhaifei'],
      id          : '70e51c813e713eeffc20abbc934e86b2',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
